{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7438121156547839861\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11281553818\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14367002935416756319\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tbCallBack = keras.callbacks.TensorBoard(log_dir='/data/tb-logs', histogram_freq=0, write_graph=True, write_images=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 256, 256\n",
    "train_data_dir = \"/data/oxford102/train/\"\n",
    "validation_data_dir = \"/data/oxford102/train/\"\n",
    "nb_train_samples = 4604\n",
    "nb_validation_samples = 1094 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_categories = 102\n",
    "batch_size = 16\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "#from keras.models import load_model\n",
    "#model = load_model(\"/data/vgg16_fungi_all_p2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2\n",
      "1 block1_conv1\n",
      "2 block1_conv2\n",
      "3 block1_pool\n",
      "4 block2_conv1\n",
      "5 block2_conv2\n",
      "6 block2_pool\n",
      "7 block3_conv1\n",
      "8 block3_conv2\n",
      "9 block3_conv3\n",
      "10 block3_conv4\n",
      "11 block3_pool\n",
      "12 block4_conv1\n",
      "13 block4_conv2\n",
      "14 block4_conv3\n",
      "15 block4_conv4\n",
      "16 block4_pool\n",
      "17 block5_conv1\n",
      "18 block5_conv2\n",
      "19 block5_conv3\n",
      "20 block5_conv4\n",
      "21 block5_pool\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2\n",
      "block1_conv1\n",
      "block1_conv2\n",
      "block1_pool\n",
      "block2_conv1\n",
      "block2_conv2\n",
      "block2_pool\n",
      "block3_conv1\n",
      "block3_conv2\n",
      "block3_conv3\n",
      "block3_conv4\n",
      "block3_pool\n",
      "block4_conv1\n",
      "block4_conv2\n",
      "block4_conv3\n",
      "block4_conv4\n",
      "block4_pool\n",
      "block5_conv1\n",
      "block5_conv2\n",
      "block5_conv3\n",
      "block5_conv4\n",
      "block5_pool\n"
     ]
    }
   ],
   "source": [
    "# # Since the initial layers train very general features (e.g. edges, we're not going to retrain those)\n",
    "for layer in model.layers[:]:\n",
    "    print(layer.name)\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "#x = Dense(102, activation=\"relu\")(x)\n",
    "predictions = Dense(nr_categories, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "model_final = Model(input = model.input, output = predictions)\n",
    "#model_final = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-25fdc5710de9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the initial layers train very general features (e.g. edges, we're not going to retrain those)\n",
    "for layer in model_final.layers[:12]:\n",
    "    print(layer.name)\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              33555456  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 102)               104550    \n",
      "=================================================================\n",
      "Total params: 53,684,390\n",
      "Trainable params: 33,660,006\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "#model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=[\"accuracy\"])\n",
    "#model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0), metrics=[\"accuracy\"])\n",
    "#model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0), metrics=[\"accuracy\"])\n",
    "#model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train__val_datagen = ImageDataGenerator(rescale = 1./255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 256, 256\n",
    "train_generator = train__val_datagen.flow_from_directory(\n",
    "        train_data_dir,  # this is the target directory\n",
    "        target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "        batch_size=batch_size,\n",
    "        subset=\"training\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1094 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train__val_datagen.flow_from_directory(\n",
    "        train_data_dir,  # this is the target directory\n",
    "        target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "        subset=\"validation\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"vgg16_oxford102_train_dataset.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()), histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "288/287 [==============================] - 88s 307ms/step - loss: 4.5757 - acc: 0.0380 - val_loss: 4.3221 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.05210, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 2/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 4.2929 - acc: 0.0735 - val_loss: 4.0831 - val_acc: 0.1243\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.05210 to 0.12431, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 3/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 4.0673 - acc: 0.1171 - val_loss: 3.9103 - val_acc: 0.1600\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.12431 to 0.15996, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 4/50\n",
      "288/287 [==============================] - 84s 291ms/step - loss: 3.8164 - acc: 0.1643 - val_loss: 3.6347 - val_acc: 0.2011\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.15996 to 0.20110, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 5/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 3.5976 - acc: 0.2005 - val_loss: 3.4181 - val_acc: 0.2761\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.20110 to 0.27605, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 6/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 3.3451 - acc: 0.2535 - val_loss: 3.1916 - val_acc: 0.3556\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.27605 to 0.35558, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 7/50\n",
      "288/287 [==============================] - 84s 291ms/step - loss: 3.1068 - acc: 0.3049 - val_loss: 3.0086 - val_acc: 0.3885\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.35558 to 0.38848, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 8/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 2.9354 - acc: 0.3405 - val_loss: 2.8651 - val_acc: 0.4214\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.38848 to 0.42139, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 9/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 2.7675 - acc: 0.3735 - val_loss: 2.6971 - val_acc: 0.4433\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.42139 to 0.44333, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 10/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 2.5904 - acc: 0.4144 - val_loss: 2.5742 - val_acc: 0.4726\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.44333 to 0.47258, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 11/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 2.4160 - acc: 0.4527 - val_loss: 2.4457 - val_acc: 0.5119\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.47258 to 0.51188, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 12/50\n",
      "288/287 [==============================] - 83s 290ms/step - loss: 2.2901 - acc: 0.4704 - val_loss: 2.3567 - val_acc: 0.5311\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.51188 to 0.53108, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 13/50\n",
      "288/287 [==============================] - 83s 290ms/step - loss: 2.1310 - acc: 0.5192 - val_loss: 2.2209 - val_acc: 0.5375\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.53108 to 0.53748, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 14/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 2.0270 - acc: 0.5360 - val_loss: 2.1443 - val_acc: 0.5713\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.53748 to 0.57130, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 15/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 1.9090 - acc: 0.5645 - val_loss: 2.0524 - val_acc: 0.5786\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.57130 to 0.57861, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 16/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 1.8162 - acc: 0.5817 - val_loss: 1.9799 - val_acc: 0.5713\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.57861\n",
      "Epoch 17/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 1.7015 - acc: 0.6054 - val_loss: 1.9312 - val_acc: 0.5804\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.57861 to 0.58044, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 18/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 1.6526 - acc: 0.6272 - val_loss: 1.8323 - val_acc: 0.6289\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.58044 to 0.62888, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 19/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 1.5518 - acc: 0.6438 - val_loss: 1.7969 - val_acc: 0.6161\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.62888\n",
      "Epoch 20/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 1.4710 - acc: 0.6667 - val_loss: 1.7562 - val_acc: 0.6033\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.62888\n",
      "Epoch 21/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 1.3944 - acc: 0.6869 - val_loss: 1.6967 - val_acc: 0.6371\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.62888 to 0.63711, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 22/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 1.3375 - acc: 0.7028 - val_loss: 1.6293 - val_acc: 0.6554\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.63711 to 0.65539, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 23/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 1.2568 - acc: 0.7203 - val_loss: 1.6230 - val_acc: 0.6508\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.65539\n",
      "Epoch 24/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 1.2014 - acc: 0.7365 - val_loss: 1.5473 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.65539 to 0.66636, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 25/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 1.1636 - acc: 0.7437 - val_loss: 1.5327 - val_acc: 0.6618\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.66636\n",
      "Epoch 26/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 1.1040 - acc: 0.7584 - val_loss: 1.4778 - val_acc: 0.6782\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.66636 to 0.67824, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 27/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 1.0714 - acc: 0.7614 - val_loss: 1.4712 - val_acc: 0.6746\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.67824\n",
      "Epoch 28/50\n",
      "288/287 [==============================] - 83s 288ms/step - loss: 1.0188 - acc: 0.7777 - val_loss: 1.4355 - val_acc: 0.6755\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.67824\n",
      "Epoch 29/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 0.9775 - acc: 0.7912 - val_loss: 1.4177 - val_acc: 0.6801\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.67824 to 0.68007, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 30/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 0.9467 - acc: 0.7994 - val_loss: 1.3729 - val_acc: 0.6947\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.68007 to 0.69470, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 31/50\n",
      "288/287 [==============================] - 83s 288ms/step - loss: 0.9006 - acc: 0.8084 - val_loss: 1.3580 - val_acc: 0.6865\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.69470\n",
      "Epoch 32/50\n",
      "288/287 [==============================] - 83s 288ms/step - loss: 0.8676 - acc: 0.8153 - val_loss: 1.3252 - val_acc: 0.7176\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.69470 to 0.71755, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 33/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 0.8211 - acc: 0.8315 - val_loss: 1.3224 - val_acc: 0.7075\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.71755\n",
      "Epoch 34/50\n",
      "288/287 [==============================] - 83s 288ms/step - loss: 0.8023 - acc: 0.8347 - val_loss: 1.2991 - val_acc: 0.7157\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.71755\n",
      "Epoch 35/50\n",
      "288/287 [==============================] - 83s 288ms/step - loss: 0.7560 - acc: 0.8424 - val_loss: 1.2575 - val_acc: 0.7166\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.71755\n",
      "Epoch 36/50\n",
      "288/287 [==============================] - 83s 288ms/step - loss: 0.7375 - acc: 0.8544 - val_loss: 1.2539 - val_acc: 0.7212\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.71755 to 0.72121, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 37/50\n",
      "288/287 [==============================] - 83s 290ms/step - loss: 0.7225 - acc: 0.8572 - val_loss: 1.2400 - val_acc: 0.7276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00037: val_acc improved from 0.72121 to 0.72761, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 38/50\n",
      "288/287 [==============================] - 84s 292ms/step - loss: 0.7040 - acc: 0.8620 - val_loss: 1.2300 - val_acc: 0.7230\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.72761\n",
      "Epoch 39/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 0.6504 - acc: 0.8749 - val_loss: 1.2266 - val_acc: 0.7194\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.72761\n",
      "Epoch 40/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 0.6474 - acc: 0.8723 - val_loss: 1.2208 - val_acc: 0.7203\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.72761\n",
      "Epoch 41/50\n",
      "288/287 [==============================] - 83s 288ms/step - loss: 0.6152 - acc: 0.8831 - val_loss: 1.1743 - val_acc: 0.7331\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.72761 to 0.73309, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 42/50\n",
      "288/287 [==============================] - 83s 290ms/step - loss: 0.5914 - acc: 0.8932 - val_loss: 1.1778 - val_acc: 0.7349\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.73309 to 0.73492, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 43/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 0.5756 - acc: 0.8911 - val_loss: 1.1674 - val_acc: 0.7258\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.73492\n",
      "Epoch 44/50\n",
      "288/287 [==============================] - 84s 291ms/step - loss: 0.5636 - acc: 0.8942 - val_loss: 1.1502 - val_acc: 0.7203\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.73492\n",
      "Epoch 45/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 0.5373 - acc: 0.9050 - val_loss: 1.1411 - val_acc: 0.7404\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.73492 to 0.74040, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 46/50\n",
      "288/287 [==============================] - 83s 290ms/step - loss: 0.5269 - acc: 0.9054 - val_loss: 1.1255 - val_acc: 0.7431\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.74040 to 0.74314, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 47/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 0.5103 - acc: 0.9079 - val_loss: 1.1342 - val_acc: 0.7450\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.74314 to 0.74497, saving model to vgg16_oxford102_train_dataset.h5\n",
      "Epoch 48/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 0.4898 - acc: 0.9131 - val_loss: 1.1151 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.74497\n",
      "Epoch 49/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 0.4714 - acc: 0.9156 - val_loss: 1.1242 - val_acc: 0.7303\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.74497\n",
      "Epoch 50/50\n",
      "288/287 [==============================] - 83s 289ms/step - loss: 0.4619 - acc: 0.9208 - val_loss: 1.1026 - val_acc: 0.7422\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.74497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe289b0d278>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.fit_generator(\n",
    "train_generator,\n",
    "#samples_per_epoch = nb_train_samples,\n",
    "steps_per_epoch = nb_train_samples/batch_size,    \n",
    "epochs = epochs,\n",
    "validation_data = validation_generator,\n",
    "#nb_val_samples = nb_validation_samples,\n",
    "validation_steps = nb_validation_samples/batch_size,    \n",
    "callbacks = [checkpoint, early, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.fit_generator(\n",
    "train_generator,\n",
    "#samples_per_epoch = nb_train_samples,\n",
    "steps_per_epoch = nb_train_samples/batch_size,    \n",
    "epochs = epochs,\n",
    "validation_data = validation_generator,\n",
    "#nb_val_samples = nb_validation_samples,\n",
    "validation_steps = nb_validation_samples/batch_size,    \n",
    "callbacks = [checkpoint, early, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "generator = train__val_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=int(batch_size/10),\n",
    "        class_mode=None) #,  # this means our generator will only yield batches of data, no labels\n",
    "#) #shuffle=False)  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs\n",
    "# the predict_generator method returns the output of a model, given\n",
    "# a generator that yields batches of numpy data\n",
    "bottleneck_features_train = model.predict_generator(generator, 60000)\n",
    "# save the output as a Numpy array\n",
    "np.save(open('bottleneck_features_train.npy', 'w'), bottleneck_features_train)\n",
    "\n",
    "generator = train__val_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=int(batch_size/20),\n",
    "        class_mode=None)\n",
    "#) #shuffle=False)\n",
    "bottleneck_features_validation = model.predict_generator(generator, 8000)\n",
    "np.save(open('bottleneck_features_validation.npy', 'w'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(open('bottleneck_features_train.npy'))\n",
    "# the features were saved in order, so recreating the labels is easy\n",
    "train_labels = np.array([0] * 1000 + [1] * 1000)\n",
    "\n",
    "validation_data = np.load(open('bottleneck_features_validation.npy'))\n",
    "validation_labels = np.array([0] * 400 + [1] * 400)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(nr_categories, activation='softmax')) \n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          epochs=50,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "model.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_inv = train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = {v:k for k, v in indices_inv.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10249_Amanita_citrina var. citrina'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_inv['10273_Amanita_virosa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941 800\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "im = Image.open('fgcvx/train/images/15309_Inocybe_adaequata/TOB2017-9198446_HypgMYRSZ.JPG')\n",
    "width, height = im.size\n",
    "print(width, height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 667\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
