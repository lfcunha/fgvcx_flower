{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ALL imagenet networks with defaut param optimizer WITHOUT data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test rmsprop vs SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch size 32 vs 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### should show terrible variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow\n",
    "from time import time\n",
    "\n",
    "import pandas\n",
    "\n",
    "import pickle as pk\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` https://www.kaggle.com/kmader/transfer-learning-with-inceptionv3```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/oxford102/train'\n",
    "img_width, img_height = 256, 256\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "nr_categories = 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 256, 256\n",
    "train_data_dir = \"/data/oxford102/train/\"\n",
    "validation_data_dir = \"/data/oxford102/train/\"\n",
    "nb_train_samples = 4604\n",
    "nb_validation_samples = 1094 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('/data/oxford102/jpg/image_00001.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='preview', save_prefix='flower', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"/data/preview/\"\n",
    "imgs = np.random.choice(os.listdir(category), size=20, replace=False)\n",
    "#os.listdir(category)\n",
    "\n",
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(12, 12))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    #img = np.random.randint(10, size=(h,w))\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    img=mpimg.imread(category + imgs[i-1])\n",
    "    print(img.shape)\n",
    "    imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_generator(input_processor, augmentation=False):\n",
    "    if augmentation:\n",
    "        return ImageDataGenerator(#rescale = 1./255, \n",
    "                                            rotation_range=40,\n",
    "                                            width_shift_range=0.2,\n",
    "                                            height_shift_range=0.2,\n",
    "                                            shear_range=0.2,\n",
    "                                            zoom_range=0.2,\n",
    "                                            horizontal_flip=True,\n",
    "                                            fill_mode='nearest',\n",
    "                                            preprocessing_function=input_processor, \n",
    "                                            validation_split=0.2)\n",
    "    else:\n",
    "        return  ImageDataGenerator(preprocessing_function=input_processor, \n",
    "                                           validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_generators(network=\"vgg16\", augmentation=False, input_shape=(256, 256)):\n",
    "    input_processors = {\n",
    "        \"vgg16\": keras.applications.vgg16.preprocess_input\n",
    "    }\n",
    "    \n",
    "    train_val_datagen = get_image_generator(input_processors[network])\n",
    "    \n",
    "    train_generator = train_val_datagen.flow_from_directory(\n",
    "            train_data_dir,  # this is the target directory\n",
    "            target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "            batch_size=batch_size,\n",
    "            subset=\"training\",\n",
    "            class_mode='categorical')\n",
    "    validation_generator = train_val_datagen.flow_from_directory(\n",
    "            train_data_dir,  # this is the target directory\n",
    "            target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "            subset=\"validation\",\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "    \n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator = get_image_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    models = {\n",
    "        \"vgg16\": (keras.applications.vgg16.VGG16, keras.applications.vgg16.preprocess_input),\n",
    "        \"vgg19\": (keras.applications.vgg19.VGG19, keras.applications.vgg19.preprocess_input),\n",
    "        \"inceptionv3\": (applications.inception_v3.InceptionV3, keras.applications.inception_v3.preprocess_input),\n",
    "        \"xception\": (applications.xception.Xception, keras.applications.xception.preprocess_input),\n",
    "        \"resnet50\": (keras.applications.resnet50.ResNet50, keras.applications.resnet50.preprocess_input),\n",
    "        \"inceptionresnetv2\": (keras.applications.inception_resnet_v2, keras.applications.inception_resnet_v2.preprocess_input),\n",
    "        \"mobilenet\": (keras.applications.mobilenet.MobileNet, keras.applications.mobilenet.preprocess_input),\n",
    "        \"mobilenetv2\": (keras.applications.mobilenet_v2, keras.applications.mobilenet_v2.preprocess_input),\n",
    "        \"densenet121\": (keras.applications.densenet.DenseNet121, keras.applications.densenet.preprocess_input),\n",
    "        \"densenet169\": (keras.applications.densenet.DenseNet169, keras.applications.densenet.preprocess_input),\n",
    "        \"densenet201\": (keras.applications.densenet.DenseNet201, keras.applications.densenet.preprocess_input),\n",
    "        \"nastnetlarge\": (keras.applications.nasnet.NASNetLarge, keras.applications.nasnet.preprocess_input),\n",
    "        \"nastnetmobile\": (keras.applications.nasnet.NASNetMobile, keras.applications.nasnet.preprocess_input)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(network_name):\n",
    "    k.set_learning_phase(0)\n",
    "    \n",
    "    if network_name == \"vgg16\":\n",
    "        base_model = keras.applications.vgg16.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "    elif network_name == \"vgg19\":\n",
    "        base_model = keras.applications.vgg19.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "    else:\n",
    "        raise Exception(\"check your network name\")\n",
    "        \n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "        #Adding custom Layers \n",
    "    k.set_learning_phase(1)\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x, training=False)\n",
    "    #x = Dense(102, activation=\"relu\")(x)\n",
    "    predictions = Dense(nr_categories, activation=\"softmax\")(x)\n",
    "    \n",
    "    _model = Model(input = base_model.input, output = predictions)\n",
    "    \n",
    "    return _model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in base_model.layers[:]:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Adding custom Layers \n",
    "# k.set_learning_phase(1)\n",
    "# x = base_model.output\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(1024, activation=\"relu\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = BatchNormalization()(x, training=False)\n",
    "# #x = Dense(102, activation=\"relu\")(x)\n",
    "# predictions = Dense(nr_categories, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# model = Model(input = base_model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_generator, validation_generator = get_image_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model \n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "#model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=[\"accuracy\"])\n",
    "#model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0), metrics=[\"accuracy\"])\n",
    "#model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0), metrics=[\"accuracy\"])\n",
    "#model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    np.random.seed(seed)\n",
    "    log_time = time()\n",
    "    params['log_time'] = log_time\n",
    "    batch_size = params.get(\"batch_size\")\n",
    "    \n",
    "    base = '/data/oxford102/experiments'\n",
    "    path = os.path.join(base, str(log_time))\n",
    "    checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "    csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        history_callback = _model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=num_train_img // batch_size,\n",
    "                epochs=params.get(\"epochs\"),\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=num_val_img // batch_size,\n",
    "                callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "    except Exception as e:\n",
    "        raise(e)\n",
    "    finally:\n",
    "        pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "        _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "        print(params)\n",
    "        params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(_model, optimizer):\n",
    "    _model.compile(loss = \"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(optimizer, params=None):\n",
    "\n",
    "    if optimizer.lower() == \"sgd\":\n",
    "        _params = params or dict(lr=0.0001, momentum=0.9)\n",
    "        return optimizers.SGD(**_params)\n",
    "    \n",
    "    elif optimizer.lower() == \"adam\":\n",
    "        _params = params or dict(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        return optimizers.Adam(**_params)\n",
    "    \n",
    "    elif optimizer.lower() == \"adadelta\":\n",
    "        _params = params or dict(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "        return optimizers.Adadelta(**_params)\n",
    "    \n",
    "    elif optimizer.lower() == \"adagrad\":\n",
    "        _params = params or dict(lr=0.01, epsilon=None, decay=0.0)\n",
    "        return optimizers.Adagrad(**_params)\n",
    "    \n",
    "    elif optimizer.lower() == \"rmsprop\":\n",
    "        _params = params or dict(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "        return optimizers.RMSprop(**_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import glorot_uniform  # Or your initializer of choice\n",
    "def run(params):\n",
    "#     import tensorflow as tf\n",
    "#     import gc\n",
    "#     sess = tf.Session()\n",
    "\n",
    "#     from keras import backend as K\n",
    "#     K.set_session(sess)\n",
    "#     model = None\n",
    "\n",
    "#     gc.collect()\n",
    "    \n",
    "    __model = build_model(params[\"network_name\"])\n",
    "    \n",
    "    opt = get_optimizer(params[\"optimizer\"], params.get(\"optimizer_params\"))\n",
    "    print(opt)\n",
    "    compile_model(__model, opt)\n",
    "    \n",
    "#     initial_weights = model.get_weights()\n",
    "#     with sess.as_default():\n",
    "#       new_weights = [glorot_uniform()(w.shape).eval() for w in initial_weights]\n",
    "#     model.set_weights(new_weights)\n",
    "    \n",
    "    train_generator, validation_generator = get_image_generators()\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    run_training(params.get(\"network_name\"), __model, train_generator, validation_generator, params, 4604, 1094)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'network_name': 'vgg16',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 41s 582ms/step - loss: 14.5700 - acc: 0.0563 - val_loss: 13.8963 - val_acc: 0.1048\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.10478, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 34s 478ms/step - loss: 13.0808 - acc: 0.1426 - val_loss: 12.6350 - val_acc: 0.1783\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.10478 to 0.17831, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 35s 491ms/step - loss: 11.7604 - acc: 0.2345 - val_loss: 11.8201 - val_acc: 0.2151\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.17831 to 0.21507, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 34s 473ms/step - loss: 10.8241 - acc: 0.2738 - val_loss: 10.4955 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.21507 to 0.27757, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 35s 498ms/step - loss: 9.3074 - acc: 0.3574 - val_loss: 9.6155 - val_acc: 0.3199\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.27757 to 0.31985, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 34s 476ms/step - loss: 8.8704 - acc: 0.3696 - val_loss: 8.5494 - val_acc: 0.3658\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.31985 to 0.36581, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 35s 496ms/step - loss: 7.1569 - acc: 0.4749 - val_loss: 7.6822 - val_acc: 0.4044\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.36581 to 0.40441, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 34s 479ms/step - loss: 6.3237 - acc: 0.5007 - val_loss: 6.9516 - val_acc: 0.4154\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.40441 to 0.41544, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 35s 494ms/step - loss: 5.2096 - acc: 0.5617 - val_loss: 5.9815 - val_acc: 0.4007\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.41544\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 34s 477ms/step - loss: 4.0460 - acc: 0.5858 - val_loss: 5.1144 - val_acc: 0.4081\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.41544\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 35s 487ms/step - loss: 2.9708 - acc: 0.6268 - val_loss: 4.0152 - val_acc: 0.4228\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.41544 to 0.42279, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 34s 479ms/step - loss: 2.3747 - acc: 0.6207 - val_loss: 3.4645 - val_acc: 0.4210\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.42279\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 35s 498ms/step - loss: 1.6247 - acc: 0.6950 - val_loss: 3.3237 - val_acc: 0.4540\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.42279 to 0.45404, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 34s 476ms/step - loss: 1.2389 - acc: 0.7535 - val_loss: 3.0458 - val_acc: 0.4890\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.45404 to 0.48897, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 35s 488ms/step - loss: 0.8665 - acc: 0.8209 - val_loss: 2.8748 - val_acc: 0.5184\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.48897 to 0.51838, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 34s 476ms/step - loss: 0.7140 - acc: 0.8444 - val_loss: 2.9318 - val_acc: 0.5276\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.51838 to 0.52757, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 35s 487ms/step - loss: 0.5426 - acc: 0.8757 - val_loss: 2.9511 - val_acc: 0.5018\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.52757\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 34s 478ms/step - loss: 0.4753 - acc: 0.8904 - val_loss: 2.6797 - val_acc: 0.5643\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.52757 to 0.56434, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 35s 490ms/step - loss: 0.3497 - acc: 0.9107 - val_loss: 2.7174 - val_acc: 0.5533\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.56434\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 34s 479ms/step - loss: 0.3210 - acc: 0.9198 - val_loss: 2.7509 - val_acc: 0.5368\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.56434\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 35s 488ms/step - loss: 0.2763 - acc: 0.9325 - val_loss: 2.7913 - val_acc: 0.5662\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.56434 to 0.56618, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 34s 477ms/step - loss: 0.2404 - acc: 0.9366 - val_loss: 2.7577 - val_acc: 0.5551\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.56618\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 34s 484ms/step - loss: 0.2362 - acc: 0.9498 - val_loss: 2.6015 - val_acc: 0.5974\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.56618 to 0.59743, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 34s 476ms/step - loss: 0.1825 - acc: 0.9507 - val_loss: 2.8726 - val_acc: 0.5368\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.59743\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 34s 482ms/step - loss: 0.1796 - acc: 0.9491 - val_loss: 2.4022 - val_acc: 0.6268\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.59743 to 0.62684, saving model to /data/oxford102/experiments/1542065107.884702/vgg16_1542065107.884702.h5\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 34s 477ms/step - loss: 0.1398 - acc: 0.9608 - val_loss: 2.7682 - val_acc: 0.5717\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.62684\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 34s 483ms/step - loss: 0.1220 - acc: 0.9651 - val_loss: 2.5808 - val_acc: 0.5864\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.62684\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 34s 479ms/step - loss: 0.1379 - acc: 0.9665 - val_loss: 2.6684 - val_acc: 0.5882\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.62684\n",
      "Epoch 00028: early stopping\n",
      "{'network_name': 'vgg16', 'image_aug': False, 'optimizer': 'SGD', 'batch_size': 64, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1542065107.884702}\n"
     ]
    }
   ],
   "source": [
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 35s 496ms/step - loss: 1.1921e-07 - acc: 0.0062 - val_loss: 1.1921e-07 - val_acc: 0.0037\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.00368, saving model to /data/oxford102/experiments/1542067020.9744284/vgg16_1542067020.9744284.h5\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 34s 484ms/step - loss: 1.1921e-07 - acc: 0.0048 - val_loss: 1.1921e-07 - val_acc: 0.0037\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.00368\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 35s 495ms/step - loss: 1.1921e-07 - acc: 0.0045 - val_loss: 1.1921e-07 - val_acc: 0.0037\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.00368\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 34s 484ms/step - loss: 1.1921e-07 - acc: 0.0066 - val_loss: 1.1921e-07 - val_acc: 0.0037\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.00368\n",
      "Epoch 00004: early stopping\n",
      "{'network_name': 'vgg16', 'image_aug': False, 'optimizer': 'rmsprop', 'optimizer_params': None, 'batch_size': 64, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1542067020.9744284}\n"
     ]
    }
   ],
   "source": [
    "run({'network_name': 'vgg16',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'rmsprop',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 70s 487ms/step - loss: 1.1921e-07 - acc: 0.0055 - val_loss: 1.1921e-07 - val_acc: 0.0055\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.00551, saving model to /data/oxford102/experiments/1542067170.5056026/vgg16_1542067170.5056026.h5\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 69s 480ms/step - loss: 1.1921e-07 - acc: 0.0053 - val_loss: 1.1921e-07 - val_acc: 0.0055\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.00551\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 69s 485ms/step - loss: 1.1921e-07 - acc: 0.0055 - val_loss: 1.1921e-07 - val_acc: 0.0055\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.00551\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 69s 483ms/step - loss: 1.1921e-07 - acc: 0.0052 - val_loss: 1.1921e-07 - val_acc: 0.0055\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.00551\n",
      "Epoch 00004: early stopping\n",
      "{'network_name': 'vgg16', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 32, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1542067170.5056026}\n"
     ]
    }
   ],
   "source": [
    "run({'network_name': 'vgg16',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 18s 507ms/step - loss: 1.1921e-07 - acc: 0.0054 - val_loss: 1.1921e-07 - val_acc: 0.0117\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.01172, saving model to /data/oxford102/experiments/1542067458.2843618/vgg16_1542067458.2843618.h5\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 17s 477ms/step - loss: 1.1921e-07 - acc: 0.0080 - val_loss: 1.1921e-07 - val_acc: 0.0117\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.01172\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 17s 480ms/step - loss: 1.1921e-07 - acc: 0.0063 - val_loss: 1.1921e-07 - val_acc: 0.0117\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.01172\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 17s 473ms/step - loss: 1.1921e-07 - acc: 0.0027 - val_loss: 1.1921e-07 - val_acc: 0.0117\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.01172\n",
      "Epoch 00004: early stopping\n",
      "{'network_name': 'vgg16', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 128, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1542067458.2843618}\n"
     ]
    }
   ],
   "source": [
    "run({'network_name': 'vgg16',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 128,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 70s 491ms/step - loss: 1.1921e-07 - acc: 0.0055 - val_loss: 1.1921e-07 - val_acc: 0.0055\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.00551, saving model to /data/oxford102/experiments/1542067538.452063/vgg16_1542067538.452063.h5\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 70s 489ms/step - loss: 1.1921e-07 - acc: 0.0055 - val_loss: 1.1921e-07 - val_acc: 0.0055\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.00551\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 69s 484ms/step - loss: 1.1921e-07 - acc: 0.0055 - val_loss: 1.1921e-07 - val_acc: 0.0055\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.00551\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 69s 485ms/step - loss: 1.1921e-07 - acc: 0.0055 - val_loss: 1.1921e-07 - val_acc: 0.0055\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.00551\n",
      "Epoch 00004: early stopping\n",
      "{'network_name': 'vgg16', 'image_aug': False, 'optimizer': 'rmsprop', 'optimizer_params': None, 'batch_size': 32, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1542067538.452063}\n"
     ]
    }
   ],
   "source": [
    "run({'network_name': 'vgg16',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'rmsprop',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train small convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D, MaxPooling2D\n",
    "# from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), input_shape=(256, 256, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "# model.add(Dense(256))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(102, activation=\"softmax\"))\n",
    "# #model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "# # #Adding custom Layers \n",
    "# # x = model.output\n",
    "# # x = Flatten()(x)\n",
    "# # x = Dense(1024, activation=\"relu\")(x)\n",
    "# # x = Dropout(0.5)(x)\n",
    "# # #x = Dense(1024, activation=\"relu\")(x)\n",
    "# # predictions = Dense(nr_categories, activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='rmsprop', \n",
    "#               #optimizer=optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# #model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(optimizer=optimizers.SGD, verbose=False, image_size=(256,256)):\n",
    "   \n",
    "    img_width, img_height = input_shape\n",
    "\n",
    "    params = dict(weights=\"imagenet\",\n",
    "                  include_top=False,\n",
    "                  input_shape=(img_width, img_height, 3))\n",
    "            \n",
    "    models = {\n",
    "        \"vgg16\": (keras.applications.vgg16.VGG16, keras.applications.vgg16.preprocess_input),\n",
    "        \"vgg19\": (keras.applications.vgg19.VGG19, keras.applications.vgg19.preprocess_input),\n",
    "        \"inceptionv3\": (applications.inception_v3.InceptionV3, keras.applications.inception_v3.preprocess_input),\n",
    "        \"xception\": (applications.xception.Xception, keras.applications.xception.preprocess_input),\n",
    "        \"resnet50\": (keras.applications.resnet50.ResNet50, keras.applications.resnet50.preprocess_input),\n",
    "        \"inceptionresnetv2\": (keras.applications.inception_resnet_v2, keras.applications.inception_resnet_v2.preprocess_input),\n",
    "        \"mobilenet\": (keras.applications.mobilenet.MobileNet, keras.applications.mobilenet.preprocess_input),\n",
    "        \"mobilenetv2\": (keras.applications.mobilenet_v2, keras.applications.mobilenet_v2.preprocess_input),\n",
    "        \"densenet121\": (keras.applications.densenet.DenseNet121, keras.applications.densenet.preprocess_input),\n",
    "        \"densenet169\": (keras.applications.densenet.DenseNet169, keras.applications.densenet.preprocess_input),\n",
    "        \"densenet201\": (keras.applications.densenet.DenseNet201, keras.applications.densenet.preprocess_input),\n",
    "        \"nastnetlarge\": (keras.applications.nasnet.NASNetLarge, keras.applications.nasnet.preprocess_input),\n",
    "        \"nastnetmobile\": (keras.applications.nasnet.NASNetMobile, keras.applications.nasnet.preprocess_input)} \n",
    "\n",
    "    _model, preprocess_input = models.get(model_name)[0](**params), models.get(model_name)[1]\n",
    "    \n",
    "    if verbose:\n",
    "        _model.summary()\n",
    "\n",
    "    return _model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_generator(image_augmentation=False, validation_split=0.2, preprocess_input=None):\n",
    "\n",
    "    if not image_augmentation:\n",
    "        return ImageDataGenerator(#rescale=1./255,\n",
    "                                  preprocessing_function=preprocess_input,\n",
    "                                  validation_split=validation_split)\n",
    "\n",
    "    return ImageDataGenerator(\n",
    "        #rescale=1. / 255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=preprocess_input,\n",
    "        validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_val_datagen_no_aug = get_image_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_val_datagen = get_image_generator(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#     data_dir,  # this is the target directory\n",
    "#     target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical',\n",
    "#     subset = \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_generator = train_datagen.flow_from_directory(\n",
    "#     data_dir,  # this is the target directory\n",
    "#     target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical',\n",
    "#     subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(params):\n",
    "    data_dir = '/data/oxford102/train'\n",
    "    img_width, img_height = params.get('image_size')\n",
    "    batch_size =  params.get(\"batch_size\")\n",
    "\n",
    "    if type(params.get('optimizer')) in [keras.optimizers.Adam, keras.optimizers.SGD, keras.optimizers.RMSprop]:\n",
    "        opt = params.get('optimizer')\n",
    "    elif params.get(\"optimizer\") == \"rmsprop\":\n",
    "        opt = \"rmsprop\"\n",
    "    elif params.get(\"optimizer\") == \"sgd\":\n",
    "        opt = optimizers.SGD(lr=0.0001, momentum=0.9)\n",
    "    elif params.get(\"optimizer\") == \"adam\":\n",
    "        opt = optimizers.Adam()    \n",
    "        \n",
    "    model = None\n",
    "    model = get_model(optimizer=opt, image_size=params.get('image_size'), n_categories=102, verbose=True)\n",
    "       \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generators(params):\n",
    "    img_width, img_height = params.get('image_size')\n",
    "    batch_size =  params.get(\"batch_size\")\n",
    "    \n",
    "    if not params.get(\"image_aug\"):\n",
    "        train_val_datagen = get_image_generator()\n",
    "    else: \n",
    "        train_val_datagen = get_image_generator(True)\n",
    "\n",
    "    train_generator = train_val_datagen.flow_from_directory(\n",
    "        data_dir,  # this is the target directory\n",
    "        target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset = \"training\")    \n",
    "        \n",
    "    validation_generator = train_val_datagen.flow_from_directory(\n",
    "        data_dir,  # this is the target directory\n",
    "        target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset=\"validation\")\n",
    "    \n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def run_training(model_name, model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    np.random.seed(seed)\n",
    "    log_time = time()\n",
    "    params['log_time'] = log_time\n",
    "    batch_size = params.get(\"batch_size\")\n",
    "    \n",
    "    base = '/data/oxford102/experiments'\n",
    "    path = os.path.join(base, str(log_time))\n",
    "    checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "    csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(log_time)), append=True, separator=';')\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        history_callback = model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=num_train_img // batch_size,\n",
    "                epochs=params.get(\"epochs\"),\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=num_val_img // batch_size,\n",
    "                callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "    except Exception as e:\n",
    "        raise(e)\n",
    "    finally:\n",
    "        pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "        model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "        print(params)\n",
    "        params\n",
    "        #with open(\"experiments\")\n",
    "        # Saving the Loss:\n",
    "        # with the csvlogger callback\n",
    "        # see the training callba balls\n",
    "\n",
    "        # with pandas\n",
    "        #pandas.DataFrame(history_callback.history).to_csv(\"history_small_convnet_rmsprop_50_100.csv\")\n",
    "\n",
    "        #with numpy\n",
    "        # loss_history = history_callback.history[\"loss\"]\n",
    "        # numpy_loss_history = np.array(loss_history)\n",
    "        # np.savetxt(\"loss_history_small_convnet_rmsprop_50_100.txt\", numpy_loss_history, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import glorot_uniform  # Or your initializer of choice\n",
    "def run(params):\n",
    "    import tensorflow as tf\n",
    "    sess = tf.Session()\n",
    "\n",
    "    from keras import backend as K\n",
    "    K.set_session(sess)\n",
    "    model = None\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    model = setup_model(params)\n",
    "    initial_weights = model.get_weights()\n",
    "    with sess.as_default():\n",
    "      new_weights = [glorot_uniform()(w.shape).eval() for w in initial_weights]\n",
    "    model.set_weights(new_weights)\n",
    "    train_generator, validation_generator = get_generators(params)\n",
    "\n",
    "    run_training(params.get(\"network_name\"), model, train_generator, validation_generator, params, 4604, 1094)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params = {'network_name': 'vgg16'\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD', \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import glorot_uniform  # Or your initializer of choice\n",
    "def run(params):\n",
    "    import tensorflow as tf\n",
    "    sess = tf.Session()\n",
    "\n",
    "    from keras import backend as K\n",
    "    K.set_session(sess)\n",
    "    model = None\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    model = setup_model(params)\n",
    "    initial_weights = model.get_weights()\n",
    "    with sess.as_default():\n",
    "      new_weights = [glorot_uniform()(w.shape).eval() for w in initial_weights]\n",
    "    model.set_weights(new_weights)\n",
    "    train_generator, validation_generator = get_generators(params)\n",
    "    run_training(model, train_generator, validation_generator, params, 4604, 1094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(259, 259, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionResNetV2(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# # let's add a fully-connected layer\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# # and a logistic layer -- let's say we have 200 classes\n",
    "# predictions = Dense(102, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Both Flatten and GlobalAveragePooling2D are valid options. So is GlobalMaxPooling2D.\n",
    "\n",
    "Flatten will result in a larger Dense layer afterwards, which is more expensive and may result in worse overfitting. But if you have lots of data, it might also perform better.\n",
    "\n",
    "As usual, it depends completely on your problem.\n",
    "\"\"\"\n",
    "\n",
    "# model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "# model.add(Dense(256))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(102, activation=\"softmax\"))\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)  # GlobalAveragePooling2D()(x) or GlobalMaxPooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  #256\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(102, activation='softmax')(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'SGD', \n",
    "         'batch_size': 128,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator = get_generators(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"inception_resnetv2_{}.h5\".format(log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"inception_resnetv2_{}.csv\".format(log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inception_v3 \n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"inceptionv3_{}.h5\".format(log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"inceptionv3_{}.csv\".format(log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINE TUNE TOP LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {\n",
    "    1: {'log_time': None, 'optimizer': optimizers.rmsprop, 'image_augmentation': True, \"tensorboard_id\":1},\n",
    "    2: {'log_time': None, 'optimizer': optimizers.rmsprop, 'image_augmentation': False, \"tensorboard_id\":2},\n",
    "    2: {'log_time': None, 'optimizer': optimizers.SGD(lr=0.0001, momentum=0.9), 'image_augmentation': True, \"tensorboard_id\":3},\n",
    "    2: {'log_time': None, 'optimizer': optimizers.SGD(lr=0.0001, momentum=0.9), 'image_augmentation': False, \"tensorboard_id\":4},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 16,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = setup_model(params)\n",
    "train_generator, validation_generator = get_generators(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(model, train_generator, validation_generator, params, 4604, 1094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['log_time'] = 1541280636.0738575\n",
    "params['optimizer'] = \"rmsprop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'sgd', \n",
    "         'batch_size': 16,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = setup_model(params)\n",
    "train_generator, validation_generator = get_generators(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(model, train_generator, validation_generator, params, 4604, 1094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'image_aug': False,\n",
    "#          'optimizer': 'sgd', \n",
    "#          'batch_size': 16,\n",
    "#          'epochs': 100,\n",
    "#          'image_size': (256, 256),\n",
    "#          'log_time': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['optimizer'] = \"adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'sgd', \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'sgd', \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add dropout after each conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'sgd', \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DROPOUT AGAIN ONLY ON DENSE LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'sgd', \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 16,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'adam', \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'adam', \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'adam', \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'adam', \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'sgd', \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'sgd', \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Loss:\n",
    "# with the csvlogger callback\n",
    "# see the training callba balls\n",
    "\n",
    "# with pandas\n",
    "#pandas.DataFrame(history_callback.history).to_csv(\"history_small_convnet_rmsprop_50_100.csv\")\n",
    "\n",
    "#with numpy\n",
    "# loss_history = history_callback.history[\"loss\"]\n",
    "# numpy_loss_history = np.array(loss_history)\n",
    "# np.savetxt(\"loss_history_small_convnet_rmsprop_50_100.txt\", numpy_loss_history, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(\"/data/oxford102/small_convnet_rmsprop_50_100.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# early = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "# tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()), histogram_freq=0, write_graph=True, write_images=True)\n",
    "# csv_logger = CSVLogger('small_convnet_1.csv', append=True, separator=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_callback = model.fit_generator(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=4604 // batch_size,\n",
    "#         epochs=50,\n",
    "#         validation_data=validation_generator,\n",
    "#         validation_steps=1094 // batch_size,\n",
    "#         callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "# #model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no image aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator = train_datagen_no_aug.flow_from_directory(\n",
    "#     data_dir,  # this is the target directory\n",
    "#     target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical',\n",
    "#     subset = \"training\")\n",
    "\n",
    "# validation_generator = train_datagen_no_aug.flow_from_directory(\n",
    "#     data_dir,  # this is the target directory\n",
    "#     target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical',\n",
    "#     subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(\"/data/oxford102/small_convnet_rmsprop_50_100_nodaug.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# early = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "# tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()), histogram_freq=0, write_graph=True, write_images=True)\n",
    "# csv_logger = CSVLogger('small_convnet_1.csv', append=True, separator=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_callback = model.fit_generator(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=4604 // batch_size,\n",
    "#         epochs=50,\n",
    "#         validation_data=validation_generator,\n",
    "#         validation_steps=1094 // batch_size,\n",
    "#         callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "# #model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 16,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 16,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'rmsprop', \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': \"rmsprop\", \n",
    "         'batch_size': 128,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': \"rmsprop\", \n",
    "         'batch_size': 128,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'sgd', \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'sgd', \n",
    "         'batch_size': 16,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'sgd', \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'sgd', \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'sgd', \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'sgd', \n",
    "         'batch_size': 16,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'sgd', \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'sgd', \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'adam', \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'adam', \n",
    "         'batch_size': 16,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'adam', \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': 'adam', \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': 'adam', \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change LR, dropout, momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': keras.optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.0), \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': keras.optimizers.RMSprop(lr=0.1, rho=0.9, epsilon=None, decay=0.0), \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': keras.optimizers.RMSprop(lr=0.001, rho=0.5, epsilon=None, decay=0.0), \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': keras.optimizers.RMSprop(lr=0.01, rho=0.5, epsilon=None, decay=0.0), \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': False,\n",
    "         'optimizer': keras.optimizers.RMSprop(lr=0.1, rho=0.5, epsilon=None, decay=0.0), \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the loss increases and the accuracy increase too is because your regularization techniques are working well and you're fighting the overfitting problem. This is true only if the loss, then, starts to decrease whilst the accuracy continues to increase. Otherwise, if the loss keep growing your model is diverging and you should look for the cause (usually you're using a too high learning rate value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decrease lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=None, decay=0.0), \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': keras.optimizers.RMSprop(lr=0.0001, rho=0.5, epsilon=None, decay=0.0), \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add decay, so we can get closer to the local minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': keras.optimizers.RMSprop(lr=0.001, rho=0.5, epsilon=None, decay=0.1), \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout (0.2 conv layers, 0.5 final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': \"rmsprop\",# keras.optimizers.RMSprop(lr=0.01, rho=0.5, epsilon=None, decay=0.0), \n",
    "         'batch_size': 128,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0), \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (128, 128),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_aug': True,\n",
    "         'optimizer': keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0), \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (512, 512),\n",
    "         'log_time': None}\n",
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "\n",
    "    image=mpimg.imread(img)\n",
    "    imgplot = plt.imshow(image)\n",
    "\n",
    "    image = load_img(img, target_size=(256, 256))\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    # do the same preprocessing as the vgg did\n",
    "    image = preprocess_input(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_arr):\n",
    "    # predict the probability across all output classes\n",
    "    yhat = model.predict(img_arr)\n",
    "    # convert the probabilities to class labels\n",
    "    label = decode_predictions(yhat)\n",
    "    # retrieve the most likely result, e.g. highest probability\n",
    "    label = label[0][0]\n",
    "    # print the classification\n",
    "    print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = '/data/oxford102/jpg/image_00001.jpg'\n",
    "image_array = preprocess_img(img)\n",
    "#predict(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='baseline_CNN.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_proba(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['pink primrose', 'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea', 'english marigold', 'tiger lily', 'moon orchid', 'bird of paradise', 'monkshood', 'globe thistle', 'snapdragon', \"colt's foot\", 'king protea', 'spear thistle', 'yellow iris', 'globe-flower', 'purple coneflower', 'peruvian lily', 'balloon flower', 'giant white arum lily', 'fire lily', 'pincushion flower', 'fritillary', 'red ginger', 'grape hyacinth', 'corn poppy', 'prince of wales feathers', 'stemless gentian', 'artichoke', 'sweet william', 'carnation', 'garden phlox', 'love in the mist', 'mexican aster', 'alpine sea holly', 'ruby-lipped cattleya', 'cape flower', 'great masterwort', 'siam tulip', 'lenten rose', 'barbeton daisy', 'daffodil', 'sword lily', 'poinsettia', 'bolero deep blue', 'wallflower', 'marigold', 'buttercup', 'oxeye daisy', 'common dandelion', 'petunia', 'wild pansy', 'primula', 'sunflower', 'pelargonium', 'bishop of llandaff', 'gaura', 'geranium', 'orange dahlia', 'pink-yellow dahlia?', 'cautleya spicata', 'japanese anemone', 'black-eyed susan', 'silverbush', 'californian poppy', 'osteospermum', 'spring crocus', 'bearded iris', 'windflower', 'tree poppy', 'gazania', 'azalea', 'water lily', 'rose', 'thorn apple', 'morning glory', 'passion flower', 'lotus', 'toad lily', 'anthurium', 'frangipani', 'clematis', 'hibiscus', 'columbine', 'desert-rose', 'tree mallow', 'magnolia', 'cyclamen ', 'watercress', 'canna lily', 'hippeastrum ', 'bee balm', 'ball moss', 'foxglove', 'bougainvillea', 'camellia', 'mallow', 'mexican petunia', 'bromelia', 'blanket flower', 'trumpet creeper', 'blackberry lily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_class_labels = np.array(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(pred[0]):\n",
    "    if x == 1.0:\n",
    "        print(_class_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict_generator(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities[1]> 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimizer=SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(\"/data/oxford102/small_convnet_sgd.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# early = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "# tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()), histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit_generator(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=5698 // batch_size,\n",
    "#         epochs=50,\n",
    "#         validation_data=validation_generator,\n",
    "#         validation_steps=2441 // batch_size,\n",
    "#         callbacks = [checkpoint, early, tensorboard])\n",
    "# #model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(\"/data/oxford102/small_convnet_rmsprop_more_augmentation.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# early = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "# tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()), histogram_freq=0, write_graph=True, write_images=True)\n",
    "# model.fit_generator(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=5698 // batch_size,\n",
    "#         epochs=50,\n",
    "#         validation_data=validation_generator,\n",
    "#         validation_steps=2441 // batch_size,\n",
    "#         callbacks = [checkpoint, early, tensorboard])\n",
    "# #model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 16\n",
    "\n",
    "# # this is the augmentation configuration we will use for training\n",
    "# train_datagen_no_aug = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         validation_split=0.2\n",
    "# )\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#         rotation_range=40,\n",
    "#         width_shift_range=0.2,\n",
    "#         height_shift_range=0.2,\n",
    "#         rescale=1./255,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True,\n",
    "#         fill_mode='nearest',\n",
    "#         validation_split=0.2)\n",
    "\n",
    "# # this is the augmentation configuration we will use for testing:\n",
    "# # only rescaling\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# # this is a generator that will read pictures found in\n",
    "# # subfolers of 'data/train', and indefinitely generate\n",
    "# # batches of augmented image data\n",
    "# # train_generator = train_datagen.flow_from_directory(\n",
    "# #         '/data/oxford102/train',  # this is the target directory\n",
    "# #         target_size=(150, 150),  # all images will be resized to 150x150\n",
    "# #         batch_size=batch_size,\n",
    "# #         class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# # # this is a similar generator, for validation data\n",
    "# # validation_generator = test_datagen.flow_from_directory(\n",
    "# #         '/data/oxford102/val',\n",
    "# #         target_size=(150, 150),\n",
    "# #         batch_size=batch_size,\n",
    "# #         class_mode='categorical')\n",
    "\n",
    "# data_dir = '/data/oxford102/train'\n",
    "# img_width, img_height = 256, 256\n",
    "# batch_size = 32\n",
    "# epochs = 100\n",
    "    \n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#     data_dir,  # this is the target directory\n",
    "#     target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical',\n",
    "#     subset = \"training\")\n",
    "\n",
    "# validation_generator = train_datagen.flow_from_directory(\n",
    "#     data_dir,  # this is the target directory\n",
    "#     target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical',\n",
    "#     subset=\"validation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
