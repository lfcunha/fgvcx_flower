{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.applications.mobilenet_v2 import decode_predictions\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow\n",
    "from time import time\n",
    "\n",
    "import pandas\n",
    "\n",
    "import pickle as pk\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Batch size with RMSprop.\n",
    "#### First, evaluate each size independently (restart kernel each time without clearing output).\n",
    "#### Then, to the, all sequential to get approximation of the weights really fast and improve accuracy sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16719645532637051605\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 155385856\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3924908777888707315\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MobileNetV2',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'absolute_import',\n",
       " 'decode_predictions',\n",
       " 'division',\n",
       " 'keras_modules_injection',\n",
       " 'mobilenet_v2',\n",
       " 'preprocess_input',\n",
       " 'print_function']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(keras.applications.mobilenet_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/oxford102/train'\n",
    "train_data_dir = \"/data/oxford102/train/\"\n",
    "validation_data_dir = \"/data/oxford102/train/\"\n",
    "img_width, img_height = 256, 256\n",
    "#batch_size = 32\n",
    "epochs = 100\n",
    "nr_categories = 102\n",
    "nb_train_samples = 4604\n",
    "nb_validation_samples = 1094 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_processor = applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_datagen = ImageDataGenerator(preprocessing_function=input_processor, \n",
    "                                           validation_split=0.2)\n",
    "\n",
    "train_val_datagen_aug = ImageDataGenerator(\n",
    "        #rescale=1. / 255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=input_processor,\n",
    "        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generators(batch_size, img_aug=False):\n",
    "    datagen = train_val_datagen if not train_val_datagen else train_val_datagen_aug\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "            train_data_dir,  # this is the target directory\n",
    "            target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "            batch_size=batch_size,\n",
    "            subset=\"training\",\n",
    "            class_mode='categorical')\n",
    "\n",
    "    validation_generator = train_val_datagen.flow_from_directory(\n",
    "            train_data_dir,  # this is the target directory\n",
    "            target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "            subset=\"validation\",\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "    \n",
    "    return train_generator, validation_generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras import regularizers\n",
    "\n",
    "\n",
    "def get_model(verbose=False, network_name=\"inception_resnet_v2\"):\n",
    "    k.set_learning_phase(0)\n",
    "\n",
    "    img_width, img_height = (256, 256)\n",
    "    if network_name == \"vgg16\":\n",
    "        base_model = keras.applications.vgg16.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "    elif network_name == \"vgg19\":\n",
    "        base_model = keras.applications.vgg19.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "    elif network_name == \"inception_resnet_v2\":\n",
    "        base_model = keras.applications.inception_resnet_v2.InceptionResNetV2(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "    elif network_name == \"mobilenet_v2\":\n",
    "        base_model = keras.applications.mobilenet_v2.MobileNetV2(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"check your network name\")\n",
    "\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "\n",
    "        #Adding custom Layers \n",
    "    k.set_learning_phase(1)\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation=\"relu\", \n",
    "              #kernel_regularizer=regularizers.l2(0.01),\n",
    "             #       activity_regularizer=regularizers.l1(0.001)\n",
    "             )(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x, training=True)\n",
    "    #x = Dense(102, activation=\"relu\")(x)\n",
    "    predictions = Dense(nr_categories, activation=\"softmax\")(x)\n",
    "\n",
    "    _model = Model(input = base_model.input, output = predictions)\n",
    "    \n",
    "    if verbose:\n",
    "        _model.summary()\n",
    "    \n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "\n",
    "def run(params):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    log_time = time()\n",
    "    params['log_time'] = log_time\n",
    "    batch_size = params.get(\"batch_size\")\n",
    "\n",
    "\n",
    "    train_generator, validation_generator = get_generators(batch_size)\n",
    "\n",
    "    _model = get_model(params[\"network_name\"])\n",
    "    _model.compile(loss = \"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "    base = '/data/oxford102/experiments'\n",
    "    path = os.path.join(base, str(log_time))\n",
    "    checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "    csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        history_callback = _model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=num_train_img // batch_size,\n",
    "                epochs=params.get(\"epochs\"),\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=num_val_img // batch_size,\n",
    "                callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "    except Exception as e:\n",
    "        raise(e)\n",
    "    finally:\n",
    "        pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "        _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "        print(params)\n",
    "        params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer_name': \"RMSprop\",\n",
    "         'optimizer': optimizers.RMSprop(lr=0.001),\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'RMSprop',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 256,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 30s 861ms/step - loss: 3.5846 - acc: 0.2348 - val_loss: 3.0738 - val_acc: 0.3203\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.32031, saving model to /data/oxford102/experiments/1544313888.896595/mobilenet_v2_1544313888.896595.h5\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 24s 679ms/step - loss: 2.8652 - acc: 0.3402 - val_loss: 2.7228 - val_acc: 0.3711\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.32031 to 0.37109, saving model to /data/oxford102/experiments/1544313888.896595/mobilenet_v2_1544313888.896595.h5\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 24s 684ms/step - loss: 2.5635 - acc: 0.4232 - val_loss: 2.3986 - val_acc: 0.4766\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.37109 to 0.47656, saving model to /data/oxford102/experiments/1544313888.896595/mobilenet_v2_1544313888.896595.h5\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 24s 683ms/step - loss: 2.4074 - acc: 0.4580 - val_loss: 2.2437 - val_acc: 0.5156\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.47656 to 0.51562, saving model to /data/oxford102/experiments/1544313888.896595/mobilenet_v2_1544313888.896595.h5\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 25s 717ms/step - loss: 1.8285 - acc: 0.6105 - val_loss: 2.1661 - val_acc: 0.5043\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.51562\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 24s 683ms/step - loss: 1.6730 - acc: 0.6366 - val_loss: 1.8676 - val_acc: 0.5820\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.51562 to 0.58203, saving model to /data/oxford102/experiments/1544313888.896595/mobilenet_v2_1544313888.896595.h5\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 24s 691ms/step - loss: 1.6045 - acc: 0.6643 - val_loss: 1.7866 - val_acc: 0.5859\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.58203 to 0.58594, saving model to /data/oxford102/experiments/1544313888.896595/mobilenet_v2_1544313888.896595.h5\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 24s 686ms/step - loss: 1.5214 - acc: 0.6696 - val_loss: 1.7575 - val_acc: 0.5625\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.58594\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 24s 672ms/step - loss: 1.1552 - acc: 0.7503 - val_loss: 1.6921 - val_acc: 0.6304\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.58594 to 0.63043, saving model to /data/oxford102/experiments/1544313888.896595/mobilenet_v2_1544313888.896595.h5\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 24s 685ms/step - loss: 1.0624 - acc: 0.7750 - val_loss: 1.5861 - val_acc: 0.6172\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.63043\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 24s 682ms/step - loss: 1.0818 - acc: 0.7723 - val_loss: 1.5266 - val_acc: 0.6328\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.63043 to 0.63281, saving model to /data/oxford102/experiments/1544313888.896595/mobilenet_v2_1544313888.896595.h5\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 24s 686ms/step - loss: 1.0489 - acc: 0.7866 - val_loss: 1.5002 - val_acc: 0.6602\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.63281 to 0.66016, saving model to /data/oxford102/experiments/1544313888.896595/mobilenet_v2_1544313888.896595.h5\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 24s 682ms/step - loss: 0.8534 - acc: 0.8341 - val_loss: 1.3136 - val_acc: 0.6680\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.66016 to 0.66797, saving model to /data/oxford102/experiments/1544313888.896595/mobilenet_v2_1544313888.896595.h5\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 24s 674ms/step - loss: 0.7705 - acc: 0.8545 - val_loss: 1.4514 - val_acc: 0.6652\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.66797\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 24s 681ms/step - loss: 0.7443 - acc: 0.8562 - val_loss: 1.4099 - val_acc: 0.6523\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.66797\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 24s 683ms/step - loss: 0.7287 - acc: 0.8589 - val_loss: 1.3072 - val_acc: 0.6836\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.66797 to 0.68359, saving model to /data/oxford102/experiments/1544313888.896595/mobilenet_v2_1544313888.896595.h5\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 24s 683ms/step - loss: 0.5570 - acc: 0.8925 - val_loss: 1.2408 - val_acc: 0.7031\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.68359 to 0.70312, saving model to /data/oxford102/experiments/1544313888.896595/mobilenet_v2_1544313888.896595.h5\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 23s 670ms/step - loss: 0.5113 - acc: 0.9080 - val_loss: 1.2283 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.70312 to 0.70435, saving model to /data/oxford102/experiments/1544313888.896595/mobilenet_v2_1544313888.896595.h5\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 24s 684ms/step - loss: 0.5156 - acc: 0.9027 - val_loss: 1.1790 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.70435 to 0.75000, saving model to /data/oxford102/experiments/1544313888.896595/mobilenet_v2_1544313888.896595.h5\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 24s 682ms/step - loss: 0.5212 - acc: 0.9054 - val_loss: 1.3271 - val_acc: 0.6484\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.75000\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 24s 680ms/step - loss: 0.4195 - acc: 0.9258 - val_loss: 1.2581 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.75000\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 24s 672ms/step - loss: 0.3802 - acc: 0.9330 - val_loss: 1.2421 - val_acc: 0.6870\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.75000\n",
      "Epoch 00022: early stopping\n",
      "{'network_name': 'vgg19', 'image_aug': False, 'optimizer': 'RMSprop', 'optimizer_params': None, 'batch_size': 128, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1544313888.896595}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'RMSprop',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 128,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 55s 769ms/step - loss: 3.1814 - acc: 0.3072 - val_loss: 2.6400 - val_acc: 0.4320\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.43199, saving model to /data/oxford102/experiments/1544321516.4379833/mobilenet_v2_1544321516.4379833.h5\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 49s 685ms/step - loss: 2.4163 - acc: 0.4626 - val_loss: 2.2147 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.43199 to 0.50551, saving model to /data/oxford102/experiments/1544321516.4379833/mobilenet_v2_1544321516.4379833.h5\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 50s 704ms/step - loss: 1.6797 - acc: 0.6342 - val_loss: 1.9133 - val_acc: 0.5695\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.50551 to 0.56950, saving model to /data/oxford102/experiments/1544321516.4379833/mobilenet_v2_1544321516.4379833.h5\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 49s 688ms/step - loss: 1.5051 - acc: 0.6774 - val_loss: 1.6431 - val_acc: 0.6121\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.56950 to 0.61213, saving model to /data/oxford102/experiments/1544321516.4379833/mobilenet_v2_1544321516.4379833.h5\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 48s 682ms/step - loss: 1.0723 - acc: 0.7787 - val_loss: 1.6126 - val_acc: 0.6216\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.61213 to 0.62162, saving model to /data/oxford102/experiments/1544321516.4379833/mobilenet_v2_1544321516.4379833.h5\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 49s 688ms/step - loss: 1.0372 - acc: 0.7905 - val_loss: 1.4587 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.62162 to 0.64706, saving model to /data/oxford102/experiments/1544321516.4379833/mobilenet_v2_1544321516.4379833.h5\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 48s 682ms/step - loss: 0.7526 - acc: 0.8588 - val_loss: 1.3650 - val_acc: 0.6448\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.64706\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 49s 686ms/step - loss: 0.6809 - acc: 0.8737 - val_loss: 1.2665 - val_acc: 0.6949\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.64706 to 0.69485, saving model to /data/oxford102/experiments/1544321516.4379833/mobilenet_v2_1544321516.4379833.h5\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 48s 682ms/step - loss: 0.5026 - acc: 0.9162 - val_loss: 1.2659 - val_acc: 0.6988\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.69485 to 0.69884, saving model to /data/oxford102/experiments/1544321516.4379833/mobilenet_v2_1544321516.4379833.h5\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 49s 687ms/step - loss: 0.5071 - acc: 0.9137 - val_loss: 1.2822 - val_acc: 0.6691\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.69884\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 48s 681ms/step - loss: 0.3776 - acc: 0.9342 - val_loss: 1.2444 - val_acc: 0.6853\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.69884\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 49s 686ms/step - loss: 0.3507 - acc: 0.9357 - val_loss: 1.2066 - val_acc: 0.6930\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.69884\n",
      "Epoch 00012: early stopping\n",
      "{'network_name': 'vgg19', 'image_aug': False, 'optimizer': 'RMSprop', 'optimizer_params': None, 'batch_size': 64, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1544321516.4379833}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'RMSprop',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "143/143 [==============================] - 104s 728ms/step - loss: 2.8257 - acc: 0.3722 - val_loss: 2.2077 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.50000, saving model to /data/oxford102/experiments/1544322364.962447/mobilenet_v2_1544322364.962447.h5\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 99s 692ms/step - loss: 1.6082 - acc: 0.6630 - val_loss: 1.7285 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.50000 to 0.60358, saving model to /data/oxford102/experiments/1544322364.962447/mobilenet_v2_1544322364.962447.h5\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 98s 684ms/step - loss: 1.0723 - acc: 0.7830 - val_loss: 1.4895 - val_acc: 0.6375\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.60358 to 0.63748, saving model to /data/oxford102/experiments/1544322364.962447/mobilenet_v2_1544322364.962447.h5\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 98s 683ms/step - loss: 0.7257 - acc: 0.8654 - val_loss: 1.2789 - val_acc: 0.6836\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.63748 to 0.68362, saving model to /data/oxford102/experiments/1544322364.962447/mobilenet_v2_1544322364.962447.h5\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 98s 683ms/step - loss: 0.5229 - acc: 0.9075 - val_loss: 1.3222 - val_acc: 0.6629\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.68362\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 98s 683ms/step - loss: 0.4137 - acc: 0.9310 - val_loss: 1.2218 - val_acc: 0.7024\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.68362 to 0.70245, saving model to /data/oxford102/experiments/1544322364.962447/mobilenet_v2_1544322364.962447.h5\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 98s 683ms/step - loss: 0.3171 - acc: 0.9499 - val_loss: 1.2053 - val_acc: 0.7034\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.70245 to 0.70339, saving model to /data/oxford102/experiments/1544322364.962447/mobilenet_v2_1544322364.962447.h5\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 98s 683ms/step - loss: 0.2580 - acc: 0.9600 - val_loss: 1.1753 - val_acc: 0.7024\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.70339\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 98s 683ms/step - loss: 0.2223 - acc: 0.9611 - val_loss: 1.1246 - val_acc: 0.7232\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.70339 to 0.72316, saving model to /data/oxford102/experiments/1544322364.962447/mobilenet_v2_1544322364.962447.h5\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 98s 682ms/step - loss: 0.1915 - acc: 0.9687 - val_loss: 1.1740 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.72316\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 98s 682ms/step - loss: 0.1785 - acc: 0.9720 - val_loss: 1.1527 - val_acc: 0.7166\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.72316\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 97s 682ms/step - loss: 0.1374 - acc: 0.9814 - val_loss: 1.0511 - val_acc: 0.7382\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.72316 to 0.73823, saving model to /data/oxford102/experiments/1544322364.962447/mobilenet_v2_1544322364.962447.h5\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 98s 682ms/step - loss: 0.1331 - acc: 0.9801 - val_loss: 1.1224 - val_acc: 0.7090\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.73823\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 97s 681ms/step - loss: 0.1246 - acc: 0.9790 - val_loss: 1.2036 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.73823\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 97s 681ms/step - loss: 0.1273 - acc: 0.9777 - val_loss: 1.0579 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.73823\n",
      "Epoch 00015: early stopping\n",
      "{'network_name': 'vgg19', 'image_aug': False, 'optimizer': 'RMSprop', 'optimizer_params': None, 'batch_size': 32, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1544322364.962447}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'RMSprop',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "287/287 [==============================] - 204s 711ms/step - loss: 2.1876 - acc: 0.5239 - val_loss: 1.6708 - val_acc: 0.6093\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.60930, saving model to /data/oxford102/experiments/1544324718.4162903/mobilenet_v2_1544324718.4162903.h5\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 196s 682ms/step - loss: 0.8537 - acc: 0.8272 - val_loss: 1.3012 - val_acc: 0.6784\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.60930 to 0.67844, saving model to /data/oxford102/experiments/1544324718.4162903/mobilenet_v2_1544324718.4162903.h5\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 196s 683ms/step - loss: 0.4377 - acc: 0.9240 - val_loss: 1.1310 - val_acc: 0.7269\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.67844 to 0.72693, saving model to /data/oxford102/experiments/1544324718.4162903/mobilenet_v2_1544324718.4162903.h5\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 196s 683ms/step - loss: 0.2630 - acc: 0.9578 - val_loss: 1.1568 - val_acc: 0.7095\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.72693\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 196s 683ms/step - loss: 0.1877 - acc: 0.9703 - val_loss: 1.1189 - val_acc: 0.7185\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.72693\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 196s 682ms/step - loss: 0.1467 - acc: 0.9774 - val_loss: 1.1662 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.72693\n",
      "Epoch 00006: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'RMSprop', 'optimizer_params': None, 'batch_size': 16, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1544324718.4162903}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'mobilenet_v2',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'RMSprop',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 16,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "575/575 [==============================] - 403s 701ms/step - loss: 1.5411 - acc: 0.6723 - val_loss: 1.3399 - val_acc: 0.6692\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66916, saving model to /data/oxford102/experiments/1544399249.5668316/mobilenet_v2_1544399249.5668316.h5\n",
      "Epoch 2/100\n",
      "575/575 [==============================] - 393s 683ms/step - loss: 0.3679 - acc: 0.9373 - val_loss: 1.1550 - val_acc: 0.7090\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.66916 to 0.70904, saving model to /data/oxford102/experiments/1544399249.5668316/mobilenet_v2_1544399249.5668316.h5\n",
      "Epoch 3/100\n",
      "575/575 [==============================] - 392s 682ms/step - loss: 0.1783 - acc: 0.9726 - val_loss: 1.1863 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.70904\n",
      "Epoch 4/100\n",
      "575/575 [==============================] - 392s 682ms/step - loss: 0.1210 - acc: 0.9810 - val_loss: 1.1200 - val_acc: 0.7149\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.70904 to 0.71492, saving model to /data/oxford102/experiments/1544399249.5668316/mobilenet_v2_1544399249.5668316.h5\n",
      "Epoch 5/100\n",
      "575/575 [==============================] - 392s 682ms/step - loss: 0.0908 - acc: 0.9856 - val_loss: 1.1872 - val_acc: 0.7135\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.71492\n",
      "Epoch 6/100\n",
      "575/575 [==============================] - 392s 681ms/step - loss: 0.0736 - acc: 0.9892 - val_loss: 1.1539 - val_acc: 0.7206\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.71492 to 0.72057, saving model to /data/oxford102/experiments/1544399249.5668316/mobilenet_v2_1544399249.5668316.h5\n",
      "Epoch 7/100\n",
      "575/575 [==============================] - 392s 682ms/step - loss: 0.0612 - acc: 0.9915 - val_loss: 1.2163 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.72057\n",
      "Epoch 8/100\n",
      "575/575 [==============================] - 392s 681ms/step - loss: 0.0539 - acc: 0.9918 - val_loss: 1.2508 - val_acc: 0.7105\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.72057\n",
      "Epoch 9/100\n",
      "575/575 [==============================] - 392s 682ms/step - loss: 0.0525 - acc: 0.9924 - val_loss: 1.2755 - val_acc: 0.7068\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.72057\n",
      "Epoch 00009: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'RMSprop', 'optimizer_params': None, 'batch_size': 8, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1544399249.5668316}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'mobilenet_v2',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'RMSprop',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN BATCHE SIZES SEQUENTIAL (no restart of kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1649 - acc: 0.9844 - val_loss: 1.1774 - val_acc: 0.7344\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.73438, saving model to /data/oxford102/experiments/1544329528.7978303/mobilenet_v2_1544329528.7978303.h5\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 6s 698ms/step - loss: 0.2239 - acc: 0.9727 - val_loss: 1.2865 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.73438\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 5s 683ms/step - loss: 0.2118 - acc: 0.9688 - val_loss: 1.0640 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.73438 to 0.78125, saving model to /data/oxford102/experiments/1544329528.7978303/mobilenet_v2_1544329528.7978303.h5\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 6s 688ms/step - loss: 0.1862 - acc: 0.9766 - val_loss: 1.4649 - val_acc: 0.6094\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.78125\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 5s 684ms/step - loss: 0.2061 - acc: 0.9609 - val_loss: 1.3113 - val_acc: 0.7031\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.78125\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 6s 689ms/step - loss: 0.1702 - acc: 0.9766 - val_loss: 1.1727 - val_acc: 0.6562\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.78125\n",
      "Epoch 00006: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'RMSprop', 'optimizer_params': None, 'batch_size': 512, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1544329528.7978303}\n"
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'RMSprop',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 512,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 17s 982ms/step - loss: 0.2301 - acc: 0.9651 - val_loss: 1.3921 - val_acc: 0.6250\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.62500, saving model to /data/oxford102/experiments/1544329584.4107325/mobilenet_v2_1544329584.4107325.h5\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 11s 661ms/step - loss: 0.1688 - acc: 0.9816 - val_loss: 1.3094 - val_acc: 0.7157\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.62500 to 0.71569, saving model to /data/oxford102/experiments/1544329584.4107325/mobilenet_v2_1544329584.4107325.h5\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 12s 686ms/step - loss: 0.1453 - acc: 0.9779 - val_loss: 1.2163 - val_acc: 0.6797\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.71569\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 12s 686ms/step - loss: 0.2289 - acc: 0.9596 - val_loss: 1.0969 - val_acc: 0.7344\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.71569 to 0.73438, saving model to /data/oxford102/experiments/1544329584.4107325/mobilenet_v2_1544329584.4107325.h5\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 12s 690ms/step - loss: 0.1854 - acc: 0.9758 - val_loss: 1.1594 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.73438\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 12s 684ms/step - loss: 0.1638 - acc: 0.9651 - val_loss: 1.0879 - val_acc: 0.6953\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.73438\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 12s 684ms/step - loss: 0.1388 - acc: 0.9816 - val_loss: 0.9973 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.73438 to 0.78125, saving model to /data/oxford102/experiments/1544329584.4107325/mobilenet_v2_1544329584.4107325.h5\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 12s 691ms/step - loss: 0.1102 - acc: 0.9908 - val_loss: 1.2024 - val_acc: 0.6797\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.78125\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 12s 684ms/step - loss: 0.1653 - acc: 0.9724 - val_loss: 1.3071 - val_acc: 0.6719\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.78125\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 11s 662ms/step - loss: 0.1276 - acc: 0.9853 - val_loss: 0.9456 - val_acc: 0.7059\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.78125\n",
      "Epoch 00010: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'RMSprop', 'optimizer_params': None, 'batch_size': 256, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1544329584.4107325}\n"
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'RMSprop',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 256,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 28s 793ms/step - loss: 0.2139 - acc: 0.9625 - val_loss: 1.0995 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.71094, saving model to /data/oxford102/experiments/1544329740.684749/mobilenet_v2_1544329740.684749.h5\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 24s 680ms/step - loss: 0.1259 - acc: 0.9837 - val_loss: 1.0764 - val_acc: 0.7578\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.71094 to 0.75781, saving model to /data/oxford102/experiments/1544329740.684749/mobilenet_v2_1544329740.684749.h5\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 23s 671ms/step - loss: 0.1215 - acc: 0.9857 - val_loss: 1.1856 - val_acc: 0.6913\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.75781\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 24s 678ms/step - loss: 0.1274 - acc: 0.9813 - val_loss: 1.0628 - val_acc: 0.7422\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.75781\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 24s 681ms/step - loss: 0.1478 - acc: 0.9732 - val_loss: 1.3182 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.75781\n",
      "Epoch 00005: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'RMSprop', 'optimizer_params': None, 'batch_size': 128, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1544329740.684749}\n"
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'RMSprop',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 128,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 53s 753ms/step - loss: 0.1639 - acc: 0.9762 - val_loss: 1.1253 - val_acc: 0.7181\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.71815, saving model to /data/oxford102/experiments/1544329882.089569/mobilenet_v2_1544329882.089569.h5\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 49s 686ms/step - loss: 0.1255 - acc: 0.9815 - val_loss: 1.1536 - val_acc: 0.7261\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.71815 to 0.72610, saving model to /data/oxford102/experiments/1544329882.089569/mobilenet_v2_1544329882.089569.h5\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 48s 682ms/step - loss: 0.1108 - acc: 0.9824 - val_loss: 1.1970 - val_acc: 0.6931\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.72610\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 49s 685ms/step - loss: 0.1124 - acc: 0.9810 - val_loss: 1.1961 - val_acc: 0.7316\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.72610 to 0.73162, saving model to /data/oxford102/experiments/1544329882.089569/mobilenet_v2_1544329882.089569.h5\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 48s 681ms/step - loss: 0.1053 - acc: 0.9833 - val_loss: 1.2451 - val_acc: 0.6853\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.73162\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 49s 685ms/step - loss: 0.1141 - acc: 0.9806 - val_loss: 1.1622 - val_acc: 0.7206\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.73162\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 48s 680ms/step - loss: 0.0921 - acc: 0.9846 - val_loss: 1.1569 - val_acc: 0.7104\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.73162\n",
      "Epoch 00007: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'RMSprop', 'optimizer_params': None, 'batch_size': 64, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1544329882.089569}\n"
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'RMSprop',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "143/143 [==============================] - 102s 717ms/step - loss: 0.1109 - acc: 0.9803 - val_loss: 1.1367 - val_acc: 0.7241\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.72411, saving model to /data/oxford102/experiments/1544330253.19369/mobilenet_v2_1544330253.19369.h5\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 98s 683ms/step - loss: 0.0811 - acc: 0.9889 - val_loss: 1.2432 - val_acc: 0.7090\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.72411\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 98s 682ms/step - loss: 0.0959 - acc: 0.9847 - val_loss: 1.1647 - val_acc: 0.7260\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.72411 to 0.72599, saving model to /data/oxford102/experiments/1544330253.19369/mobilenet_v2_1544330253.19369.h5\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 98s 682ms/step - loss: 0.0768 - acc: 0.9886 - val_loss: 1.1317 - val_acc: 0.7250\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.72599\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 97s 681ms/step - loss: 0.0702 - acc: 0.9908 - val_loss: 1.2014 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.72599\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 97s 681ms/step - loss: 0.0726 - acc: 0.9895 - val_loss: 1.3137 - val_acc: 0.6911\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.72599\n",
      "Epoch 00006: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'RMSprop', 'optimizer_params': None, 'batch_size': 32, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1544330253.19369}\n"
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'RMSprop',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "287/287 [==============================] - 201s 699ms/step - loss: 0.0806 - acc: 0.9874 - val_loss: 1.1497 - val_acc: 0.7232\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.72316, saving model to /data/oxford102/experiments/1544330862.5871413/mobilenet_v2_1544330862.5871413.h5\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 195s 680ms/step - loss: 0.0666 - acc: 0.9901 - val_loss: 1.1626 - val_acc: 0.7218\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.72316\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 195s 679ms/step - loss: 0.0582 - acc: 0.9915 - val_loss: 1.1660 - val_acc: 0.7194\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.72316\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 195s 679ms/step - loss: 0.0541 - acc: 0.9918 - val_loss: 1.2133 - val_acc: 0.7232\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.72316 to 0.72316, saving model to /data/oxford102/experiments/1544330862.5871413/mobilenet_v2_1544330862.5871413.h5\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 195s 681ms/step - loss: 0.0546 - acc: 0.9917 - val_loss: 1.2185 - val_acc: 0.7133\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.72316\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 195s 680ms/step - loss: 0.0504 - acc: 0.9928 - val_loss: 1.2078 - val_acc: 0.7133\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.72316\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 195s 679ms/step - loss: 0.0510 - acc: 0.9923 - val_loss: 1.2968 - val_acc: 0.7090\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.72316\n",
      "Epoch 00007: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'RMSprop', 'optimizer_params': None, 'batch_size': 16, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1544330862.5871413}\n"
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'RMSprop',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 16,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "575/575 [==============================] - 397s 690ms/step - loss: 0.0552 - acc: 0.9925 - val_loss: 1.2356 - val_acc: 0.7090\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.70904, saving model to /data/oxford102/experiments/1544332252.6100016/mobilenet_v2_1544332252.6100016.h5\n",
      "Epoch 2/100\n",
      "575/575 [==============================] - 391s 681ms/step - loss: 0.0414 - acc: 0.9940 - val_loss: 1.2587 - val_acc: 0.7142\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.70904 to 0.71422, saving model to /data/oxford102/experiments/1544332252.6100016/mobilenet_v2_1544332252.6100016.h5\n",
      "Epoch 3/100\n",
      "459/575 [======================>.......] - ETA: 1:05 - loss: 0.0390 - acc: 0.9948{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'RMSprop', 'optimizer_params': None, 'batch_size': 8, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1544332252.6100016}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-fde69bb22279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_val_img\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             callbacks = [checkpoint, early, tensorboard, csv_logger])\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'RMSprop',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINETUNE TOP LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(base_model.layers[619:]):\n",
    "    print(i, layer.name)\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 51s 723ms/step - loss: 0.1369 - acc: 0.9802 - val_loss: 1.1463 - val_acc: 0.6834\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.68340, saving model to /data/oxford102/experiments/1544327751.1324658/vgg19_1544327751.1324658.h5\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 47s 665ms/step - loss: 0.1201 - acc: 0.9859 - val_loss: 1.2191 - val_acc: 0.6985\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.68340 to 0.69853, saving model to /data/oxford102/experiments/1544327751.1324658/vgg19_1544327751.1324658.h5\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 47s 661ms/step - loss: 0.1182 - acc: 0.9824 - val_loss: 1.0393 - val_acc: 0.7124\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.69853 to 0.71236, saving model to /data/oxford102/experiments/1544327751.1324658/vgg19_1544327751.1324658.h5\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 47s 663ms/step - loss: 0.1097 - acc: 0.9832 - val_loss: 1.1543 - val_acc: 0.7096\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.71236\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 47s 660ms/step - loss: 0.1159 - acc: 0.9837 - val_loss: 1.1926 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.71236\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 47s 662ms/step - loss: 0.0997 - acc: 0.9899 - val_loss: 1.0985 - val_acc: 0.6985\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.71236\n",
      "Epoch 00006: early stopping\n",
      "{'network_name': 'vgg19', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 64, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1544327751.1324658}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"vgg19\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
