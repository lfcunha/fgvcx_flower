{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.applications.mobilenet_v2 import decode_predictions\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow\n",
    "from time import time\n",
    "\n",
    "import pandas\n",
    "\n",
    "import pickle as pk\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Batch size with SGD.\n",
    "#### First, evaluate each size independently (restart kernel each time without clearing output).\n",
    "#### Then, to the, all sequential to get approximation of the weights really fast and improve accuracy sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14569439545989952112\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 155385856\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17018183478892526836\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MobileNetV2',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'absolute_import',\n",
       " 'decode_predictions',\n",
       " 'division',\n",
       " 'keras_modules_injection',\n",
       " 'mobilenet_v2',\n",
       " 'preprocess_input',\n",
       " 'print_function']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(keras.applications.mobilenet_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/oxford102/train'\n",
    "img_width, img_height = 256, 256\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "nr_categories = 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 256, 256\n",
    "train_data_dir = \"/data/oxford102/train/\"\n",
    "validation_data_dir = \"/data/oxford102/train/\"\n",
    "nb_train_samples = 4604\n",
    "nb_validation_samples = 1094 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_processor = applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_datagen = ImageDataGenerator(preprocessing_function=input_processor, \n",
    "                                           validation_split=0.2)\n",
    "\n",
    "train_val_datagen_aug = ImageDataGenerator(\n",
    "        #rescale=1. / 255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=input_processor,\n",
    "        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "train_generator = train_val_datagen.flow_from_directory(\n",
    "        train_data_dir,  # this is the target directory\n",
    "        target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "        batch_size=batch_size,\n",
    "        subset=\"training\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = train_val_datagen.flow_from_directory(\n",
    "        train_data_dir,  # this is the target directory\n",
    "        target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "        subset=\"validation\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras import regularizers\n",
    "\n",
    "k.set_learning_phase(0)\n",
    "\n",
    "network_name = \"inception_resnet_v2\"\n",
    "img_width, img_height = (256, 256)\n",
    "if network_name == \"vgg16\":\n",
    "    base_model = keras.applications.vgg16.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "elif network_name == \"vgg19\":\n",
    "    base_model = keras.applications.vgg19.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "elif network_name == \"inception_resnet_v2\":\n",
    "    base_model = keras.applications.inception_resnet_v2.InceptionResNetV2(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "elif network_name == \"mobilenet_v2\":\n",
    "    base_model = keras.applications.mobilenet_v2.MobileNetV2(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "\n",
    "else:\n",
    "    raise Exception(\"check your network name\")\n",
    "\n",
    "for layer in base_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "    #Adding custom Layers \n",
    "k.set_learning_phase(1)\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\", \n",
    "          #kernel_regularizer=regularizers.l2(0.01),\n",
    "         #       activity_regularizer=regularizers.l1(0.001)\n",
    "         )(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x, training=True)\n",
    "#x = Dense(102, activation=\"relu\")(x)\n",
    "predictions = Dense(nr_categories, activation=\"softmax\")(x)\n",
    "\n",
    "_model = Model(input = base_model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 5.0864 - acc: 0.0234 - val_loss: 4.7734 - val_acc: 0.0625\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.06250, saving model to /data/oxford102/experiments/1543693601.6052575/mobilenet_v2_1543693601.6052575.h5\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 6s 701ms/step - loss: 4.3289 - acc: 0.0938 - val_loss: 4.1550 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.06250 to 0.12500, saving model to /data/oxford102/experiments/1543693601.6052575/mobilenet_v2_1543693601.6052575.h5\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 6s 697ms/step - loss: 3.7408 - acc: 0.2227 - val_loss: 3.8572 - val_acc: 0.1875\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.12500 to 0.18750, saving model to /data/oxford102/experiments/1543693601.6052575/mobilenet_v2_1543693601.6052575.h5\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 6s 690ms/step - loss: 3.5255 - acc: 0.2148 - val_loss: 3.6086 - val_acc: 0.2031\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.18750 to 0.20312, saving model to /data/oxford102/experiments/1543693601.6052575/mobilenet_v2_1543693601.6052575.h5\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 6s 691ms/step - loss: 3.3208 - acc: 0.2734 - val_loss: 3.4750 - val_acc: 0.2344\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.20312 to 0.23438, saving model to /data/oxford102/experiments/1543693601.6052575/mobilenet_v2_1543693601.6052575.h5\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 6s 703ms/step - loss: 3.3038 - acc: 0.2656 - val_loss: 3.1519 - val_acc: 0.3125\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.23438 to 0.31250, saving model to /data/oxford102/experiments/1543693601.6052575/mobilenet_v2_1543693601.6052575.h5\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 6s 691ms/step - loss: 3.2116 - acc: 0.2695 - val_loss: 2.9379 - val_acc: 0.2969\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.31250\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 6s 691ms/step - loss: 3.0529 - acc: 0.2656 - val_loss: 3.0731 - val_acc: 0.2500\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.31250\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 6s 692ms/step - loss: 2.9903 - acc: 0.2930 - val_loss: 2.6792 - val_acc: 0.4219\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.31250 to 0.42188, saving model to /data/oxford102/experiments/1543693601.6052575/mobilenet_v2_1543693601.6052575.h5\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 6s 691ms/step - loss: 2.9611 - acc: 0.2617 - val_loss: 2.9345 - val_acc: 0.3125\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.42188\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 6s 696ms/step - loss: 2.7354 - acc: 0.3789 - val_loss: 2.4294 - val_acc: 0.4531\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.42188 to 0.45312, saving model to /data/oxford102/experiments/1543693601.6052575/mobilenet_v2_1543693601.6052575.h5\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 6s 701ms/step - loss: 2.7011 - acc: 0.3984 - val_loss: 2.6692 - val_acc: 0.3906\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.45312\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 6s 695ms/step - loss: 2.7050 - acc: 0.3750 - val_loss: 2.6140 - val_acc: 0.3438\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.45312\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 6s 695ms/step - loss: 2.6287 - acc: 0.3906 - val_loss: 2.6604 - val_acc: 0.3438\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.45312\n",
      "Epoch 00014: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 512, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543693601.6052575}\n"
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 512,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 18s 1s/step - loss: 4.6732 - acc: 0.0551 - val_loss: 4.0026 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.12500, saving model to /data/oxford102/experiments/1543694274.3468575/mobilenet_v2_1543694274.3468575.h5\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 12s 681ms/step - loss: 3.6736 - acc: 0.2040 - val_loss: 3.5287 - val_acc: 0.2188\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.12500 to 0.21875, saving model to /data/oxford102/experiments/1543694274.3468575/mobilenet_v2_1543694274.3468575.h5\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 12s 683ms/step - loss: 3.3118 - acc: 0.2537 - val_loss: 2.8055 - val_acc: 0.3359\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.21875 to 0.33594, saving model to /data/oxford102/experiments/1543694274.3468575/mobilenet_v2_1543694274.3468575.h5\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 12s 682ms/step - loss: 3.0461 - acc: 0.3143 - val_loss: 2.9778 - val_acc: 0.2734\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.33594\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 12s 685ms/step - loss: 2.9547 - acc: 0.3125 - val_loss: 3.0340 - val_acc: 0.3203\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.33594\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 12s 685ms/step - loss: 2.8496 - acc: 0.3640 - val_loss: 2.7419 - val_acc: 0.3359\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.33594\n",
      "Epoch 00006: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 256, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543694274.3468575}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 256,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 31s 875ms/step - loss: 4.1742 - acc: 0.1321 - val_loss: 3.5311 - val_acc: 0.2305\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.23047, saving model to /data/oxford102/experiments/1543694982.5953884/mobilenet_v2_1543694982.5953884.h5\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 24s 680ms/step - loss: 3.2298 - acc: 0.2554 - val_loss: 2.7678 - val_acc: 0.3477\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.23047 to 0.34766, saving model to /data/oxford102/experiments/1543694982.5953884/mobilenet_v2_1543694982.5953884.h5\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 24s 683ms/step - loss: 2.8592 - acc: 0.3348 - val_loss: 2.8644 - val_acc: 0.3164\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.34766\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 24s 682ms/step - loss: 2.5642 - acc: 0.4286 - val_loss: 2.3770 - val_acc: 0.4219\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.34766 to 0.42188, saving model to /data/oxford102/experiments/1543694982.5953884/mobilenet_v2_1543694982.5953884.h5\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 25s 719ms/step - loss: 2.1416 - acc: 0.5280 - val_loss: 2.3954 - val_acc: 0.4478\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.42188 to 0.44783, saving model to /data/oxford102/experiments/1543694982.5953884/mobilenet_v2_1543694982.5953884.h5\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 24s 685ms/step - loss: 1.9648 - acc: 0.5598 - val_loss: 2.2345 - val_acc: 0.4961\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.44783 to 0.49609, saving model to /data/oxford102/experiments/1543694982.5953884/mobilenet_v2_1543694982.5953884.h5\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 24s 687ms/step - loss: 1.8590 - acc: 0.5982 - val_loss: 2.1999 - val_acc: 0.4648\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.49609\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 24s 686ms/step - loss: 1.8554 - acc: 0.6018 - val_loss: 2.0456 - val_acc: 0.5352\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.49609 to 0.53516, saving model to /data/oxford102/experiments/1543694982.5953884/mobilenet_v2_1543694982.5953884.h5\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 24s 675ms/step - loss: 1.6381 - acc: 0.6518 - val_loss: 2.0168 - val_acc: 0.5391\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.53516 to 0.53913, saving model to /data/oxford102/experiments/1543694982.5953884/mobilenet_v2_1543694982.5953884.h5\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 24s 684ms/step - loss: 1.4516 - acc: 0.7018 - val_loss: 1.8906 - val_acc: 0.5781\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.53913 to 0.57812, saving model to /data/oxford102/experiments/1543694982.5953884/mobilenet_v2_1543694982.5953884.h5\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 24s 687ms/step - loss: 1.4379 - acc: 0.7063 - val_loss: 1.7671 - val_acc: 0.5664\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.57812\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 24s 686ms/step - loss: 1.4719 - acc: 0.6857 - val_loss: 2.0408 - val_acc: 0.5078\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.57812\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 24s 685ms/step - loss: 1.2697 - acc: 0.7486 - val_loss: 1.7993 - val_acc: 0.5820\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.57812 to 0.58203, saving model to /data/oxford102/experiments/1543694982.5953884/mobilenet_v2_1543694982.5953884.h5\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 24s 676ms/step - loss: 1.2269 - acc: 0.7679 - val_loss: 1.7131 - val_acc: 0.6522\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.58203 to 0.65217, saving model to /data/oxford102/experiments/1543694982.5953884/mobilenet_v2_1543694982.5953884.h5\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 24s 684ms/step - loss: 1.1602 - acc: 0.7821 - val_loss: 1.8231 - val_acc: 0.5703\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.65217\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 24s 684ms/step - loss: 1.1381 - acc: 0.7714 - val_loss: 1.6607 - val_acc: 0.6445\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.65217\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 24s 684ms/step - loss: 1.0381 - acc: 0.8171 - val_loss: 1.5433 - val_acc: 0.6562\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.65217 to 0.65625, saving model to /data/oxford102/experiments/1543694982.5953884/mobilenet_v2_1543694982.5953884.h5\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 24s 677ms/step - loss: 0.9960 - acc: 0.8321 - val_loss: 1.6259 - val_acc: 0.6435\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.65625\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 24s 685ms/step - loss: 0.9676 - acc: 0.8277 - val_loss: 1.3998 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.65625 to 0.71094, saving model to /data/oxford102/experiments/1543694982.5953884/mobilenet_v2_1543694982.5953884.h5\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 24s 687ms/step - loss: 0.9581 - acc: 0.8366 - val_loss: 1.6724 - val_acc: 0.6172\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.71094\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 24s 685ms/step - loss: 0.8611 - acc: 0.8520 - val_loss: 1.7051 - val_acc: 0.6172\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.71094\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 24s 675ms/step - loss: 0.8083 - acc: 0.8857 - val_loss: 1.4104 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.71094\n",
      "Epoch 00022: early stopping\n",
      "{'network_name': 'vgg19', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 128, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543694982.5953884}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 128,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 56s 788ms/step - loss: 3.6405 - acc: 0.2232 - val_loss: 2.9654 - val_acc: 0.2941\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.29412, saving model to /data/oxford102/experiments/1543696022.9753711/mobilenet_v2_1543696022.9753711.h5\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 49s 686ms/step - loss: 2.6617 - acc: 0.3627 - val_loss: 2.4622 - val_acc: 0.4210\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.29412 to 0.42096, saving model to /data/oxford102/experiments/1543696022.9753711/mobilenet_v2_1543696022.9753711.h5\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 50s 706ms/step - loss: 1.9522 - acc: 0.5627 - val_loss: 2.2141 - val_acc: 0.4884\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.42096 to 0.48842, saving model to /data/oxford102/experiments/1543696022.9753711/mobilenet_v2_1543696022.9753711.h5\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 49s 691ms/step - loss: 1.8308 - acc: 0.5854 - val_loss: 1.9468 - val_acc: 0.5496\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.48842 to 0.54963, saving model to /data/oxford102/experiments/1543696022.9753711/mobilenet_v2_1543696022.9753711.h5\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 48s 683ms/step - loss: 1.4604 - acc: 0.7085 - val_loss: 1.8077 - val_acc: 0.5965\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.54963 to 0.59653, saving model to /data/oxford102/experiments/1543696022.9753711/mobilenet_v2_1543696022.9753711.h5\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 49s 689ms/step - loss: 1.3934 - acc: 0.7099 - val_loss: 1.7798 - val_acc: 0.6066\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.59653 to 0.60662, saving model to /data/oxford102/experiments/1543696022.9753711/mobilenet_v2_1543696022.9753711.h5\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 49s 684ms/step - loss: 1.2117 - acc: 0.7746 - val_loss: 1.7423 - val_acc: 0.5869\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.60662\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 49s 691ms/step - loss: 1.1507 - acc: 0.7817 - val_loss: 1.7797 - val_acc: 0.5919\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.60662\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 49s 684ms/step - loss: 1.0045 - acc: 0.8321 - val_loss: 1.6938 - val_acc: 0.6139\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.60662 to 0.61390, saving model to /data/oxford102/experiments/1543696022.9753711/mobilenet_v2_1543696022.9753711.h5\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 49s 692ms/step - loss: 0.9249 - acc: 0.8504 - val_loss: 1.4784 - val_acc: 0.6838\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.61390 to 0.68382, saving model to /data/oxford102/experiments/1543696022.9753711/mobilenet_v2_1543696022.9753711.h5\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 49s 685ms/step - loss: 0.8075 - acc: 0.8812 - val_loss: 1.4262 - val_acc: 0.6699\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.68382\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 49s 690ms/step - loss: 0.7907 - acc: 0.8754 - val_loss: 1.3531 - val_acc: 0.6967\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.68382 to 0.69669, saving model to /data/oxford102/experiments/1543696022.9753711/mobilenet_v2_1543696022.9753711.h5\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 49s 685ms/step - loss: 0.6802 - acc: 0.9140 - val_loss: 1.5367 - val_acc: 0.6602\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.69669\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 49s 689ms/step - loss: 0.6123 - acc: 0.9164 - val_loss: 1.2401 - val_acc: 0.7298\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.69669 to 0.72978, saving model to /data/oxford102/experiments/1543696022.9753711/mobilenet_v2_1543696022.9753711.h5\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 49s 684ms/step - loss: 0.5533 - acc: 0.9347 - val_loss: 1.3693 - val_acc: 0.6911\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.72978\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 49s 691ms/step - loss: 0.5444 - acc: 0.9309 - val_loss: 1.2826 - val_acc: 0.7335\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.72978 to 0.73346, saving model to /data/oxford102/experiments/1543696022.9753711/mobilenet_v2_1543696022.9753711.h5\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 49s 684ms/step - loss: 0.4978 - acc: 0.9432 - val_loss: 1.3002 - val_acc: 0.6931\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.73346\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 49s 691ms/step - loss: 0.4507 - acc: 0.9569 - val_loss: 1.2698 - val_acc: 0.7206\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.73346\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 49s 684ms/step - loss: 0.3864 - acc: 0.9650 - val_loss: 1.1370 - val_acc: 0.7529\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.73346 to 0.75290, saving model to /data/oxford102/experiments/1543696022.9753711/mobilenet_v2_1543696022.9753711.h5\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 49s 690ms/step - loss: 0.3770 - acc: 0.9661 - val_loss: 1.2096 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.75290\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 49s 685ms/step - loss: 0.3172 - acc: 0.9775 - val_loss: 1.1283 - val_acc: 0.7432\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.75290\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 49s 691ms/step - loss: 0.2978 - acc: 0.9798 - val_loss: 1.1580 - val_acc: 0.7353\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.75290\n",
      "Epoch 00022: early stopping\n",
      "{'network_name': 'vgg19', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 64, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543696022.9753711}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "143/143 [==============================] - 105s 737ms/step - loss: 3.1774 - acc: 0.2891 - val_loss: 2.4184 - val_acc: 0.4494\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.44945, saving model to /data/oxford102/experiments/1543698650.283622/mobilenet_v2_1543698650.283622.h5\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 99s 696ms/step - loss: 1.8789 - acc: 0.5832 - val_loss: 2.1135 - val_acc: 0.5075\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.44945 to 0.50753, saving model to /data/oxford102/experiments/1543698650.283622/mobilenet_v2_1543698650.283622.h5\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 98s 688ms/step - loss: 1.4631 - acc: 0.7012 - val_loss: 1.8541 - val_acc: 0.5669\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.50753 to 0.56685, saving model to /data/oxford102/experiments/1543698650.283622/mobilenet_v2_1543698650.283622.h5\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 98s 688ms/step - loss: 1.1657 - acc: 0.7796 - val_loss: 1.6025 - val_acc: 0.6290\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.56685 to 0.62900, saving model to /data/oxford102/experiments/1543698650.283622/mobilenet_v2_1543698650.283622.h5\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 98s 689ms/step - loss: 0.9894 - acc: 0.8287 - val_loss: 1.5323 - val_acc: 0.6507\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.62900 to 0.65066, saving model to /data/oxford102/experiments/1543698650.283622/mobilenet_v2_1543698650.283622.h5\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 98s 688ms/step - loss: 0.8334 - acc: 0.8632 - val_loss: 1.5222 - val_acc: 0.6563\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.65066 to 0.65631, saving model to /data/oxford102/experiments/1543698650.283622/mobilenet_v2_1543698650.283622.h5\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 98s 688ms/step - loss: 0.6882 - acc: 0.9062 - val_loss: 1.3543 - val_acc: 0.6977\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.65631 to 0.69774, saving model to /data/oxford102/experiments/1543698650.283622/mobilenet_v2_1543698650.283622.h5\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 98s 688ms/step - loss: 0.5557 - acc: 0.9319 - val_loss: 1.2929 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.69774 to 0.70621, saving model to /data/oxford102/experiments/1543698650.283622/mobilenet_v2_1543698650.283622.h5\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 98s 688ms/step - loss: 0.4755 - acc: 0.9486 - val_loss: 1.2483 - val_acc: 0.7081\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.70621 to 0.70810, saving model to /data/oxford102/experiments/1543698650.283622/mobilenet_v2_1543698650.283622.h5\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 98s 688ms/step - loss: 0.4026 - acc: 0.9655 - val_loss: 1.2735 - val_acc: 0.7137\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.70810 to 0.71375, saving model to /data/oxford102/experiments/1543698650.283622/mobilenet_v2_1543698650.283622.h5\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 98s 687ms/step - loss: 0.3522 - acc: 0.9726 - val_loss: 1.1281 - val_acc: 0.7373\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.71375 to 0.73729, saving model to /data/oxford102/experiments/1543698650.283622/mobilenet_v2_1543698650.283622.h5\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 98s 687ms/step - loss: 0.3148 - acc: 0.9814 - val_loss: 1.1211 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.73729 to 0.75895, saving model to /data/oxford102/experiments/1543698650.283622/mobilenet_v2_1543698650.283622.h5\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 98s 689ms/step - loss: 0.2664 - acc: 0.9825 - val_loss: 1.0647 - val_acc: 0.7476\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.75895\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 98s 688ms/step - loss: 0.2128 - acc: 0.9897 - val_loss: 1.0503 - val_acc: 0.7561\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.75895\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 98s 688ms/step - loss: 0.1815 - acc: 0.9908 - val_loss: 1.0446 - val_acc: 0.7524\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.75895\n",
      "Epoch 00015: early stopping\n",
      "{'network_name': 'vgg19', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 32, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543698650.283622}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "287/287 [==============================] - 206s 718ms/step - loss: 2.5124 - acc: 0.4361 - val_loss: 2.0569 - val_acc: 0.5144\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.51442, saving model to /data/oxford102/experiments/1543700995.231042/mobilenet_v2_1543700995.231042.h5\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 197s 685ms/step - loss: 1.3275 - acc: 0.7366 - val_loss: 1.6435 - val_acc: 0.6285\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.51442 to 0.62853, saving model to /data/oxford102/experiments/1543700995.231042/mobilenet_v2_1543700995.231042.h5\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 197s 686ms/step - loss: 0.8779 - acc: 0.8477 - val_loss: 1.4170 - val_acc: 0.6784\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.62853 to 0.67844, saving model to /data/oxford102/experiments/1543700995.231042/mobilenet_v2_1543700995.231042.h5\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 197s 687ms/step - loss: 0.5967 - acc: 0.9254 - val_loss: 1.2736 - val_acc: 0.7128\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.67844 to 0.71281, saving model to /data/oxford102/experiments/1543700995.231042/mobilenet_v2_1543700995.231042.h5\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 197s 686ms/step - loss: 0.4291 - acc: 0.9591 - val_loss: 1.1748 - val_acc: 0.7269\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.71281 to 0.72693, saving model to /data/oxford102/experiments/1543700995.231042/mobilenet_v2_1543700995.231042.h5\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 197s 686ms/step - loss: 0.2856 - acc: 0.9783 - val_loss: 1.0875 - val_acc: 0.7486\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.72693 to 0.74859, saving model to /data/oxford102/experiments/1543700995.231042/mobilenet_v2_1543700995.231042.h5\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 197s 685ms/step - loss: 0.2050 - acc: 0.9891 - val_loss: 1.0560 - val_acc: 0.7538\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.74859 to 0.75377, saving model to /data/oxford102/experiments/1543700995.231042/mobilenet_v2_1543700995.231042.h5\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 197s 686ms/step - loss: 0.1513 - acc: 0.9942 - val_loss: 1.0147 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.75377 to 0.76036, saving model to /data/oxford102/experiments/1543700995.231042/mobilenet_v2_1543700995.231042.h5\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 197s 686ms/step - loss: 0.1140 - acc: 0.9962 - val_loss: 0.9435 - val_acc: 0.7806\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.76036 to 0.78060, saving model to /data/oxford102/experiments/1543700995.231042/mobilenet_v2_1543700995.231042.h5\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 197s 686ms/step - loss: 0.0884 - acc: 0.9984 - val_loss: 0.9278 - val_acc: 0.7867\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.78060 to 0.78672, saving model to /data/oxford102/experiments/1543700995.231042/mobilenet_v2_1543700995.231042.h5\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 197s 685ms/step - loss: 0.0802 - acc: 0.9980 - val_loss: 0.9138 - val_acc: 0.7825\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.78672\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 197s 686ms/step - loss: 0.0660 - acc: 0.9991 - val_loss: 0.8998 - val_acc: 0.7811\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.78672\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 197s 686ms/step - loss: 0.0538 - acc: 0.9996 - val_loss: 0.9034 - val_acc: 0.7792\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.78672\n",
      "Epoch 00013: early stopping\n",
      "{'network_name': 'vgg19', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 16, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543700995.231042}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 16,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'mobilenet_v2',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN BATCHE SIZES SEQUENTIAL (no restart of kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 5.0864 - acc: 0.0234 - val_loss: 4.7674 - val_acc: 0.0625\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.06250, saving model to /data/oxford102/experiments/1543704623.951991/mobilenet_v2_1543704623.951991.h5\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 6s 703ms/step - loss: 4.3308 - acc: 0.0938 - val_loss: 4.1569 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.06250 to 0.12500, saving model to /data/oxford102/experiments/1543704623.951991/mobilenet_v2_1543704623.951991.h5\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 6s 698ms/step - loss: 3.7287 - acc: 0.2188 - val_loss: 3.8336 - val_acc: 0.2031\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.12500 to 0.20312, saving model to /data/oxford102/experiments/1543704623.951991/mobilenet_v2_1543704623.951991.h5\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 6s 691ms/step - loss: 3.5078 - acc: 0.2305 - val_loss: 3.6627 - val_acc: 0.2031\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.20312\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 6s 690ms/step - loss: 3.2908 - acc: 0.2656 - val_loss: 3.4550 - val_acc: 0.2500\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.20312 to 0.25000, saving model to /data/oxford102/experiments/1543704623.951991/mobilenet_v2_1543704623.951991.h5\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 6s 691ms/step - loss: 3.3314 - acc: 0.2656 - val_loss: 3.1217 - val_acc: 0.2812\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.25000 to 0.28125, saving model to /data/oxford102/experiments/1543704623.951991/mobilenet_v2_1543704623.951991.h5\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 6s 707ms/step - loss: 3.1932 - acc: 0.2891 - val_loss: 2.7842 - val_acc: 0.3594\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.28125 to 0.35938, saving model to /data/oxford102/experiments/1543704623.951991/mobilenet_v2_1543704623.951991.h5\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 6s 690ms/step - loss: 3.0469 - acc: 0.2656 - val_loss: 2.9798 - val_acc: 0.2812\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.35938\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 6s 693ms/step - loss: 2.9994 - acc: 0.2812 - val_loss: 2.7245 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.35938 to 0.37500, saving model to /data/oxford102/experiments/1543704623.951991/mobilenet_v2_1543704623.951991.h5\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 6s 694ms/step - loss: 2.9123 - acc: 0.2969 - val_loss: 2.8899 - val_acc: 0.3125\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.37500\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 6s 692ms/step - loss: 2.7382 - acc: 0.3789 - val_loss: 2.5303 - val_acc: 0.4062\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.37500 to 0.40625, saving model to /data/oxford102/experiments/1543704623.951991/mobilenet_v2_1543704623.951991.h5\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 6s 702ms/step - loss: 2.7123 - acc: 0.3828 - val_loss: 2.5709 - val_acc: 0.3906\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.40625\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 6s 692ms/step - loss: 2.6664 - acc: 0.4102 - val_loss: 2.6171 - val_acc: 0.3594\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.40625\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 6s 693ms/step - loss: 2.6029 - acc: 0.3828 - val_loss: 2.6880 - val_acc: 0.3281\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.40625\n",
      "Epoch 00014: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 512, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543704623.951991}\n"
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 512,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 17s 999ms/step - loss: 2.5992 - acc: 0.4136 - val_loss: 2.4823 - val_acc: 0.4297\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.42969, saving model to /data/oxford102/experiments/1543704889.6438491/mobilenet_v2_1543704889.6438491.h5\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 13s 745ms/step - loss: 2.1704 - acc: 0.5156 - val_loss: 2.4965 - val_acc: 0.4062\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.42969\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 12s 687ms/step - loss: 2.0437 - acc: 0.5110 - val_loss: 2.3772 - val_acc: 0.4531\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.42969 to 0.45312, saving model to /data/oxford102/experiments/1543704889.6438491/mobilenet_v2_1543704889.6438491.h5\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 12s 688ms/step - loss: 2.0654 - acc: 0.5074 - val_loss: 1.9531 - val_acc: 0.5859\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.45312 to 0.58594, saving model to /data/oxford102/experiments/1543704889.6438491/mobilenet_v2_1543704889.6438491.h5\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 12s 692ms/step - loss: 1.9702 - acc: 0.5588 - val_loss: 2.2115 - val_acc: 0.4062\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.58594\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 12s 691ms/step - loss: 1.9947 - acc: 0.5257 - val_loss: 2.1831 - val_acc: 0.4766\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.58594\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 12s 689ms/step - loss: 1.9811 - acc: 0.5349 - val_loss: 2.3234 - val_acc: 0.4219\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.58594\n",
      "Epoch 00007: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 256, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543704889.6438491}\n"
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 256,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 28s 813ms/step - loss: 1.8433 - acc: 0.5916 - val_loss: 2.0691 - val_acc: 0.4883\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.48828, saving model to /data/oxford102/experiments/1543705007.2282727/mobilenet_v2_1543705007.2282727.h5\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 24s 683ms/step - loss: 1.5683 - acc: 0.6679 - val_loss: 1.9867 - val_acc: 0.5547\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.48828 to 0.55469, saving model to /data/oxford102/experiments/1543705007.2282727/mobilenet_v2_1543705007.2282727.h5\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 24s 685ms/step - loss: 1.5117 - acc: 0.6723 - val_loss: 2.0120 - val_acc: 0.5078\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.55469\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 24s 687ms/step - loss: 1.4888 - acc: 0.6875 - val_loss: 2.0093 - val_acc: 0.5609\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.55469 to 0.56087, saving model to /data/oxford102/experiments/1543705007.2282727/mobilenet_v2_1543705007.2282727.h5\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 24s 686ms/step - loss: 1.4488 - acc: 0.6938 - val_loss: 1.8969 - val_acc: 0.5625\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.56087 to 0.56250, saving model to /data/oxford102/experiments/1543705007.2282727/mobilenet_v2_1543705007.2282727.h5\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 24s 682ms/step - loss: 1.3037 - acc: 0.7351 - val_loss: 1.7899 - val_acc: 0.6055\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.56250 to 0.60547, saving model to /data/oxford102/experiments/1543705007.2282727/mobilenet_v2_1543705007.2282727.h5\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 24s 685ms/step - loss: 1.2327 - acc: 0.7580 - val_loss: 1.7528 - val_acc: 0.5781\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.60547\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 24s 674ms/step - loss: 1.2326 - acc: 0.7366 - val_loss: 1.7113 - val_acc: 0.6261\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.60547 to 0.62609, saving model to /data/oxford102/experiments/1543705007.2282727/mobilenet_v2_1543705007.2282727.h5\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 24s 686ms/step - loss: 1.2069 - acc: 0.7777 - val_loss: 1.5649 - val_acc: 0.6484\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.62609 to 0.64844, saving model to /data/oxford102/experiments/1543705007.2282727/mobilenet_v2_1543705007.2282727.h5\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 24s 681ms/step - loss: 1.1053 - acc: 0.7908 - val_loss: 1.7254 - val_acc: 0.5781\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.64844\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 24s 684ms/step - loss: 0.9889 - acc: 0.8241 - val_loss: 1.5267 - val_acc: 0.6719\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.64844 to 0.67188, saving model to /data/oxford102/experiments/1543705007.2282727/mobilenet_v2_1543705007.2282727.h5\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 24s 686ms/step - loss: 0.9680 - acc: 0.8179 - val_loss: 1.6810 - val_acc: 0.6055\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.67188\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 24s 674ms/step - loss: 0.9914 - acc: 0.8232 - val_loss: 1.5614 - val_acc: 0.6348\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.67188\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 24s 685ms/step - loss: 0.8766 - acc: 0.8545 - val_loss: 1.6339 - val_acc: 0.6328\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.67188\n",
      "Epoch 00014: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 128, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543705007.2282727}\n"
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 128,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 54s 754ms/step - loss: 0.8442 - acc: 0.8653 - val_loss: 1.4747 - val_acc: 0.6795\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.67954, saving model to /data/oxford102/experiments/1543705415.1222022/mobilenet_v2_1543705415.1222022.h5\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 49s 691ms/step - loss: 0.8008 - acc: 0.8849 - val_loss: 1.4565 - val_acc: 0.6783\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.67954\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 49s 687ms/step - loss: 0.7292 - acc: 0.9067 - val_loss: 1.5287 - val_acc: 0.6622\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.67954\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 49s 692ms/step - loss: 0.7050 - acc: 0.9008 - val_loss: 1.4019 - val_acc: 0.7040\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.67954 to 0.70404, saving model to /data/oxford102/experiments/1543705415.1222022/mobilenet_v2_1543705415.1222022.h5\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 49s 685ms/step - loss: 0.6505 - acc: 0.9243 - val_loss: 1.3132 - val_acc: 0.7220\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.70404 to 0.72201, saving model to /data/oxford102/experiments/1543705415.1222022/mobilenet_v2_1543705415.1222022.h5\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 49s 690ms/step - loss: 0.5797 - acc: 0.9245 - val_loss: 1.3035 - val_acc: 0.7022\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.72201\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 49s 687ms/step - loss: 0.4846 - acc: 0.9555 - val_loss: 1.3000 - val_acc: 0.7413\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.72201 to 0.74131, saving model to /data/oxford102/experiments/1543705415.1222022/mobilenet_v2_1543705415.1222022.h5\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 49s 691ms/step - loss: 0.4810 - acc: 0.9445 - val_loss: 1.2182 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.74131\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 49s 686ms/step - loss: 0.4063 - acc: 0.9639 - val_loss: 1.3302 - val_acc: 0.6892\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.74131\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 49s 692ms/step - loss: 0.3902 - acc: 0.9687 - val_loss: 1.1196 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.74131 to 0.75000, saving model to /data/oxford102/experiments/1543705415.1222022/mobilenet_v2_1543705415.1222022.h5\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 49s 686ms/step - loss: 0.3469 - acc: 0.9740 - val_loss: 1.2803 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.75000\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 49s 689ms/step - loss: 0.3386 - acc: 0.9700 - val_loss: 1.1960 - val_acc: 0.7261\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.75000\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 49s 686ms/step - loss: 0.3078 - acc: 0.9802 - val_loss: 1.1476 - val_acc: 0.7394\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.75000\n",
      "Epoch 00013: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 64, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543705415.1222022}\n"
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "143/143 [==============================] - 104s 727ms/step - loss: 0.2626 - acc: 0.9794 - val_loss: 1.1046 - val_acc: 0.7326\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.73258, saving model to /data/oxford102/experiments/1543706100.347142/mobilenet_v2_1543706100.347142.h5\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 98s 688ms/step - loss: 0.2247 - acc: 0.9873 - val_loss: 1.0311 - val_acc: 0.7712\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.73258 to 0.77119, saving model to /data/oxford102/experiments/1543706100.347142/mobilenet_v2_1543706100.347142.h5\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 98s 687ms/step - loss: 0.1910 - acc: 0.9921 - val_loss: 1.0635 - val_acc: 0.7542\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.77119\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 98s 688ms/step - loss: 0.1674 - acc: 0.9919 - val_loss: 1.0230 - val_acc: 0.7825\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.77119 to 0.78249, saving model to /data/oxford102/experiments/1543706100.347142/mobilenet_v2_1543706100.347142.h5\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 98s 688ms/step - loss: 0.1347 - acc: 0.9961 - val_loss: 1.0468 - val_acc: 0.7486\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.78249\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 98s 688ms/step - loss: 0.1227 - acc: 0.9967 - val_loss: 1.0411 - val_acc: 0.7495\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.78249\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 98s 688ms/step - loss: 0.1040 - acc: 0.9976 - val_loss: 0.9368 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.78249\n",
      "Epoch 00007: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 32, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543706100.347142}\n"
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "287/287 [==============================] - 202s 705ms/step - loss: 0.0961 - acc: 0.9981 - val_loss: 0.9368 - val_acc: 0.7806\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78060, saving model to /data/oxford102/experiments/1543706823.1523945/mobilenet_v2_1543706823.1523945.h5\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 198s 688ms/step - loss: 0.0718 - acc: 0.9991 - val_loss: 0.9422 - val_acc: 0.7797\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.78060\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 198s 688ms/step - loss: 0.0612 - acc: 0.9989 - val_loss: 0.8923 - val_acc: 0.7830\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.78060 to 0.78296, saving model to /data/oxford102/experiments/1543706823.1523945/mobilenet_v2_1543706823.1523945.h5\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 197s 688ms/step - loss: 0.0501 - acc: 0.9991 - val_loss: 0.8918 - val_acc: 0.7825\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.78296\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 197s 688ms/step - loss: 0.0451 - acc: 0.9993 - val_loss: 0.8779 - val_acc: 0.7895\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.78296 to 0.78955, saving model to /data/oxford102/experiments/1543706823.1523945/mobilenet_v2_1543706823.1523945.h5\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 197s 687ms/step - loss: 0.0380 - acc: 0.9998 - val_loss: 0.8800 - val_acc: 0.7848\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.78955\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 197s 687ms/step - loss: 0.0321 - acc: 0.9998 - val_loss: 0.8609 - val_acc: 0.7886\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.78955\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 197s 687ms/step - loss: 0.0295 - acc: 0.9999 - val_loss: 0.8444 - val_acc: 0.7924\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.78955 to 0.79237, saving model to /data/oxford102/experiments/1543706823.1523945/mobilenet_v2_1543706823.1523945.h5\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 198s 689ms/step - loss: 0.0277 - acc: 0.9999 - val_loss: 0.8588 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.79237\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 197s 688ms/step - loss: 0.0246 - acc: 1.0000 - val_loss: 0.8238 - val_acc: 0.7947\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.79237 to 0.79473, saving model to /data/oxford102/experiments/1543706823.1523945/mobilenet_v2_1543706823.1523945.h5\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 197s 688ms/step - loss: 0.0218 - acc: 0.9999 - val_loss: 0.8307 - val_acc: 0.7966\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.79473 to 0.79661, saving model to /data/oxford102/experiments/1543706823.1523945/mobilenet_v2_1543706823.1523945.h5\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 197s 687ms/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.8609 - val_acc: 0.7853\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.79661\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 197s 686ms/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.7895 - val_acc: 0.8093\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.79661 to 0.80932, saving model to /data/oxford102/experiments/1543706823.1523945/mobilenet_v2_1543706823.1523945.h5\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 197s 686ms/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.8355 - val_acc: 0.7910\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.80932\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 197s 686ms/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.8059 - val_acc: 0.8079\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.80932\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 197s 687ms/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.8217 - val_acc: 0.8008\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.80932\n",
      "Epoch 00016: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 16, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543706823.1523945}\n"
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 16,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "575/575 [==============================] - 400s 695ms/step - loss: 0.0146 - acc: 0.9999 - val_loss: 0.7976 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.80862, saving model to /data/oxford102/experiments/1543710046.7901342/mobilenet_v2_1543710046.7901342.h5\n",
      "Epoch 2/100\n",
      "575/575 [==============================] - 395s 686ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.8103 - val_acc: 0.7945\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.80862\n",
      "Epoch 3/100\n",
      "575/575 [==============================] - 394s 686ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.8133 - val_acc: 0.7945\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.80862\n",
      "Epoch 4/100\n",
      "575/575 [==============================] - 394s 686ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.7969 - val_acc: 0.8041\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.80862\n",
      "Epoch 00004: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 8, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543710046.7901342}\n"
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"mobilenet_v2\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': model_name,\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINETUNE TOP LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(base_model.layers[619:]):\n",
    "    print(i, layer.name)\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vgg19\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
