{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.applications.vgg19 import decode_predictions\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow\n",
    "from time import time\n",
    "\n",
    "import pandas\n",
    "\n",
    "import pickle as pk\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/oxford102/train'\n",
    "img_width, img_height = 256, 256\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "nr_categories = 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 256, 256\n",
    "train_data_dir = \"/data/oxford102/train/\"\n",
    "validation_data_dir = \"/data/oxford102/train/\"\n",
    "nb_train_samples = 4604\n",
    "nb_validation_samples = 1094 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_processor = keras.applications.vgg19.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_datagen = ImageDataGenerator(preprocessing_function=input_processor, \n",
    "                                           validation_split=0.2)\n",
    "\n",
    "train_val_datagen_aug = ImageDataGenerator(\n",
    "        #rescale=1. / 255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=input_processor,\n",
    "        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "train_generator = train_val_datagen.flow_from_directory(\n",
    "        train_data_dir,  # this is the target directory\n",
    "        target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "        batch_size=batch_size,\n",
    "        subset=\"training\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = train_val_datagen.flow_from_directory(\n",
    "        train_data_dir,  # this is the target directory\n",
    "        target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "        subset=\"validation\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:30: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "#from keras import regularizers\n",
    "\n",
    "k.set_learning_phase(0)\n",
    "\n",
    "network_name = \"vgg19\"\n",
    "img_width, img_height = (256, 256)\n",
    "if network_name == \"vgg16\":\n",
    "    base_model = keras.applications.vgg16.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "elif network_name == \"vgg19\":\n",
    "    base_model = keras.applications.vgg19.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "else:\n",
    "    raise Exception(\"check your network name\")\n",
    "\n",
    "for layer in base_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "    #Adding custom Layers \n",
    "k.set_learning_phase(1)\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\", \n",
    "          #kernel_regularizer=regularizers.l2(0.01),\n",
    "         #       activity_regularizer=regularizers.l1(0.001)\n",
    "         )(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x, training=True)\n",
    "#x = Dense(102, activation=\"relu\")(x)\n",
    "predictions = Dense(nr_categories, activation=\"softmax\")(x)\n",
    "\n",
    "_model = Model(input = base_model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              33555456  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 102)               104550    \n",
      "=================================================================\n",
      "Total params: 53,688,486\n",
      "Trainable params: 33,662,054\n",
      "Non-trainable params: 20,026,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"vgg19\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 128,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 70s 988ms/step - loss: 1.5431 - acc: 0.6466 - val_loss: 1.6666 - val_acc: 0.5864\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.58640, saving model to /data/oxford102/experiments/1543111575.964653/vgg19_1543111575.964653.h5\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 61s 862ms/step - loss: 1.5161 - acc: 0.6382 - val_loss: 1.6489 - val_acc: 0.6268\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.58640 to 0.62684, saving model to /data/oxford102/experiments/1543111575.964653/vgg19_1543111575.964653.h5\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 70s 983ms/step - loss: 1.3811 - acc: 0.6804 - val_loss: 1.5496 - val_acc: 0.6103\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.62684\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 62s 873ms/step - loss: 1.3697 - acc: 0.6765 - val_loss: 1.4327 - val_acc: 0.6434\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.62684 to 0.64338, saving model to /data/oxford102/experiments/1543111575.964653/vgg19_1543111575.964653.h5\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 69s 967ms/step - loss: 1.2474 - acc: 0.7073 - val_loss: 1.4235 - val_acc: 0.6673\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.64338 to 0.66728, saving model to /data/oxford102/experiments/1543111575.964653/vgg19_1543111575.964653.h5\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 62s 869ms/step - loss: 1.2560 - acc: 0.6967 - val_loss: 1.4088 - val_acc: 0.6765\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.66728 to 0.67647, saving model to /data/oxford102/experiments/1543111575.964653/vgg19_1543111575.964653.h5\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 69s 967ms/step - loss: 1.1389 - acc: 0.7265 - val_loss: 1.3483 - val_acc: 0.6746\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.67647\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 62s 867ms/step - loss: 1.1641 - acc: 0.7276 - val_loss: 1.2969 - val_acc: 0.6746\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.67647\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 67s 940ms/step - loss: 1.0604 - acc: 0.7535 - val_loss: 1.3921 - val_acc: 0.6691\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.67647\n",
      "Epoch 00009: early stopping\n",
      "{'network_name': 'vgg19', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 64, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543111575.964653}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"vgg19\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vgg19\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vgg19\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 16,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINETUNE TOP LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(base_model.layers[11:]):\n",
    "    print(i, layer.name)\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vgg19\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 16,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
