{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.applications.mobilenet_v2 import decode_predictions\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow\n",
    "from time import time\n",
    "\n",
    "import pandas\n",
    "\n",
    "import pickle as pk\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train all nets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15504574288862770091\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11280557671\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13008700569799606219\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MobileNetV2',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'absolute_import',\n",
       " 'decode_predictions',\n",
       " 'division',\n",
       " 'keras_modules_injection',\n",
       " 'mobilenet_v2',\n",
       " 'preprocess_input',\n",
       " 'print_function']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(keras.applications.mobilenet_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/oxford102/train'\n",
    "train_data_dir = \"/data/oxford102/train/\"\n",
    "validation_data_dir = \"/data/oxford102/train/\"\n",
    "img_width, img_height = 256, 256\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "nr_categories = 102\n",
    "nb_train_samples = 4604\n",
    "nb_validation_samples = 1094 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_generator(input_processor, img_aug=False):\n",
    "    if not img_aug:\n",
    "        train_val_datagen = ImageDataGenerator(preprocessing_function=input_processor, \n",
    "                                           validation_split=0.2)\n",
    "    else: \n",
    "        train_val_datagen = ImageDataGenerator(\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest',\n",
    "            preprocessing_function=input_processor,\n",
    "            validation_split=0.2)\n",
    "        \n",
    "    return train_val_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generators(batch_size, image_size, input_processor, img_aug=False):\n",
    "\n",
    "    img_width, img_height = image_size\n",
    "    \n",
    "    train_val_datagen = get_image_generator(input_processor, img_aug)\n",
    "\n",
    "    train_generator = train_val_datagen.flow_from_directory(\n",
    "            train_data_dir,  # this is the target directory\n",
    "            target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "            batch_size=batch_size,\n",
    "            subset=\"training\",\n",
    "            class_mode='categorical')\n",
    "\n",
    "    validation_generator = train_val_datagen.flow_from_directory(\n",
    "            train_data_dir,  # this is the target directory\n",
    "            target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "            subset=\"validation\",\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "    \n",
    "    return train_generator, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras import regularizers\n",
    "\n",
    "def get_model(network_name=\"inception_resnet_v2\", image_size=(256, 256), verbose=False):\n",
    "    k.set_learning_phase(0)\n",
    "\n",
    "    img_width, img_height = image_size\n",
    "    if network_name == \"vgg16\":\n",
    "        base_model = keras.applications.vgg16.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "        input_processor = applications.vgg16.preprocess_input\n",
    "    elif network_name == \"vgg19\":\n",
    "        base_model = keras.applications.vgg19.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "        input_processor = applications.vgg19.preprocess_input\n",
    "    elif network_name == \"inception_resnet_v2\":\n",
    "        base_model = keras.applications.inception_resnet_v2.InceptionResNetV2(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "        input_processor = applications.inception_resnet_v2.preprocess_input\n",
    "    elif network_name == \"mobilenet_v2\":\n",
    "        base_model = keras.applications.mobilenet_v2.MobileNetV2(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "        input_processor = applications.mobilenet_v2.preprocess_input\n",
    "    elif network_name == \"xception\":\n",
    "        base_model = keras.applications.xception.Xception(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "        input_processor = applications.xception.preprocess_input\n",
    "    elif network_name == \"resnet50\":\n",
    "        base_model = keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "        input_processor = applications.resnet50.preprocess_input    \n",
    "    elif network_name == \"inception_v3\":\n",
    "        base_model = keras.applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "        input_processor = applications.inception_v3.preprocess_input\n",
    "    elif network_name == \"mobilenet\":\n",
    "        base_model = keras.applications.mobilenet.MobileNet(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "        input_processor = applications.mobilenet.preprocess_input\n",
    "    elif network_name == \"densenet\":\n",
    "        base_model = keras.applications.densenet.DenseNet201(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "        input_processor = applications.densenet.preprocess_input        \n",
    "    elif network_name == \"nasnet\":\n",
    "        base_model = keras.applications.nasnet.NASNetMobile(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "        input_processor = applications.nasnet.preprocess_input\n",
    "    else:\n",
    "        raise Exception(\"check your network name\")\n",
    "\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "\n",
    "        #Adding custom Layers \n",
    "    k.set_learning_phase(1)\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation=\"relu\", \n",
    "              #kernel_regularizer=regularizers.l2(0.01),\n",
    "             #       activity_regularizer=regularizers.l1(0.001)\n",
    "             )(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x, training=True)\n",
    "    #x = Dense(102, activation=\"relu\")(x)\n",
    "    predictions = Dense(nr_categories, activation=\"softmax\")(x)\n",
    "\n",
    "    _model = Model(input = base_model.input, output = predictions)\n",
    "    if verbose:\n",
    "        _model.summary()\n",
    "    return _model, input_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(params, _model, generators):\n",
    "    model_name = params[\"network_name\"]\n",
    "    num_train_img = 4604\n",
    "    num_val_img = 1094\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    log_time = time()\n",
    "    params['log_time'] = log_time\n",
    "    batch_size = params.get(\"batch_size\")\n",
    "\n",
    "    train_generator, validation_generator = generators\n",
    "    _model.compile(loss = \"categorical_crossentropy\", optimizer = params[\"optimizer\"], metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "    base = '/data/oxford102/experiments'\n",
    "    path = os.path.join(base, str(log_time))\n",
    "    checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "    csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        history_callback = _model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=num_train_img // params[\"batch_size\"] // 2,\n",
    "                epochs=params[\"epochs\"],\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=num_val_img // params[\"batch_size\"],\n",
    "                callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "    except Exception as e:\n",
    "        raise(e)\n",
    "    finally:\n",
    "        params.pop(\"optimizer\")\n",
    "        pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "        _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "        print(params)\n",
    "        params\n",
    "        \n",
    "    return history_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd =  optimizers.SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "adagrad = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "adadelta = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "adamamx = optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nadam = optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = [\"mobilenet_v2\", \"densenet\", \"nasnet\",  \"vgg16\", \"vgg19\", \"inception_resnet_v2\", \"mobilenet\", \"resnet50\", \"inception_v3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'network_name': None,\n",
    "         'image_aug': False,\n",
    "         'optimizer_name': False, \n",
    "         'optimizer': None,\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 128,\n",
    "         'epochs': 100,\n",
    "         'image_size': (224, 224),\n",
    "         'log_time': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train all nets with rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net: mobilenet_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:56: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 18s 1s/step - loss: 2.4331 - acc: 0.4752 - val_loss: 1.4218 - val_acc: 0.6689\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66895, saving model to /data/oxford102/experiments/1546837399.7954097/mobilenet_v2_1546837399.7954097.h5\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 9s 556ms/step - loss: 1.1633 - acc: 0.7353 - val_loss: 0.9945 - val_acc: 0.7785\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.66895 to 0.77847, saving model to /data/oxford102/experiments/1546837399.7954097/mobilenet_v2_1546837399.7954097.h5\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 13s 764ms/step - loss: 0.3068 - acc: 0.9528 - val_loss: 0.7644 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.77847 to 0.82298, saving model to /data/oxford102/experiments/1546837399.7954097/mobilenet_v2_1546837399.7954097.h5\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 14s 799ms/step - loss: 0.2202 - acc: 0.9683 - val_loss: 0.8753 - val_acc: 0.7836\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.82298\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 13s 782ms/step - loss: 0.1241 - acc: 0.9852 - val_loss: 0.7021 - val_acc: 0.8188\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.82298\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 14s 819ms/step - loss: 0.0768 - acc: 0.9945 - val_loss: 0.6932 - val_acc: 0.8251\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.82298 to 0.82505, saving model to /data/oxford102/experiments/1546837399.7954097/mobilenet_v2_1546837399.7954097.h5\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 14s 805ms/step - loss: 0.0537 - acc: 0.9977 - val_loss: 0.6216 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.82505 to 0.83954, saving model to /data/oxford102/experiments/1546837399.7954097/mobilenet_v2_1546837399.7954097.h5\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 14s 813ms/step - loss: 0.0405 - acc: 0.9968 - val_loss: 0.6609 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.83954\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 14s 816ms/step - loss: 0.0321 - acc: 0.9982 - val_loss: 0.5874 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.83954 to 0.85404, saving model to /data/oxford102/experiments/1546837399.7954097/mobilenet_v2_1546837399.7954097.h5\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 14s 819ms/step - loss: 0.0168 - acc: 0.9991 - val_loss: 0.5697 - val_acc: 0.8535\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.85404\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 14s 819ms/step - loss: 0.0118 - acc: 0.9995 - val_loss: 0.6040 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.85404\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 14s 838ms/step - loss: 0.0254 - acc: 0.9977 - val_loss: 0.6552 - val_acc: 0.8468\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.85404\n",
      "Epoch 00012: early stopping\n",
      "{'network_name': 'mobilenet_v2', 'image_aug': False, 'optimizer_name': False, 'optimizer_params': None, 'batch_size': 128, 'epochs': 100, 'image_size': (224, 224), 'log_time': 1546837399.7954097}\n",
      "net: densenet\n",
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:56: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-618ec3d59b51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0m_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_processor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"network_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_generators\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_processor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-2d87d3214b81>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(params, _model, generators)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'optimizer'"
     ]
    }
   ],
   "source": [
    "params['optimizer'] = rmsprop\n",
    "params['optimizer'] = \"rmsprop\"\n",
    "\n",
    "for net in nets:\n",
    "    print(\"net:\", net)\n",
    "    params['network_name'] = net\n",
    "    _model, input_processor = get_model(params[\"network_name\"], image_size=params[\"image_size\"])\n",
    "    train_generator, validation_generator = get_generators( params[\"batch_size\"], params[\"image_size\"], input_processor)\n",
    "history = train_model(params, _model, (train_generator, validation_generator))\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
