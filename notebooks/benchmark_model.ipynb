{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.applications.mobilenet_v2 import decode_predictions\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow\n",
    "from time import time\n",
    "\n",
    "import pandas\n",
    "\n",
    "import pickle as pk\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter runing on mobilenet with RMSprop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1846044515277481367\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11280557671\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7768095235545444265\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MobileNetV2',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'absolute_import',\n",
       " 'decode_predictions',\n",
       " 'division',\n",
       " 'keras_modules_injection',\n",
       " 'mobilenet_v2',\n",
       " 'preprocess_input',\n",
       " 'print_function']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(keras.applications.mobilenet_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/oxford102/train'\n",
    "train_data_dir = \"/data/oxford102/train/\"\n",
    "validation_data_dir = \"/data/oxford102/train/\"\n",
    "img_width, img_height = 256, 256\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "nr_categories = n_categories = 102\n",
    "nb_train_samples = 4604\n",
    "nb_validation_samples = 1094 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_generator(input_processor, img_aug=False):\n",
    "    if not img_aug:\n",
    "        train_val_datagen = ImageDataGenerator(preprocessing_function=None,\n",
    "                                               rescale=1./255, \n",
    "                                           validation_split=0.2)\n",
    "    else: \n",
    "        train_val_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=None,\n",
    "            rescale=1./255, \n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest',\n",
    "            validation_split=0.2)\n",
    "        \n",
    "    return train_val_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.ImageDataGenerator at 0x7f9469882a20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageDataGenerator(\n",
    "    featurewise_center=False, \n",
    "    samplewise_center=False, \n",
    "    featurewise_std_normalization=False, \n",
    "    samplewise_std_normalization=False, \n",
    "    zca_whitening=False, \n",
    "    zca_epsilon=1e-06, \n",
    "    rotation_range=0, \n",
    "    width_shift_range=0.0, \n",
    "    height_shift_range=0.0, \n",
    "    brightness_range=None,\n",
    "    shear_range=0.0, \n",
    "    zoom_range=0.0,\n",
    "    channel_shift_range=0.0, \n",
    "    fill_mode='nearest',\n",
    "    cval=0.0, \n",
    "    horizontal_flip=False, \n",
    "    vertical_flip=False, \n",
    "    rescale=None, \n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0, \n",
    "    dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generators(batch_size, image_size, input_processor, img_aug=False):\n",
    "\n",
    "    img_width, img_height = image_size\n",
    "    \n",
    "    train_val_datagen = get_image_generator(input_processor, img_aug)\n",
    "\n",
    "    train_generator = train_val_datagen.flow_from_directory(\n",
    "            train_data_dir,  # this is the target directory\n",
    "            target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "            batch_size=batch_size,\n",
    "            subset=\"training\",\n",
    "            class_mode='categorical')\n",
    "\n",
    "    validation_generator = train_val_datagen.flow_from_directory(\n",
    "            train_data_dir,  # this is the target directory\n",
    "            target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "            subset=\"validation\",\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "    \n",
    "    return train_generator, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_benchmark_model(verbose=False, img_size=(256, 256)):\n",
    "    \n",
    "    width, height = img_size\n",
    "    model = None\n",
    "    model = Sequential()\n",
    "\n",
    "    #conv_layer1\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(width, height, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # conv_layer2\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(n_categories, activation=\"softmax\"))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    return model, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 254, 254, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 125, 125, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               14745856  \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 102)               26214     \n",
      "=================================================================\n",
      "Total params: 14,800,710\n",
      "Trainable params: 14,800,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.sequential.Sequential at 0x7f9469882978>, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_benchmark_model(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras import regularizers\n",
    "\n",
    "def get_model(network_name=\"inception_resnet_v2\", image_size=(256, 256), verbose=False):\n",
    "    k.set_learning_phase(0)\n",
    "\n",
    "    img_width, img_height = image_size\n",
    "    if network_name == \"benchmark\":\n",
    "        return get_benchmark_model(img_size=image_size)\n",
    "    if network_name == \"vgg16\":\n",
    "        base_model = keras.applications.vgg16.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "        input_processor = applications.vgg16.preprocess_input\n",
    "    elif network_name == \"vgg19\":\n",
    "        base_model = keras.applications.vgg19.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "        input_processor = applications.vgg19.preprocess_input\n",
    "    elif network_name == \"inception_resnet_v2\":\n",
    "        base_model = keras.applications.inception_resnet_v2.InceptionResNetV2(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "        input_processor = applications.inception_resnet_v2.preprocess_input\n",
    "    elif network_name == \"mobilenet_v2\":\n",
    "        base_model = keras.applications.mobilenet_v2.MobileNetV2(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "        input_processor = applications.mobilenet_v2.preprocess_input\n",
    "    else:\n",
    "        raise Exception(\"check your network name\")\n",
    "\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "\n",
    "        #Adding custom Layers \n",
    "    k.set_learning_phase(1)\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation=\"relu\", \n",
    "              #kernel_regularizer=regularizers.l2(0.01),\n",
    "             #       activity_regularizer=regularizers.l1(0.001)\n",
    "             )(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x, training=True)\n",
    "    #x = Dense(102, activation=\"relu\")(x)\n",
    "    predictions = Dense(nr_categories, activation=\"softmax\")(x)\n",
    "\n",
    "    _model = Model(input = base_model.input, output = predictions)\n",
    "    if verbose:\n",
    "        _model.summary()\n",
    "    return _model, input_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import talos as ta\n",
    "\n",
    "# p = {'lr': (0.001, 0.01, 0.1),\n",
    "#      'batch_size': (128),\n",
    "#      'epochs': [150],\n",
    "#      'dropout': (0, 0.5, 5),\n",
    "#      'weight_regulizer':[None],\n",
    "#      'emb_output_dims': [None],\n",
    "#      'shape':['brick','long_funnel'],\n",
    "#      'optimizer': [Adam, Nadam, RMSprop],\n",
    "#      'losses': [logcosh, binary_crossentropy],\n",
    "#      'activation':[relu, elu],\n",
    "#      'last_activation': [sigmoid]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(params, _model, generators):\n",
    "    model_name = params[\"network_name\"]\n",
    "    num_train_img = 4604\n",
    "    num_val_img = 1094\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    log_time = time()\n",
    "    params['log_time'] = log_time\n",
    "    batch_size = params.get(\"batch_size\")\n",
    "\n",
    "    train_generator, validation_generator = generators\n",
    "    _model.compile(loss = \"categorical_crossentropy\", optimizer = keras.optimizers.SGD(), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "    base = '/data/oxford102/experiments'\n",
    "    path = os.path.join(base, str(log_time))\n",
    "    checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "    csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        history_callback = _model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=num_train_img // params[\"batch_size\"] ,\n",
    "                epochs=params[\"epochs\"],\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=num_val_img // params[\"batch_size\"],\n",
    "                callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "    except Exception as e:\n",
    "        raise(e)\n",
    "    finally:\n",
    "        params.pop(\"optimizer\")\n",
    "        pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "        _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "        print(params)\n",
    "        params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'network_name': \"benchmark\",\n",
    "         'image_aug': False,\n",
    "         'optimizer_name': \"RMSProp\", \n",
    "         'optimizer': optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0),\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 128,\n",
    "         'epochs': 100,\n",
    "         'image_size': (224, 224),\n",
    "         'log_time': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 19s 1s/step - loss: 15.9329 - acc: 0.0110 - val_loss: 15.9450 - val_acc: 0.0107\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.01074, saving model to /data/oxford102/experiments/1548037535.6415188/benchmark_1548037535.6415188.h5\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 17s 979ms/step - loss: 15.9551 - acc: 0.0101 - val_loss: 15.9012 - val_acc: 0.0135\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.01074 to 0.01346, saving model to /data/oxford102/experiments/1548037535.6415188/benchmark_1548037535.6415188.h5\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 15s 867ms/step - loss: 15.9845 - acc: 0.0083 - val_loss: 16.0180 - val_acc: 0.0062\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.01346\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 14s 847ms/step - loss: 15.9033 - acc: 0.0133 - val_loss: 15.9679 - val_acc: 0.0093\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.01346\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 14s 800ms/step - loss: 15.9401 - acc: 0.0110 - val_loss: 15.8678 - val_acc: 0.0155\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.01346 to 0.01553, saving model to /data/oxford102/experiments/1548037535.6415188/benchmark_1548037535.6415188.h5\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 14s 826ms/step - loss: 15.9700 - acc: 0.0092 - val_loss: 15.9679 - val_acc: 0.0093\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.01553\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 13s 777ms/step - loss: 15.9253 - acc: 0.0120 - val_loss: 15.9179 - val_acc: 0.0124\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.01553\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 14s 804ms/step - loss: 15.9329 - acc: 0.0115 - val_loss: 15.9512 - val_acc: 0.0104\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.01553\n",
      "Epoch 00008: early stopping\n",
      "{'network_name': 'benchmark', 'image_aug': False, 'optimizer_name': 'RMSProp', 'optimizer_params': None, 'batch_size': 128, 'epochs': 100, 'image_size': (224, 224), 'log_time': 1548037535.6415188}\n"
     ]
    }
   ],
   "source": [
    "lr=0.001\n",
    "rho=0.9\n",
    "epsilon=None\n",
    "decay=0.0\n",
    "\n",
    "_optimizer = optimizers.RMSprop(lr=lr, rho=rho, epsilon=epsilon, decay=decay)\n",
    "params['optimizer'] = _optimizer\n",
    "_model, input_processor = get_model(params[\"network_name\"], image_size=params[\"image_size\"])\n",
    "train_generator, validation_generator = get_generators( params[\"batch_size\"], params[\"image_size\"], None)\n",
    "train_model(params, _model, (train_generator, validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'network_name': \"benchmark\",\n",
    "         'image_aug': True,\n",
    "         'optimizer_name': \"RMSProp\", \n",
    "         'optimizer': optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0),\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 128,\n",
    "         'epochs': 100,\n",
    "         'image_size': (224, 224),\n",
    "         'log_time': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 14s 816ms/step - loss: 15.6817 - acc: 0.0253 - val_loss: 15.6459 - val_acc: 0.0293\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.02930, saving model to /data/oxford102/experiments/1548037786.9805357/benchmark_1548037786.9805357.h5\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 15s 864ms/step - loss: 15.6070 - acc: 0.0317 - val_loss: 15.6342 - val_acc: 0.0300\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.02930 to 0.03002, saving model to /data/oxford102/experiments/1548037786.9805357/benchmark_1548037786.9805357.h5\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 13s 761ms/step - loss: 15.6875 - acc: 0.0267 - val_loss: 15.7010 - val_acc: 0.0259\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.03002\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 13s 773ms/step - loss: 15.6588 - acc: 0.0285 - val_loss: 15.6509 - val_acc: 0.0290\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.03002\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 13s 748ms/step - loss: 15.6285 - acc: 0.0304 - val_loss: 15.6175 - val_acc: 0.0311\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.03002 to 0.03106, saving model to /data/oxford102/experiments/1548037786.9805357/benchmark_1548037786.9805357.h5\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 14s 795ms/step - loss: 15.6811 - acc: 0.0271 - val_loss: 15.6509 - val_acc: 0.0290\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.03106\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 14s 795ms/step - loss: 15.6871 - acc: 0.0267 - val_loss: 15.6175 - val_acc: 0.0311\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.03106\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 13s 769ms/step - loss: 15.6663 - acc: 0.0280 - val_loss: 15.6175 - val_acc: 0.0311\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.03106\n",
      "Epoch 00008: early stopping\n",
      "{'network_name': 'benchmark', 'image_aug': True, 'optimizer_name': 'RMSProp', 'optimizer_params': None, 'batch_size': 128, 'epochs': 100, 'image_size': (224, 224), 'log_time': 1548037786.9805357}\n"
     ]
    }
   ],
   "source": [
    "lr=0.001\n",
    "rho=0.9\n",
    "epsilon=None\n",
    "decay=0.0\n",
    "\n",
    "_optimizer = optimizers.RMSprop(lr=lr, rho=rho, epsilon=epsilon, decay=decay)\n",
    "params['optimizer'] = _optimizer\n",
    "_model, input_processor = get_model(params[\"network_name\"], image_size=params[\"image_size\"])\n",
    "train_generator, validation_generator = get_generators( params[\"batch_size\"], params[\"image_size\"], None)\n",
    "train_model(params, _model, (train_generator, validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'network_name': \"benchmark\",\n",
    "         'image_aug': False,\n",
    "         'optimizer_name': \"SGD\", \n",
    "         'optimizer': optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False),\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "575/575 [==============================] - 33s 58ms/step - loss: 4.4228 - acc: 0.0376 - val_loss: 4.0705 - val_acc: 0.0533\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.05331, saving model to /data/oxford102/experiments/1548039573.9481478/benchmark_1548039573.9481478.h5\n",
      "Epoch 2/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 3.7344 - acc: 0.1211 - val_loss: 3.6032 - val_acc: 0.1372\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.05331 to 0.13720, saving model to /data/oxford102/experiments/1548039573.9481478/benchmark_1548039573.9481478.h5\n",
      "Epoch 3/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 3.1667 - acc: 0.2126 - val_loss: 3.2118 - val_acc: 0.2127\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.13720 to 0.21271, saving model to /data/oxford102/experiments/1548039573.9481478/benchmark_1548039573.9481478.h5\n",
      "Epoch 4/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 2.6644 - acc: 0.3098 - val_loss: 3.1059 - val_acc: 0.2385\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.21271 to 0.23849, saving model to /data/oxford102/experiments/1548039573.9481478/benchmark_1548039573.9481478.h5\n",
      "Epoch 5/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 2.1136 - acc: 0.4387 - val_loss: 3.0814 - val_acc: 0.2652\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.23849 to 0.26519, saving model to /data/oxford102/experiments/1548039573.9481478/benchmark_1548039573.9481478.h5\n",
      "Epoch 6/100\n",
      "575/575 [==============================] - 32s 55ms/step - loss: 1.3669 - acc: 0.6122 - val_loss: 3.0599 - val_acc: 0.3177\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.26519 to 0.31768, saving model to /data/oxford102/experiments/1548039573.9481478/benchmark_1548039573.9481478.h5\n",
      "Epoch 7/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 0.5677 - acc: 0.8359 - val_loss: 3.9611 - val_acc: 0.2523\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.31768\n",
      "Epoch 8/100\n",
      "575/575 [==============================] - 32s 55ms/step - loss: 0.2579 - acc: 0.9235 - val_loss: 4.0771 - val_acc: 0.2772\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.31768\n",
      "Epoch 9/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 0.1203 - acc: 0.9646 - val_loss: 4.3961 - val_acc: 0.3278\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.31768 to 0.32781, saving model to /data/oxford102/experiments/1548039573.9481478/benchmark_1548039573.9481478.h5\n",
      "Epoch 10/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 0.0561 - acc: 0.9843 - val_loss: 4.6900 - val_acc: 0.3186\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.32781\n",
      "Epoch 11/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 0.0385 - acc: 0.9900 - val_loss: 5.0767 - val_acc: 0.2928\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.32781\n",
      "Epoch 12/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 0.0442 - acc: 0.9891 - val_loss: 4.7434 - val_acc: 0.3333\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.32781 to 0.33333, saving model to /data/oxford102/experiments/1548039573.9481478/benchmark_1548039573.9481478.h5\n",
      "Epoch 13/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 0.0044 - acc: 0.9993 - val_loss: 4.7074 - val_acc: 0.3600\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.33333 to 0.36004, saving model to /data/oxford102/experiments/1548039573.9481478/benchmark_1548039573.9481478.h5\n",
      "Epoch 14/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 4.6151e-04 - acc: 1.0000 - val_loss: 4.8744 - val_acc: 0.3527\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.36004\n",
      "Epoch 15/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 2.8665e-04 - acc: 1.0000 - val_loss: 5.0336 - val_acc: 0.3453\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.36004\n",
      "Epoch 16/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 2.2957e-04 - acc: 1.0000 - val_loss: 5.0741 - val_acc: 0.3499\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.36004\n",
      "Epoch 17/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 1.8420e-04 - acc: 1.0000 - val_loss: 5.0774 - val_acc: 0.3628\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.36004 to 0.36280, saving model to /data/oxford102/experiments/1548039573.9481478/benchmark_1548039573.9481478.h5\n",
      "Epoch 18/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 1.6237e-04 - acc: 1.0000 - val_loss: 5.1519 - val_acc: 0.3435\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.36280\n",
      "Epoch 19/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 1.3810e-04 - acc: 1.0000 - val_loss: 5.0644 - val_acc: 0.3628\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.36280\n",
      "Epoch 20/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 1.2500e-04 - acc: 1.0000 - val_loss: 5.3702 - val_acc: 0.3398\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.36280\n",
      "Epoch 21/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 1.1357e-04 - acc: 1.0000 - val_loss: 5.1928 - val_acc: 0.3600\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.36280\n",
      "Epoch 22/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 1.0298e-04 - acc: 1.0000 - val_loss: 5.3143 - val_acc: 0.3591\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.36280\n",
      "Epoch 00022: early stopping\n",
      "{'network_name': 'benchmark', 'image_aug': False, 'optimizer_name': 'SGD', 'optimizer_params': None, 'batch_size': 8, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1548039573.9481478}\n"
     ]
    }
   ],
   "source": [
    "lr=0.001\n",
    "rho=0.9\n",
    "epsilon=None\n",
    "decay=0.0\n",
    "\n",
    "_model, input_processor = get_model(params[\"network_name\"], image_size=params[\"image_size\"])\n",
    "train_generator, validation_generator = get_generators( params[\"batch_size\"], params[\"image_size\"], None)\n",
    "train_model(params, _model, (train_generator, validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_benchmark_model(verbose=False, img_size=(256, 256)):\n",
    "    \n",
    "    width, height = img_size\n",
    "    model = None\n",
    "    model = Sequential()\n",
    "\n",
    "    #conv_layer1\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(width, height, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # conv_layer2\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(n_categories, activation=\"softmax\"))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    return model, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "575/575 [==============================] - 40s 70ms/step - loss: 4.3079 - acc: 0.0509 - val_loss: 3.8810 - val_acc: 0.0947\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.09467, saving model to /data/oxford102/experiments/1548040357.6217308/benchmark_1548040357.6217308.h5\n",
      "Epoch 2/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 3.4832 - acc: 0.1561 - val_loss: 3.3817 - val_acc: 0.1796\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.09467 to 0.17956, saving model to /data/oxford102/experiments/1548040357.6217308/benchmark_1548040357.6217308.h5\n",
      "Epoch 3/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 2.8557 - acc: 0.2787 - val_loss: 3.1480 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.17956 to 0.23573, saving model to /data/oxford102/experiments/1548040357.6217308/benchmark_1548040357.6217308.h5\n",
      "Epoch 4/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 2.2148 - acc: 0.4115 - val_loss: 3.0300 - val_acc: 0.2634\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.23573 to 0.26335, saving model to /data/oxford102/experiments/1548040357.6217308/benchmark_1548040357.6217308.h5\n",
      "Epoch 5/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 1.3802 - acc: 0.6202 - val_loss: 3.0122 - val_acc: 0.3186\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.26335 to 0.31860, saving model to /data/oxford102/experiments/1548040357.6217308/benchmark_1548040357.6217308.h5\n",
      "Epoch 6/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.5243 - acc: 0.8504 - val_loss: 3.5245 - val_acc: 0.3122\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.31860\n",
      "Epoch 7/100\n",
      "575/575 [==============================] - 39s 67ms/step - loss: 0.1699 - acc: 0.9554 - val_loss: 4.8711 - val_acc: 0.2569\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.31860\n",
      "Epoch 8/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.0497 - acc: 0.9835 - val_loss: 3.7609 - val_acc: 0.3573\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.31860 to 0.35727, saving model to /data/oxford102/experiments/1548040357.6217308/benchmark_1548040357.6217308.h5\n",
      "Epoch 9/100\n",
      "575/575 [==============================] - 39s 67ms/step - loss: 0.0214 - acc: 0.9961 - val_loss: 3.6841 - val_acc: 0.3886\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.35727 to 0.38858, saving model to /data/oxford102/experiments/1548040357.6217308/benchmark_1548040357.6217308.h5\n",
      "Epoch 10/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.0055 - acc: 0.9993 - val_loss: 4.0178 - val_acc: 0.3610\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.38858\n",
      "Epoch 11/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 5.0003e-04 - acc: 1.0000 - val_loss: 3.9962 - val_acc: 0.3775\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.38858\n",
      "Epoch 12/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 3.2960e-04 - acc: 1.0000 - val_loss: 4.0776 - val_acc: 0.3803\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.38858\n",
      "Epoch 00012: early stopping\n",
      "{'network_name': 'benchmark', 'image_aug': False, 'optimizer_name': 'SGD', 'optimizer_params': None, 'batch_size': 8, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1548040357.6217308}\n"
     ]
    }
   ],
   "source": [
    "params = {'network_name': \"benchmark\",\n",
    "         'image_aug': False,\n",
    "         'optimizer_name': \"SGD\", \n",
    "         'optimizer': optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False),\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "lr=0.001\n",
    "rho=0.9\n",
    "epsilon=None\n",
    "decay=0.0\n",
    "\n",
    "_model, input_processor = get_model(params[\"network_name\"], image_size=params[\"image_size\"])\n",
    "train_generator, validation_generator = get_generators( params[\"batch_size\"], params[\"image_size\"], None)\n",
    "train_model(params, _model, (train_generator, validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_benchmark_model(verbose=False, img_size=(256, 256)):\n",
    "    \n",
    "    width, height = img_size\n",
    "    model = None\n",
    "    model = Sequential()\n",
    "\n",
    "    #conv_layer1\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(width, height, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.7))\n",
    "\n",
    "    # conv_layer2\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.7))\n",
    "\n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.7))\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.7))\n",
    "\n",
    "    model.add(Dense(n_categories, activation=\"softmax\"))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    return model, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "575/575 [==============================] - 41s 71ms/step - loss: 4.3114 - acc: 0.0511 - val_loss: 3.9101 - val_acc: 0.0882\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.08824, saving model to /data/oxford102/experiments/1548040933.4639325/benchmark_1548040933.4639325.h5\n",
      "Epoch 2/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 3.4808 - acc: 0.1598 - val_loss: 3.3776 - val_acc: 0.1869\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.08824 to 0.18692, saving model to /data/oxford102/experiments/1548040933.4639325/benchmark_1548040933.4639325.h5\n",
      "Epoch 3/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 2.8374 - acc: 0.2809 - val_loss: 3.1235 - val_acc: 0.2431\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.18692 to 0.24309, saving model to /data/oxford102/experiments/1548040933.4639325/benchmark_1548040933.4639325.h5\n",
      "Epoch 4/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 2.1870 - acc: 0.4183 - val_loss: 3.0123 - val_acc: 0.2744\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.24309 to 0.27440, saving model to /data/oxford102/experiments/1548040933.4639325/benchmark_1548040933.4639325.h5\n",
      "Epoch 5/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 1.3794 - acc: 0.6154 - val_loss: 3.2430 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.27440 to 0.32136, saving model to /data/oxford102/experiments/1548040933.4639325/benchmark_1548040933.4639325.h5\n",
      "Epoch 6/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.4852 - acc: 0.8626 - val_loss: 4.0148 - val_acc: 0.2983\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.32136\n",
      "Epoch 7/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.1559 - acc: 0.9567 - val_loss: 3.7192 - val_acc: 0.3398\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.32136 to 0.33978, saving model to /data/oxford102/experiments/1548040933.4639325/benchmark_1548040933.4639325.h5\n",
      "Epoch 8/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.0637 - acc: 0.9843 - val_loss: 3.6994 - val_acc: 0.3554\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.33978 to 0.35543, saving model to /data/oxford102/experiments/1548040933.4639325/benchmark_1548040933.4639325.h5\n",
      "Epoch 9/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.0216 - acc: 0.9943 - val_loss: 3.9065 - val_acc: 0.3711\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.35543 to 0.37109, saving model to /data/oxford102/experiments/1548040933.4639325/benchmark_1548040933.4639325.h5\n",
      "Epoch 10/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 4.0902 - val_acc: 0.3729\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.37109 to 0.37293, saving model to /data/oxford102/experiments/1548040933.4639325/benchmark_1548040933.4639325.h5\n",
      "Epoch 11/100\n",
      "575/575 [==============================] - 39s 69ms/step - loss: 4.5283e-04 - acc: 1.0000 - val_loss: 4.1613 - val_acc: 0.3738\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.37293 to 0.37385, saving model to /data/oxford102/experiments/1548040933.4639325/benchmark_1548040933.4639325.h5\n",
      "Epoch 12/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 3.1532e-04 - acc: 1.0000 - val_loss: 4.1274 - val_acc: 0.3877\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.37385 to 0.38766, saving model to /data/oxford102/experiments/1548040933.4639325/benchmark_1548040933.4639325.h5\n",
      "Epoch 13/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 2.4876e-04 - acc: 1.0000 - val_loss: 4.2544 - val_acc: 0.3766\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.38766\n",
      "Epoch 14/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 2.0500e-04 - acc: 1.0000 - val_loss: 4.4056 - val_acc: 0.3757\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.38766\n",
      "Epoch 15/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 1.7459e-04 - acc: 1.0000 - val_loss: 4.2213 - val_acc: 0.3923\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.38766 to 0.39227, saving model to /data/oxford102/experiments/1548040933.4639325/benchmark_1548040933.4639325.h5\n",
      "Epoch 16/100\n",
      "575/575 [==============================] - 40s 69ms/step - loss: 1.5380e-04 - acc: 1.0000 - val_loss: 4.4795 - val_acc: 0.3748\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.39227\n",
      "Epoch 17/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 1.3451e-04 - acc: 1.0000 - val_loss: 4.4510 - val_acc: 0.3803\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.39227\n",
      "Epoch 18/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 1.2610e-04 - acc: 1.0000 - val_loss: 4.3306 - val_acc: 0.4042\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.39227 to 0.40424, saving model to /data/oxford102/experiments/1548040933.4639325/benchmark_1548040933.4639325.h5\n",
      "Epoch 19/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 1.1185e-04 - acc: 1.0000 - val_loss: 4.5748 - val_acc: 0.3720\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.40424\n",
      "Epoch 20/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 1.0106e-04 - acc: 1.0000 - val_loss: 4.4638 - val_acc: 0.3904\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.40424\n",
      "Epoch 21/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 9.6566e-05 - acc: 1.0000 - val_loss: 4.5323 - val_acc: 0.3895\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.40424\n",
      "Epoch 00021: early stopping\n",
      "{'network_name': 'benchmark', 'image_aug': False, 'optimizer_name': 'SGD', 'optimizer_params': None, 'batch_size': 8, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1548040933.4639325}\n"
     ]
    }
   ],
   "source": [
    "params = {'network_name': \"benchmark\",\n",
    "         'image_aug': False,\n",
    "         'optimizer_name': \"SGD\", \n",
    "         'optimizer': optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False),\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "lr=0.001\n",
    "rho=0.9\n",
    "epsilon=None\n",
    "decay=0.0\n",
    "\n",
    "_model, input_processor = get_model(params[\"network_name\"], image_size=params[\"image_size\"])\n",
    "train_generator, validation_generator = get_generators( params[\"batch_size\"], params[\"image_size\"], None)\n",
    "train_model(params, _model, (train_generator, validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'network_name': \"benchmark\",\n",
    "         'image_aug': True,\n",
    "         'optimizer_name': \"SGD\", \n",
    "         'optimizer': optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False),\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "lr=0.001\n",
    "rho=0.9\n",
    "epsilon=None\n",
    "decay=0.0\n",
    "\n",
    "_model, input_processor = get_model(params[\"network_name\"], image_size=params[\"image_size\"])\n",
    "train_generator, validation_generator = get_generators( params[\"batch_size\"], params[\"image_size\"], None)\n",
    "train_model(params, _model, (train_generator, validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_benchmark_model(verbose=False, img_size=(256, 256)):\n",
    "    \n",
    "    width, height = img_size\n",
    "    model = None\n",
    "    model = Sequential()\n",
    "\n",
    "    #conv_layer1\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(width, height, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.7))\n",
    "\n",
    "    # conv_layer2\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.7))\n",
    "\n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.7))\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.7))\n",
    "\n",
    "    model.add(Dense(n_categories,kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01), activation=\"softmax\"))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    return model, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "575/575 [==============================] - 41s 71ms/step - loss: 6.0723 - acc: 0.0487 - val_loss: 5.5043 - val_acc: 0.0818\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.08180, saving model to /data/oxford102/experiments/1548042086.4225383/benchmark_1548042086.4225383.h5\n",
      "Epoch 2/100\n",
      "575/575 [==============================] - 39s 69ms/step - loss: 4.9473 - acc: 0.1465 - val_loss: 4.7098 - val_acc: 0.1805\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.08180 to 0.18048, saving model to /data/oxford102/experiments/1548042086.4225383/benchmark_1548042086.4225383.h5\n",
      "Epoch 3/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 4.1181 - acc: 0.2585 - val_loss: 4.3036 - val_acc: 0.2127\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.18048 to 0.21271, saving model to /data/oxford102/experiments/1548042086.4225383/benchmark_1548042086.4225383.h5\n",
      "Epoch 4/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 3.4007 - acc: 0.3670 - val_loss: 3.8365 - val_acc: 0.2753\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.21271 to 0.27532, saving model to /data/oxford102/experiments/1548042086.4225383/benchmark_1548042086.4225383.h5\n",
      "Epoch 5/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 2.6920 - acc: 0.5033 - val_loss: 3.8641 - val_acc: 0.2772\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.27532 to 0.27716, saving model to /data/oxford102/experiments/1548042086.4225383/benchmark_1548042086.4225383.h5\n",
      "Epoch 6/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 1.8971 - acc: 0.6817 - val_loss: 4.0694 - val_acc: 0.2983\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.27716 to 0.29834, saving model to /data/oxford102/experiments/1548042086.4225383/benchmark_1548042086.4225383.h5\n",
      "Epoch 7/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 1.2424 - acc: 0.8589 - val_loss: 4.2073 - val_acc: 0.3306\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.29834 to 0.33057, saving model to /data/oxford102/experiments/1548042086.4225383/benchmark_1548042086.4225383.h5\n",
      "Epoch 8/100\n",
      "575/575 [==============================] - 39s 69ms/step - loss: 0.7709 - acc: 0.9604 - val_loss: 3.9436 - val_acc: 0.3610\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.33057 to 0.36096, saving model to /data/oxford102/experiments/1548042086.4225383/benchmark_1548042086.4225383.h5\n",
      "Epoch 9/100\n",
      "575/575 [==============================] - 39s 69ms/step - loss: 0.6271 - acc: 0.9774 - val_loss: 3.9060 - val_acc: 0.3683\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.36096 to 0.36832, saving model to /data/oxford102/experiments/1548042086.4225383/benchmark_1548042086.4225383.h5\n",
      "Epoch 10/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.5134 - acc: 0.9872 - val_loss: 4.0700 - val_acc: 0.3324\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.36832\n",
      "Epoch 11/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.4676 - acc: 0.9867 - val_loss: 4.8841 - val_acc: 0.2947\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.36832\n",
      "Epoch 12/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.3646 - acc: 0.9957 - val_loss: 3.6507 - val_acc: 0.3757\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.36832 to 0.37569, saving model to /data/oxford102/experiments/1548042086.4225383/benchmark_1548042086.4225383.h5\n",
      "Epoch 13/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.2994 - acc: 0.9996 - val_loss: 3.6704 - val_acc: 0.3831\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.37569 to 0.38306, saving model to /data/oxford102/experiments/1548042086.4225383/benchmark_1548042086.4225383.h5\n",
      "Epoch 14/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.2539 - acc: 1.0000 - val_loss: 3.5965 - val_acc: 0.3904\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.38306 to 0.39042, saving model to /data/oxford102/experiments/1548042086.4225383/benchmark_1548042086.4225383.h5\n",
      "Epoch 15/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.2200 - acc: 1.0000 - val_loss: 3.5289 - val_acc: 0.3886\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.39042\n",
      "Epoch 16/100\n",
      "575/575 [==============================] - 40s 70ms/step - loss: 0.1934 - acc: 1.0000 - val_loss: 3.6202 - val_acc: 0.3775\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.39042\n",
      "Epoch 17/100\n",
      "575/575 [==============================] - 40s 69ms/step - loss: 0.2594 - acc: 0.9915 - val_loss: 10.4562 - val_acc: 0.0599\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.39042\n",
      "Epoch 00017: early stopping\n",
      "{'network_name': 'benchmark', 'image_aug': True, 'optimizer_name': 'SGD', 'optimizer_params': None, 'batch_size': 8, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1548042086.4225383}\n"
     ]
    }
   ],
   "source": [
    "params = {'network_name': \"benchmark\",\n",
    "         'image_aug': True,\n",
    "         'optimizer_name': \"SGD\", \n",
    "         'optimizer': optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False),\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "lr=0.001\n",
    "rho=0.9\n",
    "epsilon=None\n",
    "decay=0.0\n",
    "\n",
    "_model, input_processor = get_model(params[\"network_name\"], image_size=params[\"image_size\"])\n",
    "train_generator, validation_generator = get_generators( params[\"batch_size\"], params[\"image_size\"], None)\n",
    "train_model(params, _model, (train_generator, validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.preprocessing.image.ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False, zca_whitening=False, zca_epsilon=1e-06, rotation_range=0, width_shift_range=0.0, height_shift_range=0.0, brightness_range=None, shear_range=0.0, zoom_range=0.0, channel_shift_range=0.0, fill_mode='nearest', cval=0.0, horizontal_flip=False, vertical_flip=False, rescale=None, preprocessing_function=None, data_format=None, validation_split=0.0, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_benchmark_model(verbose=False, img_size=(256, 256)):\n",
    "    \n",
    "    width, height = img_size\n",
    "    model = None\n",
    "    model = Sequential()\n",
    "\n",
    "    #conv_layer1\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(width, height, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    # conv_layer2\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.85))\n",
    "\n",
    "    model.add(Dense(n_categories,kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01), activation=\"softmax\"))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    return model, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "575/575 [==============================] - 41s 72ms/step - loss: 6.0704 - acc: 0.0500 - val_loss: 5.5051 - val_acc: 0.0827\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.08272, saving model to /data/oxford102/experiments/1548043516.3301682/benchmark_1548043516.3301682.h5\n",
      "Epoch 2/100\n",
      "575/575 [==============================] - 39s 69ms/step - loss: 4.9436 - acc: 0.1533 - val_loss: 4.6930 - val_acc: 0.1768\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.08272 to 0.17680, saving model to /data/oxford102/experiments/1548043516.3301682/benchmark_1548043516.3301682.h5\n",
      "Epoch 3/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 4.1052 - acc: 0.2620 - val_loss: 4.2645 - val_acc: 0.2265\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.17680 to 0.22652, saving model to /data/oxford102/experiments/1548043516.3301682/benchmark_1548043516.3301682.h5\n",
      "Epoch 4/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 3.3597 - acc: 0.3793 - val_loss: 4.1157 - val_acc: 0.2431\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.22652 to 0.24309, saving model to /data/oxford102/experiments/1548043516.3301682/benchmark_1548043516.3301682.h5\n",
      "Epoch 5/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 2.6471 - acc: 0.5157 - val_loss: 3.9100 - val_acc: 0.2974\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.24309 to 0.29742, saving model to /data/oxford102/experiments/1548043516.3301682/benchmark_1548043516.3301682.h5\n",
      "Epoch 6/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 1.8392 - acc: 0.7026 - val_loss: 3.9295 - val_acc: 0.3066\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.29742 to 0.30663, saving model to /data/oxford102/experiments/1548043516.3301682/benchmark_1548043516.3301682.h5\n",
      "Epoch 7/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 1.0964 - acc: 0.8902 - val_loss: 3.9667 - val_acc: 0.3232\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.30663 to 0.32320, saving model to /data/oxford102/experiments/1548043516.3301682/benchmark_1548043516.3301682.h5\n",
      "Epoch 8/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.7938 - acc: 0.9552 - val_loss: 4.4971 - val_acc: 0.3425\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.32320 to 0.34254, saving model to /data/oxford102/experiments/1548043516.3301682/benchmark_1548043516.3301682.h5\n",
      "Epoch 9/100\n",
      "575/575 [==============================] - 39s 69ms/step - loss: 0.6624 - acc: 0.9717 - val_loss: 3.9439 - val_acc: 0.3573\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.34254 to 0.35727, saving model to /data/oxford102/experiments/1548043516.3301682/benchmark_1548043516.3301682.h5\n",
      "Epoch 10/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.4899 - acc: 0.9948 - val_loss: 3.8551 - val_acc: 0.3886\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.35727 to 0.38858, saving model to /data/oxford102/experiments/1548043516.3301682/benchmark_1548043516.3301682.h5\n",
      "Epoch 11/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.3893 - acc: 1.0000 - val_loss: 3.8217 - val_acc: 0.3923\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.38858 to 0.39227, saving model to /data/oxford102/experiments/1548043516.3301682/benchmark_1548043516.3301682.h5\n",
      "Epoch 12/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.3266 - acc: 1.0000 - val_loss: 3.7846 - val_acc: 0.3950\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.39227 to 0.39503, saving model to /data/oxford102/experiments/1548043516.3301682/benchmark_1548043516.3301682.h5\n",
      "Epoch 13/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.2777 - acc: 1.0000 - val_loss: 3.6414 - val_acc: 0.3987\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.39503 to 0.39871, saving model to /data/oxford102/experiments/1548043516.3301682/benchmark_1548043516.3301682.h5\n",
      "Epoch 14/100\n",
      "575/575 [==============================] - 40s 69ms/step - loss: 0.2392 - acc: 1.0000 - val_loss: 3.6062 - val_acc: 0.4098\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.39871 to 0.40976, saving model to /data/oxford102/experiments/1548043516.3301682/benchmark_1548043516.3301682.h5\n",
      "Epoch 15/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.2087 - acc: 1.0000 - val_loss: 3.6139 - val_acc: 0.3877\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.40976\n",
      "Epoch 16/100\n",
      "575/575 [==============================] - 39s 68ms/step - loss: 0.1849 - acc: 1.0000 - val_loss: 3.5993 - val_acc: 0.3904\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.40976\n",
      "Epoch 17/100\n",
      "575/575 [==============================] - 39s 69ms/step - loss: 0.1663 - acc: 1.0000 - val_loss: 3.5355 - val_acc: 0.3923\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.40976\n",
      "Epoch 00017: early stopping\n",
      "{'network_name': 'benchmark', 'image_aug': True, 'optimizer_name': 'SGD', 'optimizer_params': None, 'batch_size': 8, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1548043516.3301682}\n"
     ]
    }
   ],
   "source": [
    "params = {'network_name': \"benchmark\",\n",
    "         'image_aug': True,\n",
    "         'optimizer_name': \"SGD\", \n",
    "         'optimizer': optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False),\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "lr=0.001\n",
    "rho=0.9\n",
    "epsilon=None\n",
    "decay=0.0\n",
    "\n",
    "_model, input_processor = get_model(params[\"network_name\"], image_size=params[\"image_size\"])\n",
    "train_generator, validation_generator = get_generators( params[\"batch_size\"], params[\"image_size\"], None)\n",
    "train_model(params, _model, (train_generator, validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_benchmark_model(verbose=False, img_size=(256, 256)):\n",
    "    \n",
    "    width, height = img_size\n",
    "    model = None\n",
    "    model = Sequential()\n",
    "\n",
    "    #conv_layer1\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(width, height, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    # conv_layer2\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "    \n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "    \n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "    \n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.85))\n",
    "\n",
    "    model.add(Dense(n_categories,kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01), activation=\"softmax\"))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    return model, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "575/575 [==============================] - 34s 59ms/step - loss: 6.2904 - acc: 0.0311 - val_loss: 6.0453 - val_acc: 0.0230\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.02298, saving model to /data/oxford102/experiments/1548044535.778602/benchmark_1548044535.778602.h5\n",
      "Epoch 2/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 5.8792 - acc: 0.0291 - val_loss: 5.6865 - val_acc: 0.0525\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.02298 to 0.05249, saving model to /data/oxford102/experiments/1548044535.778602/benchmark_1548044535.778602.h5\n",
      "Epoch 3/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 5.3775 - acc: 0.0543 - val_loss: 5.0505 - val_acc: 0.0654\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.05249 to 0.06538, saving model to /data/oxford102/experiments/1548044535.778602/benchmark_1548044535.778602.h5\n",
      "Epoch 4/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 4.9210 - acc: 0.0598 - val_loss: 4.6803 - val_acc: 0.0939\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.06538 to 0.09392, saving model to /data/oxford102/experiments/1548044535.778602/benchmark_1548044535.778602.h5\n",
      "Epoch 5/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 4.5234 - acc: 0.0985 - val_loss: 4.2197 - val_acc: 0.1317\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.09392 to 0.13168, saving model to /data/oxford102/experiments/1548044535.778602/benchmark_1548044535.778602.h5\n",
      "Epoch 6/100\n",
      "575/575 [==============================] - 32s 55ms/step - loss: 4.0964 - acc: 0.1422 - val_loss: 3.9827 - val_acc: 0.1556\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.13168 to 0.15562, saving model to /data/oxford102/experiments/1548044535.778602/benchmark_1548044535.778602.h5\n",
      "Epoch 7/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 3.7065 - acc: 0.1978 - val_loss: 3.7438 - val_acc: 0.2127\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.15562 to 0.21271, saving model to /data/oxford102/experiments/1548044535.778602/benchmark_1548044535.778602.h5\n",
      "Epoch 8/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 3.3966 - acc: 0.2417 - val_loss: 3.4393 - val_acc: 0.2514\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.21271 to 0.25138, saving model to /data/oxford102/experiments/1548044535.778602/benchmark_1548044535.778602.h5\n",
      "Epoch 9/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 3.1290 - acc: 0.2926 - val_loss: 3.2999 - val_acc: 0.3002\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.25138 to 0.30018, saving model to /data/oxford102/experiments/1548044535.778602/benchmark_1548044535.778602.h5\n",
      "Epoch 10/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 2.8564 - acc: 0.3659 - val_loss: 3.5743 - val_acc: 0.2155\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.30018\n",
      "Epoch 11/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 2.6241 - acc: 0.3989 - val_loss: 3.4835 - val_acc: 0.2680\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.30018\n",
      "Epoch 12/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 2.4055 - acc: 0.4637 - val_loss: 3.3809 - val_acc: 0.2855\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.30018\n",
      "Epoch 00012: early stopping\n",
      "{'network_name': 'benchmark', 'image_aug': True, 'optimizer_name': 'SGD', 'optimizer_params': None, 'batch_size': 8, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1548044535.778602}\n"
     ]
    }
   ],
   "source": [
    "params = {'network_name': \"benchmark\",\n",
    "         'image_aug': True,\n",
    "         'optimizer_name': \"SGD\", \n",
    "         'optimizer': optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False),\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "lr=0.001\n",
    "rho=0.9\n",
    "epsilon=None\n",
    "decay=0.0\n",
    "\n",
    "_model, input_processor = get_model(params[\"network_name\"], image_size=params[\"image_size\"])\n",
    "train_generator, validation_generator = get_generators( params[\"batch_size\"], params[\"image_size\"], None)\n",
    "train_model(params, _model, (train_generator, validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_benchmark_model(verbose=False, img_size=(256, 256)):\n",
    "    \n",
    "    width, height = img_size\n",
    "    model = None\n",
    "    model = Sequential()\n",
    "\n",
    "    #conv_layer1\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(width, height, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    # conv_layer2\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "       \n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "    \n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.85))\n",
    "\n",
    "    model.add(Dense(n_categories,kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01), activation=\"softmax\"))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    return model, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "575/575 [==============================] - 34s 58ms/step - loss: 6.2741 - acc: 0.0267 - val_loss: 5.9802 - val_acc: 0.0294\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.02941, saving model to /data/oxford102/experiments/1548045075.7719638/benchmark_1548045075.7719638.h5\n",
      "Epoch 2/100\n",
      "575/575 [==============================] - 33s 58ms/step - loss: 5.5656 - acc: 0.0613 - val_loss: 5.2883 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.02941 to 0.08195, saving model to /data/oxford102/experiments/1548045075.7719638/benchmark_1548045075.7719638.h5\n",
      "Epoch 3/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 4.9901 - acc: 0.0939 - val_loss: 4.7323 - val_acc: 0.1087\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.08195 to 0.10866, saving model to /data/oxford102/experiments/1548045075.7719638/benchmark_1548045075.7719638.h5\n",
      "Epoch 4/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 4.4800 - acc: 0.1363 - val_loss: 4.3690 - val_acc: 0.1584\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.10866 to 0.15838, saving model to /data/oxford102/experiments/1548045075.7719638/benchmark_1548045075.7719638.h5\n",
      "Epoch 5/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 4.0502 - acc: 0.1885 - val_loss: 4.0111 - val_acc: 0.1676\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.15838 to 0.16759, saving model to /data/oxford102/experiments/1548045075.7719638/benchmark_1548045075.7719638.h5\n",
      "Epoch 6/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 3.6699 - acc: 0.2307 - val_loss: 3.9437 - val_acc: 0.2035\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.16759 to 0.20350, saving model to /data/oxford102/experiments/1548045075.7719638/benchmark_1548045075.7719638.h5\n",
      "Epoch 7/100\n",
      "575/575 [==============================] - 33s 58ms/step - loss: 3.3006 - acc: 0.2976 - val_loss: 3.7940 - val_acc: 0.2302\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.20350 to 0.23020, saving model to /data/oxford102/experiments/1548045075.7719638/benchmark_1548045075.7719638.h5\n",
      "Epoch 8/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 2.9361 - acc: 0.3665 - val_loss: 3.5074 - val_acc: 0.2597\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.23020 to 0.25967, saving model to /data/oxford102/experiments/1548045075.7719638/benchmark_1548045075.7719638.h5\n",
      "Epoch 9/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 2.5829 - acc: 0.4415 - val_loss: 4.0219 - val_acc: 0.2192\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.25967\n",
      "Epoch 10/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 2.2147 - acc: 0.5246 - val_loss: 4.5565 - val_acc: 0.1888\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.25967\n",
      "Epoch 11/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 1.9137 - acc: 0.6296 - val_loss: 4.3000 - val_acc: 0.2339\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.25967\n",
      "Epoch 00011: early stopping\n",
      "{'network_name': 'benchmark', 'image_aug': True, 'optimizer_name': 'SGD', 'optimizer_params': None, 'batch_size': 8, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1548045075.7719638}\n"
     ]
    }
   ],
   "source": [
    "params = {'network_name': \"benchmark\",\n",
    "         'image_aug': True,\n",
    "         'optimizer_name': \"SGD\", \n",
    "         'optimizer': optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False),\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "lr=0.001\n",
    "rho=0.9\n",
    "epsilon=None\n",
    "decay=0.0\n",
    "\n",
    "_model, input_processor = get_model(params[\"network_name\"], image_size=params[\"image_size\"])\n",
    "train_generator, validation_generator = get_generators( params[\"batch_size\"], params[\"image_size\"], None)\n",
    "train_model(params, _model, (train_generator, validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_benchmark_model(verbose=False, img_size=(256, 256)):\n",
    "    \n",
    "    width, height = img_size\n",
    "    model = None\n",
    "    model = Sequential()\n",
    "\n",
    "    #conv_layer1\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(width, height, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    # conv_layer2\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "    \n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "    \n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "    \n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.85))\n",
    "\n",
    "    model.add(Dense(n_categories,kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01), activation=\"softmax\"))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    return model, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "575/575 [==============================] - 33s 58ms/step - loss: 4.7690 - acc: 0.0383 - val_loss: 4.4998 - val_acc: 0.0708\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.07077, saving model to /data/oxford102/experiments/1548046260.477109/benchmark_1548046260.477109.h5\n",
      "Epoch 2/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 4.5399 - acc: 0.0802 - val_loss: 4.6874 - val_acc: 0.0773\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.07077 to 0.07735, saving model to /data/oxford102/experiments/1548046260.477109/benchmark_1548046260.477109.h5\n",
      "Epoch 3/100\n",
      "575/575 [==============================] - 32s 55ms/step - loss: 4.6268 - acc: 0.1072 - val_loss: 4.7501 - val_acc: 0.1298\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.07735 to 0.12983, saving model to /data/oxford102/experiments/1548046260.477109/benchmark_1548046260.477109.h5\n",
      "Epoch 4/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 4.8082 - acc: 0.1604 - val_loss: 4.9141 - val_acc: 0.1961\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.12983 to 0.19613, saving model to /data/oxford102/experiments/1548046260.477109/benchmark_1548046260.477109.h5\n",
      "Epoch 5/100\n",
      "575/575 [==============================] - 32s 55ms/step - loss: 5.1543 - acc: 0.2170 - val_loss: 5.3270 - val_acc: 0.2551\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.19613 to 0.25506, saving model to /data/oxford102/experiments/1548046260.477109/benchmark_1548046260.477109.h5\n",
      "Epoch 6/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 5.5093 - acc: 0.2800 - val_loss: 5.9510 - val_acc: 0.2643\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.25506 to 0.26427, saving model to /data/oxford102/experiments/1548046260.477109/benchmark_1548046260.477109.h5\n",
      "Epoch 7/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 5.8303 - acc: 0.3287 - val_loss: 6.1989 - val_acc: 0.3149\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.26427 to 0.31492, saving model to /data/oxford102/experiments/1548046260.477109/benchmark_1548046260.477109.h5\n",
      "Epoch 8/100\n",
      "575/575 [==============================] - 32s 55ms/step - loss: 5.9978 - acc: 0.3850 - val_loss: 6.3409 - val_acc: 0.3508\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.31492 to 0.35083, saving model to /data/oxford102/experiments/1548046260.477109/benchmark_1548046260.477109.h5\n",
      "Epoch 9/100\n",
      "575/575 [==============================] - 31s 55ms/step - loss: 6.0675 - acc: 0.4248 - val_loss: 6.5987 - val_acc: 0.3692\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.35083 to 0.36924, saving model to /data/oxford102/experiments/1548046260.477109/benchmark_1548046260.477109.h5\n",
      "Epoch 10/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 6.1623 - acc: 0.4796 - val_loss: 7.0065 - val_acc: 0.3877\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.36924 to 0.38766, saving model to /data/oxford102/experiments/1548046260.477109/benchmark_1548046260.477109.h5\n",
      "Epoch 11/100\n",
      "575/575 [==============================] - 32s 55ms/step - loss: 6.2584 - acc: 0.5243 - val_loss: 7.0961 - val_acc: 0.4162\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.38766 to 0.41621, saving model to /data/oxford102/experiments/1548046260.477109/benchmark_1548046260.477109.h5\n",
      "Epoch 12/100\n",
      "575/575 [==============================] - 31s 55ms/step - loss: 6.2440 - acc: 0.5548 - val_loss: 6.9678 - val_acc: 0.4061\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.41621\n",
      "Epoch 13/100\n",
      "575/575 [==============================] - 32s 55ms/step - loss: 6.0428 - acc: 0.5833 - val_loss: 7.2633 - val_acc: 0.3904\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.41621\n",
      "Epoch 14/100\n",
      "575/575 [==============================] - 32s 55ms/step - loss: 5.9958 - acc: 0.6157 - val_loss: 7.5250 - val_acc: 0.4429\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.41621 to 0.44291, saving model to /data/oxford102/experiments/1548046260.477109/benchmark_1548046260.477109.h5\n",
      "Epoch 15/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 6.0681 - acc: 0.6483 - val_loss: 7.6494 - val_acc: 0.4273\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.44291\n",
      "Epoch 16/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 6.1169 - acc: 0.6624 - val_loss: 7.6770 - val_acc: 0.4374\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.44291\n",
      "Epoch 17/100\n",
      "575/575 [==============================] - 32s 55ms/step - loss: 6.1820 - acc: 0.6859 - val_loss: 7.8890 - val_acc: 0.4079\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.44291\n",
      "Epoch 00017: early stopping\n",
      "{'network_name': 'benchmark', 'image_aug': True, 'optimizer_name': 'SGD', 'optimizer_params': None, 'batch_size': 8, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1548046260.477109}\n"
     ]
    }
   ],
   "source": [
    "params = {'network_name': \"benchmark\",\n",
    "         'image_aug': True,\n",
    "         'optimizer_name': \"SGD\", \n",
    "         'optimizer': optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0),\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "lr=0.001\n",
    "rho=0.9\n",
    "epsilon=None\n",
    "decay=0.0\n",
    "\n",
    "_model, input_processor = get_model(params[\"network_name\"], image_size=params[\"image_size\"])\n",
    "train_generator, validation_generator = get_generators( params[\"batch_size\"], params[\"image_size\"], None)\n",
    "train_model(params, _model, (train_generator, validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_benchmark_model(verbose=False, img_size=(256, 256)):\n",
    "    \n",
    "    width, height = img_size\n",
    "    model = None\n",
    "    model = Sequential()\n",
    "\n",
    "    #conv_layer1\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(width, height, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    # conv_layer2\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "    \n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "    \n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.8))\n",
    "    \n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.85))\n",
    "\n",
    "    model.add(Dense(n_categories,kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01), activation=\"softmax\"))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    return model, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_benchmark_model(verbose=False, img_size=(256, 256)):\n",
    "    \n",
    "    width, height = img_size\n",
    "    model = None\n",
    "    model = Sequential()\n",
    "\n",
    "#     import keras \n",
    "#     from keras.models import Sequential\n",
    "#     from keras.layers import Conv2D\n",
    "#     from keras.layers import MaxPooling2D\n",
    "#     from keras.layers import Flatten\n",
    "#     from keras.layers import Dense\n",
    "    \n",
    "#     model = Sequential()\n",
    "    #Layer 1\n",
    "    #Conv Layer 1\n",
    "    model.add(Conv2D(filters = 6, \n",
    "                     kernel_size = 5, \n",
    "                     strides = 1, \n",
    "                     activation = 'relu', \n",
    "                     input_shape = (width,height,3)))\n",
    "    #Pooling layer 1\n",
    "    model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    #Layer 2\n",
    "    #Conv Layer 2\n",
    "    model.add(Conv2D(filters = 16, \n",
    "                     kernel_size = 5,\n",
    "                     strides = 1,\n",
    "                     activation = 'relu',\n",
    "                     input_shape = (14,14,6)))\n",
    "    #Pooling Layer 2\n",
    "    model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    #Flatten\n",
    "    model.add(Flatten())\n",
    "    #Layer 3\n",
    "    #Fully connected layer 1\n",
    "    model.add(Dense(units = 120, activation = 'relu'))\n",
    "    #Layer 4\n",
    "    #Fully connected layer 2\n",
    "    model.add(Dense(units = 84, activation = 'relu'))\n",
    "    #Layer 5\n",
    "    #Output Layer\n",
    "    model.add(Dense(units = 102, activation = 'softmax'))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    return model, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "575/575 [==============================] - 43s 75ms/step - loss: 4.0879 - acc: 0.0843 - val_loss: 3.6113 - val_acc: 0.1333\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.13327, saving model to /data/oxford102/experiments/1548101569.2404804/benchmark_1548101569.2404804.h5\n",
      "Epoch 2/100\n",
      "575/575 [==============================] - 33s 58ms/step - loss: 3.0858 - acc: 0.2343 - val_loss: 3.1702 - val_acc: 0.2238\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.13327 to 0.22376, saving model to /data/oxford102/experiments/1548101569.2404804/benchmark_1548101569.2404804.h5\n",
      "Epoch 3/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 1.9438 - acc: 0.4857 - val_loss: 3.5375 - val_acc: 0.2403\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.22376 to 0.24033, saving model to /data/oxford102/experiments/1548101569.2404804/benchmark_1548101569.2404804.h5\n",
      "Epoch 4/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 0.8601 - acc: 0.7620 - val_loss: 4.2755 - val_acc: 0.2477\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.24033 to 0.24770, saving model to /data/oxford102/experiments/1548101569.2404804/benchmark_1548101569.2404804.h5\n",
      "Epoch 5/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 0.2929 - acc: 0.9154 - val_loss: 5.6617 - val_acc: 0.2063\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.24770\n",
      "Epoch 6/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 0.1771 - acc: 0.9511 - val_loss: 6.5718 - val_acc: 0.2210\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.24770\n",
      "Epoch 7/100\n",
      "575/575 [==============================] - 33s 58ms/step - loss: 0.1023 - acc: 0.9722 - val_loss: 7.7330 - val_acc: 0.2118\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.24770\n",
      "Epoch 00007: early stopping\n",
      "{'network_name': 'benchmark', 'image_aug': True, 'optimizer_name': 'SGD', 'optimizer_params': None, 'batch_size': 8, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1548101569.2404804}\n"
     ]
    }
   ],
   "source": [
    "params = {'network_name': \"benchmark\",\n",
    "         'image_aug': True,\n",
    "         'optimizer_name': \"SGD\", \n",
    "         'optimizer': optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0),\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "lr=0.001\n",
    "rho=0.9\n",
    "epsilon=None\n",
    "decay=0.0\n",
    "\n",
    "_model, input_processor = get_model(params[\"network_name\"], image_size=params[\"image_size\"])\n",
    "train_generator, validation_generator = get_generators( params[\"batch_size\"], params[\"image_size\"], None)\n",
    "train_model(params, _model, (train_generator, validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_benchmark_model(verbose=False, img_size=(256, 256)):\n",
    "    \n",
    "    width, height = img_size\n",
    "    model = None\n",
    "    model = Sequential()\n",
    "\n",
    "#     import keras \n",
    "#     from keras.models import Sequential\n",
    "#     from keras.layers import Conv2D\n",
    "#     from keras.layers import MaxPooling2D\n",
    "#     from keras.layers import Flatten\n",
    "#     from keras.layers import Dense\n",
    "    \n",
    "#     model = Sequential()\n",
    "    #Layer 1\n",
    "    #Conv Layer 1\n",
    "    model.add(Conv2D(filters = 20, \n",
    "                     kernel_size = 5, \n",
    "                     strides = 1, \n",
    "                     activation = 'relu', \n",
    "                     input_shape = (width,height,3)))\n",
    "    #Pooling layer 1\n",
    "    model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    #Layer 2\n",
    "    #Conv Layer 2\n",
    "    model.add(Conv2D(filters = 50, \n",
    "                     kernel_size = 5,\n",
    "                     strides = 1,\n",
    "                     activation = 'relu'\n",
    "                     ))\n",
    "    #Pooling Layer 2\n",
    "    model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    #Flatten\n",
    "    model.add(Flatten())\n",
    "    #Layer 3\n",
    "    #Fully connected layer 1\n",
    "    model.add(Dense(units = 500, activation = 'relu'))\n",
    "#     #Layer 4\n",
    "#     #Fully connected layer 2\n",
    "#     model.add(Dense(units = 84, activation = 'relu'))\n",
    "    model.add(Dropout(0.85))\n",
    "    #Layer 5\n",
    "    #Output Layer\n",
    "    model.add(Dense(units = 102, activation = 'softmax'))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    return model, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "575/575 [==============================] - 61s 107ms/step - loss: 4.1051 - acc: 0.0811 - val_loss: 3.6721 - val_acc: 0.1369\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.13695, saving model to /data/oxford102/experiments/1548104077.225572/benchmark_1548104077.225572.h5\n",
      "Epoch 2/100\n",
      "575/575 [==============================] - 60s 104ms/step - loss: 3.2583 - acc: 0.2067 - val_loss: 3.3027 - val_acc: 0.2053\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.13695 to 0.20534, saving model to /data/oxford102/experiments/1548104077.225572/benchmark_1548104077.225572.h5\n",
      "Epoch 3/100\n",
      "575/575 [==============================] - 60s 104ms/step - loss: 2.5864 - acc: 0.3330 - val_loss: 3.2194 - val_acc: 0.2578\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.20534 to 0.25783, saving model to /data/oxford102/experiments/1548104077.225572/benchmark_1548104077.225572.h5\n",
      "Epoch 4/100\n",
      "575/575 [==============================] - 60s 104ms/step - loss: 1.8386 - acc: 0.5065 - val_loss: 3.1956 - val_acc: 0.2726\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.25783 to 0.27256, saving model to /data/oxford102/experiments/1548104077.225572/benchmark_1548104077.225572.h5\n",
      "Epoch 5/100\n",
      "575/575 [==============================] - 59s 103ms/step - loss: 0.8318 - acc: 0.7724 - val_loss: 3.7790 - val_acc: 0.2597\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.27256\n",
      "Epoch 6/100\n",
      "575/575 [==============================] - 60s 104ms/step - loss: 0.2114 - acc: 0.9428 - val_loss: 3.5711 - val_acc: 0.3241\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.27256 to 0.32413, saving model to /data/oxford102/experiments/1548104077.225572/benchmark_1548104077.225572.h5\n",
      "Epoch 7/100\n",
      "575/575 [==============================] - 60s 104ms/step - loss: 0.0376 - acc: 0.9904 - val_loss: 3.4893 - val_acc: 0.3757\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.32413 to 0.37569, saving model to /data/oxford102/experiments/1548104077.225572/benchmark_1548104077.225572.h5\n",
      "Epoch 8/100\n",
      "575/575 [==============================] - 60s 104ms/step - loss: 0.0105 - acc: 0.9985 - val_loss: 3.6083 - val_acc: 0.4042\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.37569 to 0.40424, saving model to /data/oxford102/experiments/1548104077.225572/benchmark_1548104077.225572.h5\n",
      "Epoch 9/100\n",
      "575/575 [==============================] - 60s 104ms/step - loss: 0.0018 - acc: 0.9998 - val_loss: 3.8328 - val_acc: 0.4116\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.40424 to 0.41160, saving model to /data/oxford102/experiments/1548104077.225572/benchmark_1548104077.225572.h5\n",
      "Epoch 10/100\n",
      "575/575 [==============================] - 60s 104ms/step - loss: 5.7993e-04 - acc: 1.0000 - val_loss: 3.9900 - val_acc: 0.3996\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.41160\n",
      "Epoch 11/100\n",
      "575/575 [==============================] - 60s 104ms/step - loss: 3.5962e-04 - acc: 1.0000 - val_loss: 3.9691 - val_acc: 0.4116\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.41160 to 0.41160, saving model to /data/oxford102/experiments/1548104077.225572/benchmark_1548104077.225572.h5\n",
      "Epoch 12/100\n",
      "575/575 [==============================] - 60s 104ms/step - loss: 2.7724e-04 - acc: 1.0000 - val_loss: 3.9703 - val_acc: 0.4033\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.41160\n",
      "Epoch 13/100\n",
      "575/575 [==============================] - 60s 104ms/step - loss: 2.3476e-04 - acc: 1.0000 - val_loss: 4.0701 - val_acc: 0.4144\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.41160 to 0.41436, saving model to /data/oxford102/experiments/1548104077.225572/benchmark_1548104077.225572.h5\n",
      "Epoch 14/100\n",
      "575/575 [==============================] - 60s 104ms/step - loss: 2.0171e-04 - acc: 1.0000 - val_loss: 4.0464 - val_acc: 0.4134\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.41436\n",
      "Epoch 15/100\n",
      "575/575 [==============================] - 60s 104ms/step - loss: 1.7985e-04 - acc: 1.0000 - val_loss: 4.1558 - val_acc: 0.4033\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.41436\n",
      "Epoch 16/100\n",
      "575/575 [==============================] - 60s 104ms/step - loss: 1.6216e-04 - acc: 1.0000 - val_loss: 4.2404 - val_acc: 0.3969\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.41436\n",
      "Epoch 00016: early stopping\n",
      "{'network_name': 'benchmark', 'image_aug': True, 'optimizer_name': 'SGD', 'optimizer_params': None, 'batch_size': 8, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1548104077.225572}\n"
     ]
    }
   ],
   "source": [
    "params = {'network_name': \"benchmark\",\n",
    "         'image_aug': True,\n",
    "         'optimizer_name': \"SGD\", \n",
    "         'optimizer': optimizers.SGD(),\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "lr=0.001\n",
    "rho=0.9\n",
    "epsilon=None\n",
    "decay=0.0\n",
    "\n",
    "_model, input_processor = get_model(params[\"network_name\"], image_size=params[\"image_size\"])\n",
    "train_generator, validation_generator = get_generators( params[\"batch_size\"], params[\"image_size\"], None)\n",
    "train_model(params, _model, (train_generator, validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_benchmark_model(verbose=False, img_size=(256, 256)):\n",
    "    \n",
    "    width, height = img_size\n",
    "    model = None\n",
    "    model = Sequential()\n",
    "\n",
    "    #conv_layer1\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(width, height, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # conv_layer2\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # conv_layer3\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    \n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(1024))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "    model.add(Dense(n_categories,kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01), activation=\"softmax\"))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    return model, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n",
      "Epoch 1/100\n",
      "575/575 [==============================] - 34s 60ms/step - loss: 6.3179 - acc: 0.0228 - val_loss: 5.9689 - val_acc: 0.0331\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.03309, saving model to /data/oxford102/experiments/1548105991.8424842/benchmark_1548105991.8424842.h5\n",
      "Epoch 2/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 5.6653 - acc: 0.0463 - val_loss: 5.3951 - val_acc: 0.0552\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.03309 to 0.05525, saving model to /data/oxford102/experiments/1548105991.8424842/benchmark_1548105991.8424842.h5\n",
      "Epoch 3/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 5.0083 - acc: 0.0902 - val_loss: 4.6999 - val_acc: 0.0976\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.05525 to 0.09761, saving model to /data/oxford102/experiments/1548105991.8424842/benchmark_1548105991.8424842.h5\n",
      "Epoch 4/100\n",
      "575/575 [==============================] - 33s 58ms/step - loss: 4.3322 - acc: 0.1546 - val_loss: 4.2884 - val_acc: 0.1565\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.09761 to 0.15654, saving model to /data/oxford102/experiments/1548105991.8424842/benchmark_1548105991.8424842.h5\n",
      "Epoch 5/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 3.8233 - acc: 0.2261 - val_loss: 3.7581 - val_acc: 0.2413\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.15654 to 0.24125, saving model to /data/oxford102/experiments/1548105991.8424842/benchmark_1548105991.8424842.h5\n",
      "Epoch 6/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 3.4976 - acc: 0.2702 - val_loss: 3.5810 - val_acc: 0.2698\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.24125 to 0.26980, saving model to /data/oxford102/experiments/1548105991.8424842/benchmark_1548105991.8424842.h5\n",
      "Epoch 7/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 3.2444 - acc: 0.3113 - val_loss: 3.4377 - val_acc: 0.2680\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.26980\n",
      "Epoch 8/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 3.0858 - acc: 0.3402 - val_loss: 3.2679 - val_acc: 0.2882\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.26980 to 0.28821, saving model to /data/oxford102/experiments/1548105991.8424842/benchmark_1548105991.8424842.h5\n",
      "Epoch 9/100\n",
      "575/575 [==============================] - 33s 57ms/step - loss: 2.9572 - acc: 0.3600 - val_loss: 3.2711 - val_acc: 0.3029\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.28821 to 0.30295, saving model to /data/oxford102/experiments/1548105991.8424842/benchmark_1548105991.8424842.h5\n",
      "Epoch 10/100\n",
      "575/575 [==============================] - 33s 58ms/step - loss: 2.8827 - acc: 0.3739 - val_loss: 3.2425 - val_acc: 0.3020\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.30295\n",
      "Epoch 11/100\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 2.8082 - acc: 0.3896 - val_loss: 3.2746 - val_acc: 0.2983\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.30295\n",
      "Epoch 12/100\n",
      "575/575 [==============================] - 33s 58ms/step - loss: 2.7464 - acc: 0.3941 - val_loss: 3.1682 - val_acc: 0.2901\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.30295\n",
      "Epoch 00012: early stopping\n",
      "{'network_name': 'benchmark', 'image_aug': True, 'optimizer_name': 'SGD', 'optimizer_params': None, 'batch_size': 8, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1548105991.8424842}\n"
     ]
    }
   ],
   "source": [
    "params = {'network_name': \"benchmark\",\n",
    "         'image_aug': True,\n",
    "         'optimizer_name': \"SGD\", \n",
    "         'optimizer': optimizers.SGD(),\n",
    "         'optimizer_params': None, \n",
    "         'batch_size': 8,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "lr=0.001\n",
    "rho=0.9\n",
    "epsilon=None\n",
    "decay=0.0\n",
    "\n",
    "_model, input_processor = get_model(params[\"network_name\"], image_size=params[\"image_size\"])\n",
    "train_generator, validation_generator = get_generators( params[\"batch_size\"], params[\"image_size\"], None)\n",
    "train_model(params, _model, (train_generator, validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
