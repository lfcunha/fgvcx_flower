{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10323754187963449898\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11284542260\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1359543691201208705\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tbCallBack = keras.callbacks.TensorBoard(log_dir='/data/tb-logs', histogram_freq=0, write_graph=True, write_images=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 128, 128\n",
    "train_data_dir = \"/data/fgcvx/train/images/\"\n",
    "validation_data_dir = \"/data/fgcvx/train/images/\"\n",
    "nb_train_samples = 81417\n",
    "nb_validation_samples = 8343 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_categories = 1394\n",
    "batch_size = 16\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "#from keras.models import load_model\n",
    "#model = load_model(\"/data/vgg16_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Since the initial layers train very general features (e.g. edges, we're not going to retrain those)\n",
    "# for layer in model.layers[:12]:\n",
    "#     print(layer.name)\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "#x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(nr_categories, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "model_final = Model(input = model.input, output = predictions)\n",
    "#model_final = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2\n",
      "block1_conv1\n",
      "block1_conv2\n",
      "block1_pool\n",
      "block2_conv1\n",
      "block2_conv2\n",
      "block2_pool\n",
      "block3_conv1\n",
      "block3_conv2\n",
      "block3_conv3\n",
      "block3_conv4\n",
      "block3_pool\n"
     ]
    }
   ],
   "source": [
    "# Since the initial layers train very general features (e.g. edges, we're not going to retrain those)\n",
    "for layer in model_final.layers[:12]:\n",
    "    print(layer.name)\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1394)              1428850   \n",
      "=================================================================\n",
      "Total params: 29,842,866\n",
      "Trainable params: 27,517,298\n",
      "Non-trainable params: 2,325,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "#model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=[\"accuracy\"])\n",
    "#model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0), metrics=[\"accuracy\"])\n",
    "#model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0), metrics=[\"accuracy\"])\n",
    "#model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train__val_datagen = ImageDataGenerator(rescale = 1./255, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 81417 images belonging to 1394 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 128, 128\n",
    "train_generator = train__val_datagen.flow_from_directory(\n",
    "        train_data_dir,  # this is the target directory\n",
    "        target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "        batch_size=batch_size,\n",
    "        subset=\"training\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8343 images belonging to 1394 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train__val_datagen.flow_from_directory(\n",
    "        train_data_dir,  # this is the target directory\n",
    "        target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "        subset=\"validation\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"vgg16_fungi_all_p2.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()), histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  38/5088 [..............................] - ETA: 31:44 - loss: 7.4611 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 4718592 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5088/5088 [============================>.] - ETA: 0s - loss: 7.1104 - acc: 0.0055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:764: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5089/5088 [==============================] - 2147s 422ms/step - loss: 7.1104 - acc: 0.0055 - val_loss: 6.8652 - val_acc: 0.0115\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.01151, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 2/50\n",
      "5089/5088 [==============================] - 2021s 397ms/step - loss: 6.8402 - acc: 0.0113 - val_loss: 6.5054 - val_acc: 0.0198\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.01151 to 0.01978, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 3/50\n",
      "5089/5088 [==============================] - 2028s 398ms/step - loss: 6.5602 - acc: 0.0194 - val_loss: 6.1887 - val_acc: 0.0328\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.01978 to 0.03284, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 4/50\n",
      "5089/5088 [==============================] - 2024s 398ms/step - loss: 6.2994 - acc: 0.0298 - val_loss: 5.9233 - val_acc: 0.0476\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.03284 to 0.04758, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 5/50\n",
      "5089/5088 [==============================] - 2025s 398ms/step - loss: 6.0482 - acc: 0.0415 - val_loss: 5.6920 - val_acc: 0.0644\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.04758 to 0.06437, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 6/50\n",
      "5089/5088 [==============================] - 2025s 398ms/step - loss: 5.8069 - acc: 0.0544 - val_loss: 5.4776 - val_acc: 0.0734\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.06437 to 0.07335, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 7/50\n",
      "5089/5088 [==============================] - 2020s 397ms/step - loss: 5.5814 - acc: 0.0692 - val_loss: 5.2707 - val_acc: 0.0939\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.07335 to 0.09385, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 8/50\n",
      "5089/5088 [==============================] - 2003s 394ms/step - loss: 5.3605 - acc: 0.0854 - val_loss: 5.0636 - val_acc: 0.1066\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.09385 to 0.10656, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 9/50\n",
      "5089/5088 [==============================] - 1999s 393ms/step - loss: 5.1454 - acc: 0.1013 - val_loss: 4.9562 - val_acc: 0.1141\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.10656 to 0.11411, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 10/50\n",
      "5089/5088 [==============================] - 2003s 394ms/step - loss: 4.9410 - acc: 0.1196 - val_loss: 4.8208 - val_acc: 0.1189\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.11411 to 0.11890, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 11/50\n",
      "5089/5088 [==============================] - 1999s 393ms/step - loss: 4.7494 - acc: 0.1361 - val_loss: 4.7058 - val_acc: 0.1308\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.11890 to 0.13077, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 12/50\n",
      "5089/5088 [==============================] - 1999s 393ms/step - loss: 4.5608 - acc: 0.1536 - val_loss: 4.6845 - val_acc: 0.1346\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.13077 to 0.13460, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 13/50\n",
      "5089/5088 [==============================] - 2001s 393ms/step - loss: 4.3712 - acc: 0.1721 - val_loss: 4.5332 - val_acc: 0.1471\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.13460 to 0.14707, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 14/50\n",
      "5089/5088 [==============================] - 2003s 394ms/step - loss: 4.1915 - acc: 0.1925 - val_loss: 4.4994 - val_acc: 0.1477\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.14707 to 0.14767, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 15/50\n",
      "5089/5088 [==============================] - 2012s 395ms/step - loss: 3.9994 - acc: 0.2148 - val_loss: 4.4866 - val_acc: 0.1553\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.14767 to 0.15534, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 16/50\n",
      "5089/5088 [==============================] - 2008s 395ms/step - loss: 3.8271 - acc: 0.2357 - val_loss: 4.4261 - val_acc: 0.1592\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.15534 to 0.15918, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 17/50\n",
      "5089/5088 [==============================] - 2006s 394ms/step - loss: 3.6471 - acc: 0.2603 - val_loss: 4.3785 - val_acc: 0.1727\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.15918 to 0.17272, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 18/50\n",
      "5089/5088 [==============================] - 2007s 394ms/step - loss: 3.4686 - acc: 0.2816 - val_loss: 4.2985 - val_acc: 0.1701\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.17272\n",
      "Epoch 19/50\n",
      "5089/5088 [==============================] - 2003s 394ms/step - loss: 3.2870 - acc: 0.3070 - val_loss: 4.3159 - val_acc: 0.1722\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.17272\n",
      "Epoch 20/50\n",
      "5089/5088 [==============================] - 2000s 393ms/step - loss: 3.0991 - acc: 0.3371 - val_loss: 4.2938 - val_acc: 0.1772\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.17272 to 0.17715, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 21/50\n",
      "5089/5088 [==============================] - 2000s 393ms/step - loss: 2.9240 - acc: 0.3638 - val_loss: 4.4300 - val_acc: 0.1653\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.17715\n",
      "Epoch 22/50\n",
      "5089/5088 [==============================] - 1999s 393ms/step - loss: 2.7368 - acc: 0.3913 - val_loss: 4.4605 - val_acc: 0.1751\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.17715\n",
      "Epoch 23/50\n",
      "5089/5088 [==============================] - 1998s 393ms/step - loss: 2.5603 - acc: 0.4221 - val_loss: 4.4385 - val_acc: 0.1796\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.17715 to 0.17955, saving model to vgg16_fungi_all_p2.h5\n",
      "Epoch 24/50\n",
      "5089/5088 [==============================] - 1996s 392ms/step - loss: 2.3866 - acc: 0.4507 - val_loss: 4.5395 - val_acc: 0.1784\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.17955\n",
      "Epoch 25/50\n",
      "5089/5088 [==============================] - 1999s 393ms/step - loss: 2.2049 - acc: 0.4822 - val_loss: 4.6366 - val_acc: 0.1754\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.17955\n",
      "Epoch 26/50\n",
      "5089/5088 [==============================] - 2004s 394ms/step - loss: 2.0448 - acc: 0.5106 - val_loss: 4.6363 - val_acc: 0.1733\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.17955\n",
      "Epoch 27/50\n",
      "5089/5088 [==============================] - 2008s 395ms/step - loss: 1.8724 - acc: 0.5449 - val_loss: 4.8556 - val_acc: 0.1764\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.17955\n",
      "Epoch 28/50\n",
      "5089/5088 [==============================] - 2003s 394ms/step - loss: 1.7201 - acc: 0.5745 - val_loss: 4.8902 - val_acc: 0.1712\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.17955\n",
      "Epoch 00028: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f780ec4e0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.fit_generator(\n",
    "train_generator,\n",
    "#samples_per_epoch = nb_train_samples,\n",
    "steps_per_epoch = nb_train_samples/batch_size,    \n",
    "epochs = epochs,\n",
    "validation_data = validation_generator,\n",
    "#nb_val_samples = nb_validation_samples,\n",
    "validation_steps = nb_validation_samples/batch_size,    \n",
    "callbacks = [checkpoint, early, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.fit_generator(\n",
    "train_generator,\n",
    "#samples_per_epoch = nb_train_samples,\n",
    "steps_per_epoch = nb_train_samples/batch_size,    \n",
    "epochs = epochs,\n",
    "validation_data = validation_generator,\n",
    "#nb_val_samples = nb_validation_samples,\n",
    "validation_steps = nb_validation_samples/batch_size,    \n",
    "callbacks = [checkpoint, early, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "generator = train__val_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=int(batch_size/10),\n",
    "        class_mode=None) #,  # this means our generator will only yield batches of data, no labels\n",
    "#) #shuffle=False)  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs\n",
    "# the predict_generator method returns the output of a model, given\n",
    "# a generator that yields batches of numpy data\n",
    "bottleneck_features_train = model.predict_generator(generator, 60000)\n",
    "# save the output as a Numpy array\n",
    "np.save(open('bottleneck_features_train.npy', 'w'), bottleneck_features_train)\n",
    "\n",
    "generator = train__val_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=int(batch_size/20),\n",
    "        class_mode=None)\n",
    "#) #shuffle=False)\n",
    "bottleneck_features_validation = model.predict_generator(generator, 8000)\n",
    "np.save(open('bottleneck_features_validation.npy', 'w'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(open('bottleneck_features_train.npy'))\n",
    "# the features were saved in order, so recreating the labels is easy\n",
    "train_labels = np.array([0] * 1000 + [1] * 1000)\n",
    "\n",
    "validation_data = np.load(open('bottleneck_features_validation.npy'))\n",
    "validation_labels = np.array([0] * 400 + [1] * 400)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(nr_categories, activation='softmax')) \n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          epochs=50,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "model.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
