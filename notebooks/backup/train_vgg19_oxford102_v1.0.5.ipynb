{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.applications.vgg19 import decode_predictions\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow\n",
    "from time import time\n",
    "\n",
    "import pandas\n",
    "\n",
    "import pickle as pk\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/oxford102/train'\n",
    "img_width, img_height = 256, 256\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "nr_categories = 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 256, 256\n",
    "train_data_dir = \"/data/oxford102/train/\"\n",
    "validation_data_dir = \"/data/oxford102/train/\"\n",
    "nb_train_samples = 4604\n",
    "nb_validation_samples = 1094 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_processor = keras.applications.vgg19.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_datagen = ImageDataGenerator(preprocessing_function=input_processor, \n",
    "                                           validation_split=0.2)\n",
    "\n",
    "train_val_datagen_aug = ImageDataGenerator(\n",
    "        #rescale=1. / 255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=input_processor,\n",
    "        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4604 images belonging to 102 classes.\n",
      "Found 1094 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "train_generator = train_val_datagen.flow_from_directory(\n",
    "        train_data_dir,  # this is the target directory\n",
    "        target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "        batch_size=batch_size,\n",
    "        subset=\"training\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = train_val_datagen.flow_from_directory(\n",
    "        train_data_dir,  # this is the target directory\n",
    "        target_size=(img_width, img_height),  # all images will be resized to 250x250\n",
    "        subset=\"validation\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:30: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "#from keras import regularizers\n",
    "\n",
    "k.set_learning_phase(0)\n",
    "\n",
    "network_name = \"vgg19\"\n",
    "img_width, img_height = (256, 256)\n",
    "if network_name == \"vgg16\":\n",
    "    base_model = keras.applications.vgg16.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "elif network_name == \"vgg19\":\n",
    "    base_model = keras.applications.vgg19.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "else:\n",
    "    raise Exception(\"check your network name\")\n",
    "\n",
    "for layer in base_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "    #Adding custom Layers \n",
    "k.set_learning_phase(1)\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\", \n",
    "          #kernel_regularizer=regularizers.l2(0.01),\n",
    "         #       activity_regularizer=regularizers.l1(0.001)\n",
    "         )(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x, training=True)\n",
    "#x = Dense(102, activation=\"relu\")(x)\n",
    "predictions = Dense(nr_categories, activation=\"softmax\")(x)\n",
    "\n",
    "_model = Model(input = base_model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              33555456  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 102)               104550    \n",
      "=================================================================\n",
      "Total params: 53,688,486\n",
      "Trainable params: 33,662,054\n",
      "Non-trainable params: 20,026,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 5.4749 - acc: 0.0156 - val_loss: 5.1211 - val_acc: 0.0312\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.03125, saving model to /data/oxford102/experiments/1543115593.83544/vgg19_1543115593.83544.h5\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 5s 597ms/step - loss: 4.8959 - acc: 0.0273 - val_loss: 4.2551 - val_acc: 0.0938\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.03125 to 0.09375, saving model to /data/oxford102/experiments/1543115593.83544/vgg19_1543115593.83544.h5\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 5s 600ms/step - loss: 4.1104 - acc: 0.1406 - val_loss: 4.2952 - val_acc: 0.1719\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.09375 to 0.17188, saving model to /data/oxford102/experiments/1543115593.83544/vgg19_1543115593.83544.h5\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 8s 975ms/step - loss: 3.8163 - acc: 0.1825 - val_loss: 3.9548 - val_acc: 0.2344\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.17188 to 0.23438, saving model to /data/oxford102/experiments/1543115593.83544/vgg19_1543115593.83544.h5\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 5s 596ms/step - loss: 3.5314 - acc: 0.2227 - val_loss: 3.5659 - val_acc: 0.2656\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.23438 to 0.26562, saving model to /data/oxford102/experiments/1543115593.83544/vgg19_1543115593.83544.h5\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 5s 600ms/step - loss: 3.2227 - acc: 0.2969 - val_loss: 3.4102 - val_acc: 0.3125\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.26562 to 0.31250, saving model to /data/oxford102/experiments/1543115593.83544/vgg19_1543115593.83544.h5\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 5s 595ms/step - loss: 3.1286 - acc: 0.3203 - val_loss: 3.1265 - val_acc: 0.3594\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.31250 to 0.35938, saving model to /data/oxford102/experiments/1543115593.83544/vgg19_1543115593.83544.h5\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 5s 597ms/step - loss: 2.8667 - acc: 0.3555 - val_loss: 2.9246 - val_acc: 0.3906\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.35938 to 0.39062, saving model to /data/oxford102/experiments/1543115593.83544/vgg19_1543115593.83544.h5\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 5s 601ms/step - loss: 2.7598 - acc: 0.3359 - val_loss: 2.9092 - val_acc: 0.4688\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.39062 to 0.46875, saving model to /data/oxford102/experiments/1543115593.83544/vgg19_1543115593.83544.h5\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 5s 607ms/step - loss: 2.4277 - acc: 0.4219 - val_loss: 2.7093 - val_acc: 0.4062\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.46875\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 5s 602ms/step - loss: 2.5171 - acc: 0.4180 - val_loss: 2.6566 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.46875\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 5s 604ms/step - loss: 2.2870 - acc: 0.4648 - val_loss: 2.6901 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.46875\n",
      "Epoch 00012: early stopping\n",
      "{'network_name': 'vgg19', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 512, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543115593.83544}\n"
     ]
    }
   ],
   "source": [
    "#run_training(model_name, _model, train_generator, validation_generator, params, num_train_img, num_val_img):\n",
    "    \n",
    "\n",
    "model_name = \"vgg19\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 512,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 20s 582ms/step - loss: 1.6284 - acc: 0.6644 - val_loss: 2.1433 - val_acc: 0.4961\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.49609, saving model to /data/oxford102/experiments/1543115732.377062/vgg19_1543115732.377062.h5\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 20s 557ms/step - loss: 1.4780 - acc: 0.6848 - val_loss: 2.0189 - val_acc: 0.5312\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.49609 to 0.53125, saving model to /data/oxford102/experiments/1543115732.377062/vgg19_1543115732.377062.h5\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 20s 560ms/step - loss: 1.3727 - acc: 0.7179 - val_loss: 1.8655 - val_acc: 0.5430\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.53125 to 0.54297, saving model to /data/oxford102/experiments/1543115732.377062/vgg19_1543115732.377062.h5\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 19s 556ms/step - loss: 1.2774 - acc: 0.7473 - val_loss: 1.6994 - val_acc: 0.6055\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.54297 to 0.60547, saving model to /data/oxford102/experiments/1543115732.377062/vgg19_1543115732.377062.h5\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 20s 576ms/step - loss: 0.8004 - acc: 0.8661 - val_loss: 1.5607 - val_acc: 0.6484\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.60547 to 0.64844, saving model to /data/oxford102/experiments/1543115732.377062/vgg19_1543115732.377062.h5\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 20s 558ms/step - loss: 0.7248 - acc: 0.8890 - val_loss: 1.6464 - val_acc: 0.6445\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.64844\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 20s 559ms/step - loss: 0.6704 - acc: 0.8991 - val_loss: 1.4384 - val_acc: 0.6797\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.64844 to 0.67969, saving model to /data/oxford102/experiments/1543115732.377062/vgg19_1543115732.377062.h5\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 20s 560ms/step - loss: 0.6842 - acc: 0.8813 - val_loss: 1.4255 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.67969 to 0.68750, saving model to /data/oxford102/experiments/1543115732.377062/vgg19_1543115732.377062.h5\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 20s 559ms/step - loss: 0.4960 - acc: 0.9384 - val_loss: 1.3436 - val_acc: 0.6953\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.68750 to 0.69531, saving model to /data/oxford102/experiments/1543115732.377062/vgg19_1543115732.377062.h5\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 20s 561ms/step - loss: 0.3933 - acc: 0.9560 - val_loss: 1.3163 - val_acc: 0.7227\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.69531 to 0.72266, saving model to /data/oxford102/experiments/1543115732.377062/vgg19_1543115732.377062.h5\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 20s 559ms/step - loss: 0.4004 - acc: 0.9527 - val_loss: 1.2995 - val_acc: 0.6797\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.72266\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 20s 560ms/step - loss: 0.3797 - acc: 0.9536 - val_loss: 1.3219 - val_acc: 0.6680\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.72266\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 21s 588ms/step - loss: 0.3026 - acc: 0.9723 - val_loss: 1.1597 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.72266 to 0.73047, saving model to /data/oxford102/experiments/1543115732.377062/vgg19_1543115732.377062.h5\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 20s 562ms/step - loss: 0.2661 - acc: 0.9795 - val_loss: 1.2382 - val_acc: 0.7070\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.73047\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 20s 559ms/step - loss: 0.2373 - acc: 0.9865 - val_loss: 1.2221 - val_acc: 0.6992\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.73047\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 20s 560ms/step - loss: 0.2463 - acc: 0.9839 - val_loss: 1.2596 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.73047\n",
      "Epoch 00016: early stopping\n",
      "{'network_name': 'vgg19', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 128, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543115732.377062}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"vgg19\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 128,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 40s 570ms/step - loss: 0.1773 - acc: 0.9921 - val_loss: 1.1752 - val_acc: 0.7371\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.73713, saving model to /data/oxford102/experiments/1543116077.08352/vgg19_1543116077.08352.h5\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 40s 560ms/step - loss: 0.1789 - acc: 0.9899 - val_loss: 1.1421 - val_acc: 0.7353\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.73713\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 40s 562ms/step - loss: 0.1369 - acc: 0.9974 - val_loss: 1.1117 - val_acc: 0.7408\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.73713 to 0.74081, saving model to /data/oxford102/experiments/1543116077.08352/vgg19_1543116077.08352.h5\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 40s 559ms/step - loss: 0.1328 - acc: 0.9974 - val_loss: 1.0795 - val_acc: 0.7684\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.74081 to 0.76838, saving model to /data/oxford102/experiments/1543116077.08352/vgg19_1543116077.08352.h5\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 40s 559ms/step - loss: 0.1070 - acc: 0.9978 - val_loss: 1.1126 - val_acc: 0.7445\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.76838\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 40s 560ms/step - loss: 0.1043 - acc: 0.9982 - val_loss: 1.0443 - val_acc: 0.7298\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.76838\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 40s 560ms/step - loss: 0.0838 - acc: 0.9987 - val_loss: 1.0768 - val_acc: 0.7537\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.76838\n",
      "Epoch 00007: early stopping\n",
      "{'network_name': 'vgg19', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 64, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543116077.08352}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"vgg19\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vgg19\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 32,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINETUNE TOP LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 block3_pool\n",
      "1 block4_conv1\n",
      "2 block4_conv2\n",
      "3 block4_conv3\n",
      "4 block4_conv4\n",
      "5 block4_pool\n",
      "6 block5_conv1\n",
      "7 block5_conv2\n",
      "8 block5_conv3\n",
      "9 block5_conv4\n",
      "10 block5_pool\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers[11:]):\n",
    "    print(i, layer.name)\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 58s 822ms/step - loss: 0.1295 - acc: 0.9947 - val_loss: 1.0170 - val_acc: 0.7555\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.75551, saving model to /data/oxford102/experiments/1543116375.9565437/vgg19_1543116375.9565437.h5\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 55s 778ms/step - loss: 0.1532 - acc: 0.9912 - val_loss: 0.9671 - val_acc: 0.7721\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.75551 to 0.77206, saving model to /data/oxford102/experiments/1543116375.9565437/vgg19_1543116375.9565437.h5\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 55s 779ms/step - loss: 0.0821 - acc: 0.9982 - val_loss: 0.9087 - val_acc: 0.7739\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.77206 to 0.77390, saving model to /data/oxford102/experiments/1543116375.9565437/vgg19_1543116375.9565437.h5\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 55s 780ms/step - loss: 0.0792 - acc: 0.9974 - val_loss: 0.8552 - val_acc: 0.8051\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.77390 to 0.80515, saving model to /data/oxford102/experiments/1543116375.9565437/vgg19_1543116375.9565437.h5\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 55s 777ms/step - loss: 0.0503 - acc: 0.9991 - val_loss: 0.8331 - val_acc: 0.8143\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.80515 to 0.81434, saving model to /data/oxford102/experiments/1543116375.9565437/vgg19_1543116375.9565437.h5\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 55s 778ms/step - loss: 0.0613 - acc: 0.9982 - val_loss: 0.8427 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.81434\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 55s 781ms/step - loss: 0.0433 - acc: 0.9996 - val_loss: 0.7343 - val_acc: 0.8456\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.81434 to 0.84559, saving model to /data/oxford102/experiments/1543116375.9565437/vgg19_1543116375.9565437.h5\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 55s 779ms/step - loss: 0.0488 - acc: 0.9991 - val_loss: 0.8340 - val_acc: 0.8033\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.84559\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 55s 780ms/step - loss: 0.0407 - acc: 0.9987 - val_loss: 0.7288 - val_acc: 0.8290\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.84559\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 55s 780ms/step - loss: 0.0381 - acc: 0.9991 - val_loss: 0.7044 - val_acc: 0.8346\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.84559\n",
      "Epoch 00010: early stopping\n",
      "{'network_name': 'vgg19', 'image_aug': False, 'optimizer': 'SGD', 'optimizer_params': None, 'batch_size': 64, 'epochs': 100, 'image_size': (256, 256), 'log_time': 1543116375.9565437}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"vgg19\"\n",
    "num_train_img = 4604\n",
    "num_val_img = 1094\n",
    "params = {'network_name': 'vgg19',\n",
    "         'image_aug': False,\n",
    "         'optimizer': 'SGD',\n",
    "          'optimizer_params': None, \n",
    "         'batch_size': 64,\n",
    "         'epochs': 100,\n",
    "         'image_size': (256, 256),\n",
    "         'log_time': None}\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "log_time = time()\n",
    "params['log_time'] = log_time\n",
    "batch_size = params.get(\"batch_size\")\n",
    "\n",
    "_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "base = '/data/oxford102/experiments'\n",
    "path = os.path.join(base, str(log_time))\n",
    "checkpoint = ModelCheckpoint(os.path.join(path, \"{}_{}.h5\".format(model_name, log_time)), monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(log_time), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = CSVLogger(os.path.join(path, \"{}_{}.csv\".format(model_name, log_time)), append=True, separator=';')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    history_callback = _model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train_img // batch_size,\n",
    "            epochs=params.get(\"epochs\"),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val_img // batch_size,\n",
    "            callbacks = [checkpoint, early, tensorboard, csv_logger])\n",
    "except Exception as e:\n",
    "    raise(e)\n",
    "finally:\n",
    "    pk.dump(params, open(\"experimental_params/experiments_{}.pk\".format(log_time), \"wb\"), protocol=pk.HIGHEST_PROTOCOL)\n",
    "    _model.save_weights(os.path.join(path, 'model_{}_weights_final_{}.h5'.format(model_name, log_time)))  # always save your weights after training or during training\n",
    "    print(params)\n",
    "    params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
